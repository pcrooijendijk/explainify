[
  [
    {
      "cve_id": [
        "CVE-2025-9648",
        "https://github.com/civetweb/civetweb/commit/782e18903515f43bafbf2e668994e82bdfa51133"
      ],
      "repo": "civetweb",
      "commit_hash": "782e18903515f43bafbf2e668994e82bdfa51133",
      "commit_message": "Make parsing of URL encoded forms more robust  Reject requests that obviously violate the URL encoding. Fixes #1348",
      "files_changed": [
        {
          "filename": "src/civetweb.c",
          "old_url": "https://raw.githubusercontent.com/civetweb/civetweb/26aa1ecf6e4f38dfdac43a44ba486341b048ffc3/src/civetweb.c",
          "new_url": "https://raw.githubusercontent.com/civetweb/civetweb/782e18903515f43bafbf2e668994e82bdfa51133/src/civetweb.c",
          "diff": "@@ -1,4 +1,4 @@\n-/* Copyright (c) 2013-2024 the Civetweb developers\n+/* Copyright (c) 2013-2025 the Civetweb developers\n  * Copyright (c) 2004-2013 Sergey Lyubka\n  *\n  * Permission is hereby granted, free of charge, to any person obtaining a copy\n@@ -7272,6 +7272,7 @@ mg_url_decode(const char *src,\n               int is_form_url_encoded)\n {\n \tint i, j, a, b,\n+\n #define HEXTOI(x) (isdigit(x) ? (x - '0') : (x - 'W'))\n \n \tfor (i = j = 0, (i < src_len) && (j < (dst_len - 1)), i++, j++) {\n@@ -7284,11 +7285,15 @@ mg_url_decode(const char *src,\n \t\t\ti += 2,\n \t\t} else if (is_form_url_encoded && (src[i] == '+')) {\n \t\t\tdst[j] = ' ',\n+\t\t} else if ((unsigned char)src[i] <= ' ') {\n+\t\t\treturn -1, /* invalid character */\n \t\t} else {\n \t\t\tdst[j] = src[i],\n \t\t}\n \t}\n \n+#undef HEXTOI\n+\n \tdst[j] = '\\0', /* Null-terminate the destination */\n \n \treturn (i >= src_len) ? j : -1,"
        },
        {
          "filename": "src/handle_form.inl",
          "old_url": "https://raw.githubusercontent.com/civetweb/civetweb/26aa1ecf6e4f38dfdac43a44ba486341b048ffc3/src/handle_form.inl",
          "new_url": "https://raw.githubusercontent.com/civetweb/civetweb/782e18903515f43bafbf2e668994e82bdfa51133/src/handle_form.inl",
          "diff": "@@ -1,4 +1,4 @@\n-/* Copyright (c) 2016-2021 the Civetweb developers\n+/* Copyright (c) 2016-2025 the Civetweb developers\n  *\n  * Permission is hereby granted, free of charge, to any person obtaining a copy\n  * of this software and associated documentation files (the \"Software\"), to deal\n@@ -39,7 +39,7 @@ url_encoded_field_found(const struct mg_connection *conn,\n \t    mg_url_decode(key, (int)key_len, key_dec, (int)sizeof(key_dec), 1),\n \n \tif (((size_t)key_dec_len >= (size_t)sizeof(key_dec)) || (key_dec_len < 0)) {\n-\t\treturn MG_FORM_FIELD_STORAGE_SKIP,\n+\t\treturn MG_FORM_FIELD_STORAGE_ABORT,\n \t}\n \n \tif (filename) {\n@@ -53,7 +53,7 @@ url_encoded_field_found(const struct mg_connection *conn,\n \t\t    || (filename_dec_len < 0)) {\n \t\t\t/* Log error message and skip this field. */\n \t\t\tmg_cry_internal(conn, \"%s: Cannot decode filename\", __func__),\n-\t\t\treturn MG_FORM_FIELD_STORAGE_SKIP,\n+\t\t\treturn MG_FORM_FIELD_STORAGE_ABORT,\n \t\t}\n \t\tremove_dot_segments(filename_dec),\n \n@@ -95,6 +95,7 @@ url_encoded_field_get(\n     struct mg_form_data_handler *fdh)\n {\n \tchar key_dec[1024],\n+\tint key_dec_len,\n \n \tchar *value_dec = (char *)mg_malloc_ctx(*value_len + 1, conn->phys_ctx),\n \tint value_dec_len, ret,\n@@ -108,7 +109,8 @@ url_encoded_field_get(\n \t\treturn MG_FORM_FIELD_STORAGE_ABORT,\n \t}\n \n-\tmg_url_decode(key, (int)key_len, key_dec, (int)sizeof(key_dec), 1),\n+\tkey_dec_len = mg_url_decode(\n+\t    key, (int)key_len, key_dec, (int)sizeof(key_dec), 1),\n \n \tif (*value_len >= 2 && value[*value_len - 2] == '%')\n \t\t*value_len -= 2,\n@@ -117,6 +119,11 @@ url_encoded_field_get(\n \tvalue_dec_len = mg_url_decode(\n \t    value, (int)*value_len, value_dec, ((int)*value_len) + 1, 1),\n \n+\tif ((key_dec_len < 0) || (value_dec_len < 0)) {\n+\t\tmg_free(value_dec),\n+\t\treturn MG_FORM_FIELD_STORAGE_ABORT,\n+\t}\n+\n \tret = fdh->field_get(key_dec,\n \t                     value_dec,\n \t                     (size_t)value_dec_len,\n@@ -136,9 +143,13 @@ unencoded_field_get(const struct mg_connection *conn,\n                     struct mg_form_data_handler *fdh)\n {\n \tchar key_dec[1024],\n+\tint key_dec_len,\n \t(void)conn,\n \n-\tmg_url_decode(key, (int)key_len, key_dec, (int)sizeof(key_dec), 1),\n+\tkey_dec_len = mg_url_decode(key, (int)key_len, key_dec, (int)sizeof(key_dec), 1),\n+\tif (key_dec_len < 0) {\n+\t\treturn MG_FORM_FIELD_STORAGE_ABORT,\n+\t}\n \n \treturn fdh->field_get(key_dec, value, value_len, fdh->user_data),\n }\n@@ -191,6 +202,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \tsize_t buf_fill = 0,\n \tint r,\n \tint field_count = 0,\n+\tint abort_read = 0,\n \tstruct mg_file fstore = STRUCT_FILE_INITIALIZER,\n \tint64_t file_size = 0, /* init here, to a avoid a false positive\n \t                         \"uninitialized variable used\" warning */\n@@ -281,6 +293,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t    conn, data, (size_t)keylen, val, (size_t *)&vallen, fdh),\n \t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\tabort_read = 1,\n \t\t\t\t\tbreak,\n \t\t\t\t}\n \t\t\t\tif (r == MG_FORM_FIELD_HANDLE_NEXT) {\n@@ -323,6 +336,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t\t\t\tr = field_stored(conn, path, file_size, fdh),\n \t\t\t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\t\t\t\tabort_read = 1,\n \t\t\t\t\t\t\t\tbreak,\n \t\t\t\t\t\t\t}\n \n@@ -361,6 +375,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\tif ((field_storage & MG_FORM_FIELD_STORAGE_ABORT)\n \t\t\t    == MG_FORM_FIELD_STORAGE_ABORT) {\n \t\t\t\t/* Stop parsing the request */\n+\t\t\t\tabort_read = 1,\n \t\t\t\tbreak,\n \t\t\t}\n \n@@ -389,7 +404,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t * Here we use \"POST\", and read the data from the request body.\n \t\t * The data read on the fly, so it is not required to buffer the\n \t\t * entire request in memory before processing it. */\n-\t\tfor (,,) {\n+\t\twhile (!abort_read) {\n \t\t\tconst char *val,\n \t\t\tconst char *next,\n \t\t\tptrdiff_t keylen, vallen,\n@@ -443,6 +458,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\tif ((field_storage & MG_FORM_FIELD_STORAGE_ABORT)\n \t\t\t    == MG_FORM_FIELD_STORAGE_ABORT) {\n \t\t\t\t/* Stop parsing the request */\n+\t\t\t\tabort_read = 1,\n \t\t\t\tbreak,\n \t\t\t}\n \n@@ -471,6 +487,15 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t} else {\n \t\t\t\t\tvallen = (ptrdiff_t)strlen(val),\n \t\t\t\t\tend_of_key_value_pair_found = all_data_read,\n+\t\t\t\t\tif ((buf + buf_fill) > (val + vallen)) {\n+\t\t\t\t\t\t/* Avoid DoS attacks by having a zero byte in the middle of\n+\t\t\t\t\t\t * a request that is supposed to be URL encoded. Since this\n+\t\t\t\t\t\t * request is certainly invalid, according to the protocol\n+\t\t\t\t\t\t * specification, stop processing it. Fixes #1348 */\n+\t\t\t\t\t\tabort_read = 1,\n+\t\t\t\t\t\tbreak,\n+\t\t\t\t\t}\n+\n \t\t\t\t}\n \n \t\t\t\tif (field_storage == MG_FORM_FIELD_STORAGE_GET) {\n@@ -492,6 +517,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t\tget_block++,\n \t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\t\tabort_read = 1,\n \t\t\t\t\t\tbreak,\n \t\t\t\t\t}\n \t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_NEXT) {\n@@ -560,7 +586,6 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t\t\tval = buf,\n \t\t\t\t\t}\n \t\t\t\t}\n-\n \t\t\t} while (!end_of_key_value_pair_found),\n \n #if !defined(NO_FILESYSTEMS)\n@@ -571,6 +596,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t\tr = field_stored(conn, path, file_size, fdh),\n \t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\t\tabort_read = 1,\n \t\t\t\t\t\tbreak,\n \t\t\t\t\t}\n \t\t\t\t} else {\n@@ -584,7 +610,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t}\n #endif /* NO_FILESYSTEMS */\n \n-\t\t\tif (all_data_read && (buf_fill == 0)) {\n+\t\t\tif ((all_data_read && (buf_fill == 0)) || abort_read) {\n \t\t\t\t/* nothing more to process */\n \t\t\t\tbreak,\n \t\t\t}\n@@ -972,6 +998,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t\tget_block++,\n \t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\t\tabort_read = 1,\n \t\t\t\t\t\tbreak,\n \t\t\t\t\t}\n \t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_NEXT) {\n@@ -1046,6 +1073,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t                        fdh),\n \t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\tabort_read = 1,\n \t\t\t\t\tbreak,\n \t\t\t\t}\n \t\t\t\tif (r == MG_FORM_FIELD_HANDLE_NEXT) {\n@@ -1074,6 +1102,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\t\t\t\t\tr = field_stored(conn, path, file_size, fdh),\n \t\t\t\t\t\t\tif (r == MG_FORM_FIELD_HANDLE_ABORT) {\n \t\t\t\t\t\t\t\t/* Stop request handling */\n+\t\t\t\t\t\t\t\tabort_read = 1,\n \t\t\t\t\t\t\t\tbreak,\n \t\t\t\t\t\t\t}\n \t\t\t\t\t\t} else {\n@@ -1092,6 +1121,7 @@ mg_handle_form_request(struct mg_connection *conn,\n \t\t\tif ((field_storage & MG_FORM_FIELD_STORAGE_ABORT)\n \t\t\t    == MG_FORM_FIELD_STORAGE_ABORT) {\n \t\t\t\t/* Stop parsing the request */\n+\t\t\t\tabort_read = 1,\n \t\t\t\tbreak,\n \t\t\t}\n "
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-7104",
        "https://github.com/danny-avila/librechat/commit/a37bf6719cfbc2de270f7d87b6b85d87cc1768db"
      ],
      "repo": "librechat",
      "commit_hash": "a37bf6719cfbc2de270f7d87b6b85d87cc1768db",
      "commit_message": "\ud83e\uddea refactor: Add Validation for Agent Creation/Updates (#8261)  * refactor: Add validation schemas for agent creation and updates  * fix: Ensure author validation is applied in correct order for agent update handler  * ci: Add comprehensive unit tests for agent creation and update handlers with mass assignment protection  * fix: add missing  web_search tool in system tools configuration",
      "files_changed": [
        {
          "filename": "api/server/controllers/agents/v1.js",
          "old_url": "https://raw.githubusercontent.com/danny-avila/librechat/e513f50c081505b2362be262c6cb38ad479c1653/api/server/controllers/agents/v1.js",
          "new_url": "https://raw.githubusercontent.com/danny-avila/librechat/a37bf6719cfbc2de270f7d87b6b85d87cc1768db/api/server/controllers/agents/v1.js",
          "diff": "@@ -1,13 +1,16 @@\n+const { z } = require('zod'),\n const fs = require('fs').promises,\n const { nanoid } = require('nanoid'),\n const { logger } = require('@librechat/data-schemas'),\n+const { agentCreateSchema, agentUpdateSchema } = require('@librechat/api'),\n const {\n   Tools,\n   Constants,\n   FileSources,\n   SystemRoles,\n   EToolResources,\n   actionDelimiter,\n+  removeNullishValues,\n } = require('librechat-data-provider'),\n const {\n   getAgent,\n@@ -30,6 +33,7 @@ const { deleteFileByFilter } = require('~/models/File'),\n const systemTools = {\n   [Tools.execute_code]: true,\n   [Tools.file_search]: true,\n+  [Tools.web_search]: true,\n },\n \n /**\n@@ -42,9 +46,13 @@ const systemTools = {\n  */\n const createAgentHandler = async (req, res) => {\n   try {\n-    const { tools = [], provider, name, description, instructions, model, ...agentData } = req.body,\n+    const validatedData = agentCreateSchema.parse(req.body),\n+    const { tools = [], ...agentData } = removeNullishValues(validatedData),\n+\n     const { id: userId } = req.user,\n \n+    agentData.id = `agent_${nanoid()}`,\n+    agentData.author = userId,\n     agentData.tools = [],\n \n     const availableTools = await getCachedTools({ includeGlobal: true }),\n@@ -58,19 +66,13 @@ const createAgentHandler = async (req, res) => {\n       }\n     }\n \n-    Object.assign(agentData, {\n-      author: userId,\n-      name,\n-      description,\n-      instructions,\n-      provider,\n-      model,\n-    }),\n-\n-    agentData.id = `agent_${nanoid()}`,\n     const agent = await createAgent(agentData),\n     res.status(201).json(agent),\n   } catch (error) {\n+    if (error instanceof z.ZodError) {\n+      logger.error('[/Agents] Validation error', error.errors),\n+      return res.status(400).json({ error: 'Invalid request data', details: error.errors }),\n+    }\n     logger.error('[/Agents] Error creating agent', error),\n     res.status(500).json({ error: error.message }),\n   }\n@@ -154,14 +156,16 @@ const getAgentHandler = async (req, res) => {\n const updateAgentHandler = async (req, res) => {\n   try {\n     const id = req.params.id,\n-    const { projectIds, removeProjectIds, ...updateData } = req.body,\n+    const validatedData = agentUpdateSchema.parse(req.body),\n+    const { projectIds, removeProjectIds, ...updateData } = removeNullishValues(validatedData),\n     const isAdmin = req.user.role === SystemRoles.ADMIN,\n     const existingAgent = await getAgent({ id }),\n-    const isAuthor = existingAgent.author.toString() === req.user.id,\n \n     if (!existingAgent) {\n       return res.status(404).json({ error: 'Agent not found' }),\n     }\n+\n+    const isAuthor = existingAgent.author.toString() === req.user.id,\n     const hasEditPermission = existingAgent.isCollaborative || isAdmin || isAuthor,\n \n     if (!hasEditPermission) {\n@@ -200,6 +204,11 @@ const updateAgentHandler = async (req, res) => {\n \n     return res.json(updatedAgent),\n   } catch (error) {\n+    if (error instanceof z.ZodError) {\n+      logger.error('[/Agents/:id] Validation error', error.errors),\n+      return res.status(400).json({ error: 'Invalid request data', details: error.errors }),\n+    }\n+\n     logger.error('[/Agents/:id] Error updating Agent', error),\n \n     if (error.statusCode === 409) {"
        },
        {
          "filename": "api/server/controllers/agents/v1.spec.js",
          "old_url": "https://raw.githubusercontent.com/danny-avila/librechat/e513f50c081505b2362be262c6cb38ad479c1653/api/server/controllers/agents/v1.spec.js",
          "new_url": "https://raw.githubusercontent.com/danny-avila/librechat/a37bf6719cfbc2de270f7d87b6b85d87cc1768db/api/server/controllers/agents/v1.spec.js",
          "diff": "@@ -0,0 +1,659 @@\n+const mongoose = require('mongoose'),\n+const { v4: uuidv4 } = require('uuid'),\n+const { MongoMemoryServer } = require('mongodb-memory-server'),\n+const { agentSchema } = require('@librechat/data-schemas'),\n+\n+// Only mock the dependencies that are not database-related\n+jest.mock('~/server/services/Config', () => ({\n+  getCachedTools: jest.fn().mockResolvedValue({\n+    web_search: true,\n+    execute_code: true,\n+    file_search: true,\n+  }),\n+})),\n+\n+jest.mock('~/models/Project', () => ({\n+  getProjectByName: jest.fn().mockResolvedValue(null),\n+})),\n+\n+jest.mock('~/server/services/Files/strategies', () => ({\n+  getStrategyFunctions: jest.fn(),\n+})),\n+\n+jest.mock('~/server/services/Files/images/avatar', () => ({\n+  resizeAvatar: jest.fn(),\n+})),\n+\n+jest.mock('~/server/services/Files/S3/crud', () => ({\n+  refreshS3Url: jest.fn(),\n+})),\n+\n+jest.mock('~/server/services/Files/process', () => ({\n+  filterFile: jest.fn(),\n+})),\n+\n+jest.mock('~/models/Action', () => ({\n+  updateAction: jest.fn(),\n+  getActions: jest.fn().mockResolvedValue([]),\n+})),\n+\n+jest.mock('~/models/File', () => ({\n+  deleteFileByFilter: jest.fn(),\n+})),\n+\n+const { createAgent: createAgentHandler, updateAgent: updateAgentHandler } = require('./v1'),\n+\n+/**\n+ * @type {import('mongoose').Model<import('@librechat/data-schemas').IAgent>}\n+ */\n+let Agent,\n+\n+describe('Agent Controllers - Mass Assignment Protection', () => {\n+  let mongoServer,\n+  let mockReq,\n+  let mockRes,\n+\n+  beforeAll(async () => {\n+    mongoServer = await MongoMemoryServer.create(),\n+    const mongoUri = mongoServer.getUri(),\n+    await mongoose.connect(mongoUri),\n+    Agent = mongoose.models.Agent || mongoose.model('Agent', agentSchema),\n+  }, 20000),\n+\n+  afterAll(async () => {\n+    await mongoose.disconnect(),\n+    await mongoServer.stop(),\n+  }),\n+\n+  beforeEach(async () => {\n+    await Agent.deleteMany({}),\n+\n+    // Reset all mocks\n+    jest.clearAllMocks(),\n+\n+    // Setup mock request and response objects\n+    mockReq = {\n+      user: {\n+        id: new mongoose.Types.ObjectId().toString(),\n+        role: 'USER',\n+      },\n+      body: {},\n+      params: {},\n+      app: {\n+        locals: {\n+          fileStrategy: 'local',\n+        },\n+      },\n+    },\n+\n+    mockRes = {\n+      status: jest.fn().mockReturnThis(),\n+      json: jest.fn().mockReturnThis(),\n+    },\n+  }),\n+\n+  describe('createAgentHandler', () => {\n+    test('should create agent with allowed fields only', async () => {\n+      const validData = {\n+        name: 'Test Agent',\n+        description: 'A test agent',\n+        instructions: 'Be helpful',\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        tools: ['web_search'],\n+        model_parameters: { temperature: 0.7 },\n+        tool_resources: {\n+          file_search: { file_ids: ['file1', 'file2'] },\n+        },\n+      },\n+\n+      mockReq.body = validData,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+      expect(createdAgent.name).toBe('Test Agent'),\n+      expect(createdAgent.description).toBe('A test agent'),\n+      expect(createdAgent.provider).toBe('openai'),\n+      expect(createdAgent.model).toBe('gpt-4'),\n+      expect(createdAgent.author.toString()).toBe(mockReq.user.id),\n+      expect(createdAgent.tools).toContain('web_search'),\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: createdAgent.id }),\n+      expect(agentInDb).toBeDefined(),\n+      expect(agentInDb.name).toBe('Test Agent'),\n+      expect(agentInDb.author.toString()).toBe(mockReq.user.id),\n+    }),\n+\n+    test('should reject creation with unauthorized fields (mass assignment protection)', async () => {\n+      const maliciousData = {\n+        // Required fields\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'Malicious Agent',\n+\n+        // Unauthorized fields that should be stripped\n+        author: new mongoose.Types.ObjectId().toString(), // Should not be able to set author\n+        authorName: 'Hacker', // Should be stripped\n+        isCollaborative: true, // Should be stripped on creation\n+        versions: [], // Should be stripped\n+        _id: new mongoose.Types.ObjectId(), // Should be stripped\n+        id: 'custom_agent_id', // Should be overridden\n+        createdAt: new Date('2020-01-01'), // Should be stripped\n+        updatedAt: new Date('2020-01-01'), // Should be stripped\n+      },\n+\n+      mockReq.body = maliciousData,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+\n+      // Verify unauthorized fields were not set\n+      expect(createdAgent.author.toString()).toBe(mockReq.user.id), // Should be the request user, not the malicious value\n+      expect(createdAgent.authorName).toBeUndefined(),\n+      expect(createdAgent.isCollaborative).toBeFalsy(),\n+      expect(createdAgent.versions).toHaveLength(1), // Should have exactly 1 version from creation\n+      expect(createdAgent.id).not.toBe('custom_agent_id'), // Should have generated ID\n+      expect(createdAgent.id).toMatch(/^agent_/), // Should have proper prefix\n+\n+      // Verify timestamps are recent (not the malicious dates)\n+      const createdTime = new Date(createdAgent.createdAt).getTime(),\n+      const now = Date.now(),\n+      expect(now - createdTime).toBeLessThan(5000), // Created within last 5 seconds\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: createdAgent.id }),\n+      expect(agentInDb.author.toString()).toBe(mockReq.user.id),\n+      expect(agentInDb.authorName).toBeUndefined(),\n+    }),\n+\n+    test('should validate required fields', async () => {\n+      const invalidData = {\n+        name: 'Missing Required Fields',\n+        // Missing provider and model\n+      },\n+\n+      mockReq.body = invalidData,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(400),\n+      expect(mockRes.json).toHaveBeenCalledWith(\n+        expect.objectContaining({\n+          error: 'Invalid request data',\n+          details: expect.any(Array),\n+        }),\n+      ),\n+\n+      // Verify nothing was created in database\n+      const count = await Agent.countDocuments(),\n+      expect(count).toBe(0),\n+    }),\n+\n+    test('should handle tool_resources validation', async () => {\n+      const dataWithInvalidToolResources = {\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'Agent with Tool Resources',\n+        tool_resources: {\n+          // Valid resources\n+          file_search: {\n+            file_ids: ['file1', 'file2'],\n+            vector_store_ids: ['vs1'],\n+          },\n+          execute_code: {\n+            file_ids: ['file3'],\n+          },\n+          // Invalid resource (should be stripped by schema)\n+          invalid_resource: {\n+            file_ids: ['file4'],\n+          },\n+        },\n+      },\n+\n+      mockReq.body = dataWithInvalidToolResources,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+      expect(createdAgent.tool_resources).toBeDefined(),\n+      expect(createdAgent.tool_resources.file_search).toBeDefined(),\n+      expect(createdAgent.tool_resources.execute_code).toBeDefined(),\n+      expect(createdAgent.tool_resources.invalid_resource).toBeUndefined(), // Should be stripped\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: createdAgent.id }),\n+      expect(agentInDb.tool_resources.invalid_resource).toBeUndefined(),\n+    }),\n+\n+    test('should handle avatar validation', async () => {\n+      const dataWithAvatar = {\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'Agent with Avatar',\n+        avatar: {\n+          filepath: 'https://example.com/avatar.png',\n+          source: 's3',\n+        },\n+      },\n+\n+      mockReq.body = dataWithAvatar,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+      expect(createdAgent.avatar).toEqual({\n+        filepath: 'https://example.com/avatar.png',\n+        source: 's3',\n+      }),\n+    }),\n+\n+    test('should handle invalid avatar format', async () => {\n+      const dataWithInvalidAvatar = {\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'Agent with Invalid Avatar',\n+        avatar: 'just-a-string', // Invalid format\n+      },\n+\n+      mockReq.body = dataWithInvalidAvatar,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(400),\n+      expect(mockRes.json).toHaveBeenCalledWith(\n+        expect.objectContaining({\n+          error: 'Invalid request data',\n+        }),\n+      ),\n+    }),\n+  }),\n+\n+  describe('updateAgentHandler', () => {\n+    let existingAgentId,\n+    let existingAgentAuthorId,\n+\n+    beforeEach(async () => {\n+      // Create an existing agent for update tests\n+      existingAgentAuthorId = new mongoose.Types.ObjectId(),\n+      const agent = await Agent.create({\n+        id: `agent_${uuidv4()}`,\n+        name: 'Original Agent',\n+        provider: 'openai',\n+        model: 'gpt-3.5-turbo',\n+        author: existingAgentAuthorId,\n+        description: 'Original description',\n+        isCollaborative: false,\n+        versions: [\n+          {\n+            name: 'Original Agent',\n+            provider: 'openai',\n+            model: 'gpt-3.5-turbo',\n+            description: 'Original description',\n+            createdAt: new Date(),\n+            updatedAt: new Date(),\n+          },\n+        ],\n+      }),\n+      existingAgentId = agent.id,\n+    }),\n+\n+    test('should update agent with allowed fields only', async () => {\n+      mockReq.user.id = existingAgentAuthorId.toString(), // Set as author\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        name: 'Updated Agent',\n+        description: 'Updated description',\n+        model: 'gpt-4',\n+        isCollaborative: true, // This IS allowed in updates\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).not.toHaveBeenCalledWith(400),\n+      expect(mockRes.status).not.toHaveBeenCalledWith(403),\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const updatedAgent = mockRes.json.mock.calls[0][0],\n+      expect(updatedAgent.name).toBe('Updated Agent'),\n+      expect(updatedAgent.description).toBe('Updated description'),\n+      expect(updatedAgent.model).toBe('gpt-4'),\n+      expect(updatedAgent.isCollaborative).toBe(true),\n+      expect(updatedAgent.author).toBe(existingAgentAuthorId.toString()),\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: existingAgentId }),\n+      expect(agentInDb.name).toBe('Updated Agent'),\n+      expect(agentInDb.isCollaborative).toBe(true),\n+    }),\n+\n+    test('should reject update with unauthorized fields (mass assignment protection)', async () => {\n+      mockReq.user.id = existingAgentAuthorId.toString(),\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        name: 'Updated Name',\n+\n+        // Unauthorized fields that should be stripped\n+        author: new mongoose.Types.ObjectId().toString(), // Should not be able to change author\n+        authorName: 'Hacker', // Should be stripped\n+        id: 'different_agent_id', // Should be stripped\n+        _id: new mongoose.Types.ObjectId(), // Should be stripped\n+        versions: [], // Should be stripped\n+        createdAt: new Date('2020-01-01'), // Should be stripped\n+        updatedAt: new Date('2020-01-01'), // Should be stripped\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const updatedAgent = mockRes.json.mock.calls[0][0],\n+\n+      // Verify unauthorized fields were not changed\n+      expect(updatedAgent.author).toBe(existingAgentAuthorId.toString()), // Should not have changed\n+      expect(updatedAgent.authorName).toBeUndefined(),\n+      expect(updatedAgent.id).toBe(existingAgentId), // Should not have changed\n+      expect(updatedAgent.name).toBe('Updated Name'), // Only this should have changed\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: existingAgentId }),\n+      expect(agentInDb.author.toString()).toBe(existingAgentAuthorId.toString()),\n+      expect(agentInDb.id).toBe(existingAgentId),\n+    }),\n+\n+    test('should reject update from non-author when not collaborative', async () => {\n+      const differentUserId = new mongoose.Types.ObjectId().toString(),\n+      mockReq.user.id = differentUserId, // Different user\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        name: 'Unauthorized Update',\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(403),\n+      expect(mockRes.json).toHaveBeenCalledWith({\n+        error: 'You do not have permission to modify this non-collaborative agent',\n+      }),\n+\n+      // Verify agent was not modified in database\n+      const agentInDb = await Agent.findOne({ id: existingAgentId }),\n+      expect(agentInDb.name).toBe('Original Agent'),\n+    }),\n+\n+    test('should allow update from non-author when collaborative', async () => {\n+      // First make the agent collaborative\n+      await Agent.updateOne({ id: existingAgentId }, { isCollaborative: true }),\n+\n+      const differentUserId = new mongoose.Types.ObjectId().toString(),\n+      mockReq.user.id = differentUserId, // Different user\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        name: 'Collaborative Update',\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).not.toHaveBeenCalledWith(403),\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const updatedAgent = mockRes.json.mock.calls[0][0],\n+      expect(updatedAgent.name).toBe('Collaborative Update'),\n+      // Author field should be removed for non-author\n+      expect(updatedAgent.author).toBeUndefined(),\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: existingAgentId }),\n+      expect(agentInDb.name).toBe('Collaborative Update'),\n+    }),\n+\n+    test('should allow admin to update any agent', async () => {\n+      const adminUserId = new mongoose.Types.ObjectId().toString(),\n+      mockReq.user.id = adminUserId,\n+      mockReq.user.role = 'ADMIN', // Set as admin\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        name: 'Admin Update',\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).not.toHaveBeenCalledWith(403),\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const updatedAgent = mockRes.json.mock.calls[0][0],\n+      expect(updatedAgent.name).toBe('Admin Update'),\n+    }),\n+\n+    test('should handle projectIds updates', async () => {\n+      mockReq.user.id = existingAgentAuthorId.toString(),\n+      mockReq.params.id = existingAgentId,\n+\n+      const projectId1 = new mongoose.Types.ObjectId().toString(),\n+      const projectId2 = new mongoose.Types.ObjectId().toString(),\n+\n+      mockReq.body = {\n+        projectIds: [projectId1, projectId2],\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const updatedAgent = mockRes.json.mock.calls[0][0],\n+      expect(updatedAgent).toBeDefined(),\n+      // Note: updateAgentProjects requires more setup, so we just verify the handler doesn't crash\n+    }),\n+\n+    test('should validate tool_resources in updates', async () => {\n+      mockReq.user.id = existingAgentAuthorId.toString(),\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        tool_resources: {\n+          ocr: {\n+            file_ids: ['ocr1', 'ocr2'],\n+          },\n+          execute_code: {\n+            file_ids: ['img1'],\n+          },\n+          // Invalid tool resource\n+          invalid_tool: {\n+            file_ids: ['invalid'],\n+          },\n+        },\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.json).toHaveBeenCalled(),\n+\n+      const updatedAgent = mockRes.json.mock.calls[0][0],\n+      expect(updatedAgent.tool_resources).toBeDefined(),\n+      expect(updatedAgent.tool_resources.ocr).toBeDefined(),\n+      expect(updatedAgent.tool_resources.execute_code).toBeDefined(),\n+      expect(updatedAgent.tool_resources.invalid_tool).toBeUndefined(),\n+    }),\n+\n+    test('should return 404 for non-existent agent', async () => {\n+      mockReq.user.id = existingAgentAuthorId.toString(),\n+      mockReq.params.id = `agent_${uuidv4()}`, // Non-existent ID\n+      mockReq.body = {\n+        name: 'Update Non-existent',\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(404),\n+      expect(mockRes.json).toHaveBeenCalledWith({ error: 'Agent not found' }),\n+    }),\n+\n+    test('should handle validation errors properly', async () => {\n+      mockReq.user.id = existingAgentAuthorId.toString(),\n+      mockReq.params.id = existingAgentId,\n+      mockReq.body = {\n+        model_parameters: 'invalid-not-an-object', // Should be an object\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(400),\n+      expect(mockRes.json).toHaveBeenCalledWith(\n+        expect.objectContaining({\n+          error: 'Invalid request data',\n+          details: expect.any(Array),\n+        }),\n+      ),\n+    }),\n+  }),\n+\n+  describe('Mass Assignment Attack Scenarios', () => {\n+    test('should prevent setting system fields during creation', async () => {\n+      const systemFields = {\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'System Fields Test',\n+\n+        // System fields that should never be settable by users\n+        __v: 99,\n+        _id: new mongoose.Types.ObjectId(),\n+        versions: [\n+          {\n+            name: 'Fake Version',\n+            provider: 'fake',\n+            model: 'fake-model',\n+          },\n+        ],\n+      },\n+\n+      mockReq.body = systemFields,\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+\n+      // Verify system fields were not affected\n+      expect(createdAgent.__v).not.toBe(99),\n+      expect(createdAgent.versions).toHaveLength(1), // Should only have the auto-created version\n+      expect(createdAgent.versions[0].name).toBe('System Fields Test'), // From actual creation\n+      expect(createdAgent.versions[0].provider).toBe('openai'), // From actual creation\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: createdAgent.id }),\n+      expect(agentInDb.__v).not.toBe(99),\n+    }),\n+\n+    test('should prevent privilege escalation through isCollaborative', async () => {\n+      // Create a non-collaborative agent\n+      const authorId = new mongoose.Types.ObjectId(),\n+      const agent = await Agent.create({\n+        id: `agent_${uuidv4()}`,\n+        name: 'Private Agent',\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        author: authorId,\n+        isCollaborative: false,\n+        versions: [\n+          {\n+            name: 'Private Agent',\n+            provider: 'openai',\n+            model: 'gpt-4',\n+            createdAt: new Date(),\n+            updatedAt: new Date(),\n+          },\n+        ],\n+      }),\n+\n+      // Try to make it collaborative as a different user\n+      const attackerId = new mongoose.Types.ObjectId().toString(),\n+      mockReq.user.id = attackerId,\n+      mockReq.params.id = agent.id,\n+      mockReq.body = {\n+        isCollaborative: true, // Trying to escalate privileges\n+      },\n+\n+      await updateAgentHandler(mockReq, mockRes),\n+\n+      // Should be rejected\n+      expect(mockRes.status).toHaveBeenCalledWith(403),\n+\n+      // Verify in database that it's still not collaborative\n+      const agentInDb = await Agent.findOne({ id: agent.id }),\n+      expect(agentInDb.isCollaborative).toBe(false),\n+    }),\n+\n+    test('should prevent author hijacking', async () => {\n+      const originalAuthorId = new mongoose.Types.ObjectId(),\n+      const attackerId = new mongoose.Types.ObjectId(),\n+\n+      // Admin creates an agent\n+      mockReq.user.id = originalAuthorId.toString(),\n+      mockReq.user.role = 'ADMIN',\n+      mockReq.body = {\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'Admin Agent',\n+        author: attackerId.toString(), // Trying to set different author\n+      },\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+\n+      // Author should be the actual user, not the attempted value\n+      expect(createdAgent.author.toString()).toBe(originalAuthorId.toString()),\n+      expect(createdAgent.author.toString()).not.toBe(attackerId.toString()),\n+\n+      // Verify in database\n+      const agentInDb = await Agent.findOne({ id: createdAgent.id }),\n+      expect(agentInDb.author.toString()).toBe(originalAuthorId.toString()),\n+    }),\n+\n+    test('should strip unknown fields to prevent future vulnerabilities', async () => {\n+      mockReq.body = {\n+        provider: 'openai',\n+        model: 'gpt-4',\n+        name: 'Future Proof Test',\n+\n+        // Unknown fields that might be added in future\n+        superAdminAccess: true,\n+        bypassAllChecks: true,\n+        internalFlag: 'secret',\n+        futureFeature: 'exploit',\n+      },\n+\n+      await createAgentHandler(mockReq, mockRes),\n+\n+      expect(mockRes.status).toHaveBeenCalledWith(201),\n+\n+      const createdAgent = mockRes.json.mock.calls[0][0],\n+\n+      // Verify unknown fields were stripped\n+      expect(createdAgent.superAdminAccess).toBeUndefined(),\n+      expect(createdAgent.bypassAllChecks).toBeUndefined(),\n+      expect(createdAgent.internalFlag).toBeUndefined(),\n+      expect(createdAgent.futureFeature).toBeUndefined(),\n+\n+      // Also check in database\n+      const agentInDb = await Agent.findOne({ id: createdAgent.id }).lean(),\n+      expect(agentInDb.superAdminAccess).toBeUndefined(),\n+      expect(agentInDb.bypassAllChecks).toBeUndefined(),\n+      expect(agentInDb.internalFlag).toBeUndefined(),\n+      expect(agentInDb.futureFeature).toBeUndefined(),\n+    }),\n+  }),\n+}),"
        },
        {
          "filename": "packages/api/src/agents/index.ts",
          "old_url": "https://raw.githubusercontent.com/danny-avila/librechat/e513f50c081505b2362be262c6cb38ad479c1653/packages/api/src/agents/index.ts",
          "new_url": "https://raw.githubusercontent.com/danny-avila/librechat/a37bf6719cfbc2de270f7d87b6b85d87cc1768db/packages/api/src/agents/index.ts",
          "diff": "@@ -2,3 +2,4 @@ export * from './config',\n export * from './memory',\n export * from './resources',\n export * from './run',\n+export * from './validation',"
        },
        {
          "filename": "packages/api/src/agents/validation.ts",
          "old_url": "https://raw.githubusercontent.com/danny-avila/librechat/e513f50c081505b2362be262c6cb38ad479c1653/packages/api/src/agents/validation.ts",
          "new_url": "https://raw.githubusercontent.com/danny-avila/librechat/a37bf6719cfbc2de270f7d87b6b85d87cc1768db/packages/api/src/agents/validation.ts",
          "diff": "@@ -0,0 +1,61 @@\n+import { z } from 'zod',\n+\n+/** Avatar schema shared between create and update */\n+export const agentAvatarSchema = z.object({\n+  filepath: z.string(),\n+  source: z.string(),\n+}),\n+\n+/** Base resource schema for tool resources */\n+export const agentBaseResourceSchema = z.object({\n+  file_ids: z.array(z.string()).optional(),\n+  files: z.array(z.any()).optional(), // Files are populated at runtime, not from user input\n+}),\n+\n+/** File resource schema extends base with vector_store_ids */\n+export const agentFileResourceSchema = agentBaseResourceSchema.extend({\n+  vector_store_ids: z.array(z.string()).optional(),\n+}),\n+\n+/** Tool resources schema matching AgentToolResources interface */\n+export const agentToolResourcesSchema = z\n+  .object({\n+    image_edit: agentBaseResourceSchema.optional(),\n+    execute_code: agentBaseResourceSchema.optional(),\n+    file_search: agentFileResourceSchema.optional(),\n+    ocr: agentBaseResourceSchema.optional(),\n+  })\n+  .optional(),\n+\n+/** Base agent schema with all common fields */\n+export const agentBaseSchema = z.object({\n+  name: z.string().nullable().optional(),\n+  description: z.string().nullable().optional(),\n+  instructions: z.string().nullable().optional(),\n+  avatar: agentAvatarSchema.nullable().optional(),\n+  model_parameters: z.record(z.unknown()).optional(),\n+  tools: z.array(z.string()).optional(),\n+  agent_ids: z.array(z.string()).optional(),\n+  end_after_tools: z.boolean().optional(),\n+  hide_sequential_outputs: z.boolean().optional(),\n+  artifacts: z.string().optional(),\n+  recursion_limit: z.number().optional(),\n+  conversation_starters: z.array(z.string()).optional(),\n+  tool_resources: agentToolResourcesSchema,\n+}),\n+\n+/** Create schema extends base with required fields for creation */\n+export const agentCreateSchema = agentBaseSchema.extend({\n+  provider: z.string(),\n+  model: z.string().nullable(),\n+  tools: z.array(z.string()).optional().default([]),\n+}),\n+\n+/** Update schema extends base with all fields optional and additional update-only fields */\n+export const agentUpdateSchema = agentBaseSchema.extend({\n+  provider: z.string().optional(),\n+  model: z.string().nullable().optional(),\n+  projectIds: z.array(z.string()).optional(),\n+  removeProjectIds: z.array(z.string()).optional(),\n+  isCollaborative: z.boolean().optional(),\n+}),"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59933",
        "https://github.com/libvips/libvips/commit/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1"
      ],
      "repo": "libvips",
      "commit_hash": "a58bfae9223a5466cc81ba9fe6dfb08233cf17d1",
      "commit_message": "validate poppler page size (#4620)  * validate poppler page size  Poppler can return pages less than 1 pixel wide or high. Check for this and flag an error.  Thanks Yang Luo, Riema Labs  * validate page size in svgload too  * add image sanity tests  * make vips_object_sanity() log an error",
      "files_changed": [
        {
          "filename": "ChangeLog",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/ChangeLog",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/ChangeLog",
          "diff": "@@ -1,6 +1,7 @@\n 8.17.2\n \n - rank: fix an off-by-one error [larsmaxfield]\n+- popplerload, svgload: validate page size [Yang Luo]\n - pdfiumload: allow both dpi and scale to be set [kleisauke]\n \n 7/7/25 8.17.1"
        },
        {
          "filename": "libvips/foreign/foreign.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/foreign/foreign.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/foreign/foreign.c",
          "diff": "@@ -1040,6 +1040,7 @@ vips_foreign_load_start(VipsImage *out, void *a, void *b)\n \t\t * If the load fails, we need to stop.\n \t\t */\n \t\tif (class->load(load) ||\n+\t\t\t!vips_object_sanity(VIPS_OBJECT(load->real)) ||\n \t\t\tvips_image_pio_input(load->real) ||\n \t\t\t!vips_foreign_load_iscompat(load->real, out)) {\n \t\t\tvips_operation_invalidate(VIPS_OPERATION(load)),\n@@ -1133,18 +1134,19 @@ vips_foreign_load_build(VipsObject *object)\n \n \tg_object_set(object, \"out\", vips_image_new(), NULL),\n \n-\tvips_image_set_string(load->out,\n-\t\tVIPS_META_LOADER, class->nickname),\n+\tvips_image_set_string(load->out, VIPS_META_LOADER, class->nickname),\n \n #ifdef DEBUG\n \tprintf(\"vips_foreign_load_build: triggering ->header\\n\"),\n #endif /*DEBUG*/\n \n \t/* Read the header into @out.\n \t */\n-\tif (fclass->header &&\n-\t\tfclass->header(load))\n-\t\treturn -1,\n+\tif (fclass->header) {\n+\t\tif (fclass->header(load) ||\n+\t\t\t!vips_object_sanity(VIPS_OBJECT(load->out)))\n+\t\t\treturn -1,\n+\t}\n \n \t/* If there's no ->load() method then the header read has done\n \t * everything. Otherwise, it's just set fields and we must also"
        },
        {
          "filename": "libvips/foreign/popplerload.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/foreign/popplerload.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/foreign/popplerload.c",
          "diff": "@@ -312,7 +312,6 @@ vips_foreign_load_pdf_header(VipsForeignLoad *load)\n \tVipsForeignLoadPdf *pdf = VIPS_FOREIGN_LOAD_PDF(load),\n \n \tint top,\n-\tint i,\n \n #ifdef DEBUG\n \tprintf(\"vips_foreign_load_pdf_header: %p\\n\", pdf),\n@@ -342,21 +341,28 @@ vips_foreign_load_pdf_header(VipsForeignLoad *load)\n \tpdf->image.top = 0,\n \tpdf->image.width = 0,\n \tpdf->image.height = 0,\n-\tfor (i = 0, i < pdf->n, i++) {\n+\tfor (int i = 0, i < pdf->n, i++) {\n \t\tdouble width,\n \t\tdouble height,\n \n \t\tif (vips_foreign_load_pdf_get_page(pdf, pdf->page_no + i))\n \t\t\treturn -1,\n+\n \t\tpoppler_page_get_size(pdf->page, &width, &height),\n \t\tpdf->pages[i].left = 0,\n \t\tpdf->pages[i].top = top,\n+\n \t\t/* We do round to nearest, in the same way that vips_resize()\n \t\t * does round to nearest. Without this, things like\n \t\t * shrink-on-load will break.\n \t\t */\n \t\tpdf->pages[i].width = rint(width * pdf->total_scale),\n \t\tpdf->pages[i].height = rint(height * pdf->total_scale),\n+\t\tif (pdf->pages[i].width <= 0 ||\n+\t\t\tpdf->pages[i].height <= 0) {\n+\t\t\tvips_error(class->nickname, \"%s\", _(\"zero-sized image\")),\n+\t\t\treturn -1,\n+\t\t}\n \n \t\tif (pdf->pages[i].width > pdf->image.width)\n \t\t\tpdf->image.width = pdf->pages[i].width,\n@@ -368,7 +374,7 @@ vips_foreign_load_pdf_header(VipsForeignLoad *load)\n \t/* If all pages are the same height, we can tag this as a toilet roll\n \t * image.\n \t */\n-\tfor (i = 1, i < pdf->n, i++)\n+\tfor (int i = 1, i < pdf->n, i++)\n \t\tif (pdf->pages[i].height != pdf->pages[0].height)\n \t\t\tbreak,\n "
        },
        {
          "filename": "libvips/foreign/svgload.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/foreign/svgload.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/foreign/svgload.c",
          "diff": "@@ -568,12 +568,19 @@ vips_foreign_load_svg_get_scaled_size(VipsForeignLoadSvg *svg,\n static int\n vips_foreign_load_svg_parse(VipsForeignLoadSvg *svg, VipsImage *out)\n {\n+\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS(svg),\n+\n \tint width,\n \tint height,\n \tdouble res,\n \n \tif (vips_foreign_load_svg_get_scaled_size(svg, &width, &height))\n \t\treturn -1,\n+\tif (width <= 0 ||\n+\t\theight <= 0) {\n+\t\tvips_error(class->nickname, \"%s\", _(\"zero-sized image\")),\n+\t\treturn -1,\n+\t}\n \n \t/* We need pixels/mm for vips.\n \t */\n@@ -583,7 +590,8 @@ vips_foreign_load_svg_parse(VipsForeignLoadSvg *svg, VipsImage *out)\n \t\twidth, height, 4,\n \t\tsvg->high_bitdepth ? VIPS_FORMAT_FLOAT : VIPS_FORMAT_UCHAR,\n \t\tVIPS_CODING_NONE,\n-\t\tsvg->high_bitdepth ? VIPS_INTERPRETATION_scRGB : VIPS_INTERPRETATION_sRGB,\n+\t\tsvg->high_bitdepth ?\n+\t\t\tVIPS_INTERPRETATION_scRGB : VIPS_INTERPRETATION_sRGB,\n \t\tres, res),\n \n \t/* We use a tilecache, so it's smalltile."
        },
        {
          "filename": "libvips/iofuncs/generate.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/iofuncs/generate.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/iofuncs/generate.c",
          "diff": "@@ -297,8 +297,8 @@ vips__demand_hint_array(VipsImage *image,\n \t */\n \tset_hint = hint,\n \tfor (i = 0, i < len, i++)\n-\t\tset_hint = (VipsDemandStyle) VIPS_MIN(\n-\t\t\t(int) set_hint, (int) in[i]->dhint),\n+\t\tset_hint = (VipsDemandStyle)\n+\t\t\tVIPS_MIN((int) set_hint, (int) in[i]->dhint),\n \n \timage->dhint = set_hint,\n \n@@ -365,6 +365,9 @@ int\n vips_image_pipeline_array(VipsImage *image,\n \tVipsDemandStyle hint, VipsImage **in)\n {\n+\tif (!vips_object_sanity(VIPS_OBJECT(image)))\n+\t\treturn -1,\n+\n \t/* This function can be called more than once per output image. For\n \t * example, jpeg header load will call this once on ->out to set the\n \t * default hint, then later call it again to connect the output image\n@@ -688,11 +691,12 @@ vips_image_generate(VipsImage *image,\n \tVIPS_DEBUG_MSG(\"vips_image_generate: %p\\n\", image),\n \n \tg_assert(generate_fn),\n-\tg_assert(vips_object_sanity(VIPS_OBJECT(image))),\n+\n+\tif (!vips_object_sanity(VIPS_OBJECT(image)))\n+\t\treturn -1,\n \n \tif (!image->hint_set) {\n-\t\tvips_error(\"vips_image_generate\",\n-\t\t\t\"%s\", _(\"demand hint not set\")),\n+\t\tvips_error(\"vips_image_generate\", \"%s\", _(\"demand hint not set\")),\n \t\treturn -1,\n \t}\n "
        },
        {
          "filename": "libvips/iofuncs/image.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/iofuncs/image.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/iofuncs/image.c",
          "diff": "@@ -615,8 +615,7 @@ vips_image_summary(VipsObject *object, VipsBuf *buf)\n \tif (vips_image_get_coding(image) == VIPS_CODING_NONE) {\n \t\tvips_buf_appendf(buf,\n \t\t\tg_dngettext(GETTEXT_PACKAGE,\n-\t\t\t\t\" %s, %d band, %s\",\n-\t\t\t\t\" %s, %d bands, %s\",\n+\t\t\t\t\" %s, %d band, %s\", \" %s, %d bands, %s\",\n \t\t\t\tvips_image_get_bands(image)),\n \t\t\tvips_enum_nick(VIPS_TYPE_BAND_FORMAT, vips_image_get_format(image)),\n \t\t\tvips_image_get_bands(image),\n@@ -625,8 +624,7 @@ vips_image_summary(VipsObject *object, VipsBuf *buf)\n \t}\n \telse {\n \t\tvips_buf_appendf(buf, \", %s\",\n-\t\t\tvips_enum_nick(VIPS_TYPE_CODING,\n-\t\t\t\tvips_image_get_coding(image))),\n+\t\t\tvips_enum_nick(VIPS_TYPE_CODING, vips_image_get_coding(image))),\n \t}\n \n \tif (vips_image_get_typeof(image, VIPS_META_LOADER) &&\n@@ -657,42 +655,40 @@ vips_image_sanity(VipsObject *object, VipsBuf *buf)\n {\n \tVipsImage *image = VIPS_IMAGE(object),\n \n-\t/* All 0 means im has been inited but never used.\n-\t */\n-\tif (image->Xsize != 0 ||\n-\t\timage->Ysize != 0 ||\n-\t\timage->Bands != 0) {\n-\t\tif (image->Xsize <= 0 ||\n-\t\t\timage->Ysize <= 0 ||\n-\t\t\timage->Bands <= 0)\n-\t\t\tvips_buf_appends(buf, \"bad dimensions\\n\"),\n-\t\tif (image->BandFmt < -1 ||\n-\t\t\timage->BandFmt > VIPS_FORMAT_DPCOMPLEX ||\n-\t\t\t(image->Coding != -1 &&\n-\t\t\t\timage->Coding != VIPS_CODING_NONE &&\n-\t\t\t\timage->Coding != VIPS_CODING_LABQ &&\n-\t\t\t\timage->Coding != VIPS_CODING_RAD) ||\n-\t\t\timage->Type >= VIPS_INTERPRETATION_LAST ||\n-\t\t\timage->dtype > VIPS_IMAGE_PARTIAL ||\n-\t\t\timage->dhint > VIPS_DEMAND_STYLE_ANY)\n-\t\t\tvips_buf_appends(buf, \"bad enum\\n\"),\n-\t\tif (image->Xres < 0 ||\n-\t\t\timage->Yres < 0)\n-\t\t\tvips_buf_appends(buf, \"bad resolution\\n\"),\n-\t}\n-\n-\t/* Must lock around inter-image links.\n+\tif (image->Xsize <= 0 ||\n+\t\timage->Ysize <= 0 ||\n+\t\timage->Bands <= 0)\n+\t\tvips_buf_appends(buf, \"bad dimensions\\n\"),\n+\tif (image->BandFmt < -1 ||\n+\t\timage->BandFmt > VIPS_FORMAT_DPCOMPLEX ||\n+\t\t(image->Coding != -1 &&\n+\t\t\timage->Coding != VIPS_CODING_NONE &&\n+\t\t\timage->Coding != VIPS_CODING_LABQ &&\n+\t\t\timage->Coding != VIPS_CODING_RAD) ||\n+\t\timage->Type >= VIPS_INTERPRETATION_LAST ||\n+\t\timage->dtype > VIPS_IMAGE_PARTIAL ||\n+\t\timage->dhint > VIPS_DEMAND_STYLE_ANY)\n+\t\tvips_buf_appends(buf, \"bad enum\\n\"),\n+\tif (image->Xres < 0 ||\n+\t\timage->Yres < 0)\n+\t\tvips_buf_appends(buf, \"bad resolution\\n\"),\n+\n+\t/* These checks are expensive -- only do in leakcheck mode.\n \t */\n-\tg_mutex_lock(&vips__global_lock),\n+\tif (vips__leak) {\n+\t\t/* Must lock around inter-image links.\n+\t\t */\n+\t\tg_mutex_lock(&vips__global_lock),\n \n-\tif (vips_slist_map2(image->upstream,\n-\t\t\t(VipsSListMap2Fn) vips_image_sanity_upstream, image, NULL))\n-\t\tvips_buf_appends(buf, \"upstream broken\\n\"),\n-\tif (vips_slist_map2(image->downstream,\n-\t\t\t(VipsSListMap2Fn) vips_image_sanity_downstream, image, NULL))\n-\t\tvips_buf_appends(buf, \"downstream broken\\n\"),\n+\t\tif (vips_slist_map2(image->upstream,\n+\t\t\t\t(VipsSListMap2Fn) vips_image_sanity_upstream, image, NULL))\n+\t\t\tvips_buf_appends(buf, \"upstream broken\\n\"),\n+\t\tif (vips_slist_map2(image->downstream,\n+\t\t\t\t(VipsSListMap2Fn) vips_image_sanity_downstream, image, NULL))\n+\t\t\tvips_buf_appends(buf, \"downstream broken\\n\"),\n \n-\tg_mutex_unlock(&vips__global_lock),\n+\t\tg_mutex_unlock(&vips__global_lock),\n+\t}\n \n \tVIPS_OBJECT_CLASS(vips_image_parent_class)->sanity(object, buf),\n }\n@@ -3148,7 +3144,8 @@ vips_image_hasalpha(VipsImage *image)\n int\n vips_image_write_prepare(VipsImage *image)\n {\n-\tg_assert(vips_object_sanity(VIPS_OBJECT(image))),\n+\tif (!vips_object_sanity(VIPS_OBJECT(image)))\n+\t\treturn -1,\n \n \tif (image->Xsize <= 0 ||\n \t\timage->Ysize <= 0 ||\n@@ -3416,7 +3413,8 @@ vips_image_wio_input(VipsImage *image)\n {\n \tVipsImage *t1,\n \n-\tg_assert(vips_object_sanity(VIPS_OBJECT(image))),\n+\tif (!vips_object_sanity(VIPS_OBJECT(image)))\n+\t\treturn -1,\n \n #ifdef DEBUG_IO\n \tprintf(\"vips_image_wio_input: wio input for %s\\n\",\n@@ -3644,7 +3642,8 @@ vips_image_inplace(VipsImage *image)\n int\n vips_image_pio_input(VipsImage *image)\n {\n-\tg_assert(vips_object_sanity(VIPS_OBJECT(image))),\n+\tif (!vips_object_sanity(VIPS_OBJECT(image)))\n+\t\treturn -1,\n \n #ifdef DEBUG_IO\n \tprintf(\"vips_image_pio_input: enabling partial input for %s\\n\","
        },
        {
          "filename": "libvips/iofuncs/object.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/iofuncs/object.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/iofuncs/object.c",
          "diff": "@@ -470,23 +470,18 @@ vips_object_print_name(VipsObject *object)\n gboolean\n vips_object_sanity(VipsObject *object)\n {\n-\tVipsObjectClass *class,\n-\tchar str[1000],\n-\tVipsBuf buf = VIPS_BUF_STATIC(str),\n-\n \tif (!object) {\n-\t\tprintf(\"vips_object_sanity: null object\\n\"),\n-\n+\t\tvips_error(\"vips_object_sanity\", _(\"null object\")),\n \t\treturn FALSE,\n \t}\n \n-\tclass = VIPS_OBJECT_GET_CLASS(object),\n+\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS(object),\n+\n+\tchar str[1000],\n+\tVipsBuf buf = VIPS_BUF_STATIC(str),\n \tclass->sanity(object, &buf),\n \tif (!vips_buf_is_empty(&buf)) {\n-\t\tprintf(\"sanity failure: \"),\n-\t\tvips_object_print_name(object),\n-\t\tprintf(\" %s\\n\", vips_buf_all(&buf)),\n-\n+\t\tvips_error(class->nickname, \"%s\", vips_buf_all(&buf)),\n \t\treturn FALSE,\n \t}\n "
        },
        {
          "filename": "libvips/iofuncs/sink.c",
          "old_url": "https://raw.githubusercontent.com/libvips/libvips/693d7fc0194ca2e2d62b28ad7dedc4d5a67094af/libvips/iofuncs/sink.c",
          "new_url": "https://raw.githubusercontent.com/libvips/libvips/a58bfae9223a5466cc81ba9fe6dfb08233cf17d1/libvips/iofuncs/sink.c",
          "diff": "@@ -474,7 +474,8 @@ vips_sink_tile(VipsImage *im,\n \tSink sink,\n \tint result,\n \n-\tg_assert(vips_object_sanity(VIPS_OBJECT(im))),\n+\tif (!vips_object_sanity(VIPS_OBJECT(im)))\n+\t\treturn -1,\n \n \t/* We don't use this, but make sure it's set in case any old binaries\n \t * are expecting it."
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59937",
        "https://github.com/wneessen/go-mail/commit/42e92cfe027be04aff72921adb0f72f11d517479"
      ],
      "repo": "go-mail",
      "commit_hash": "42e92cfe027be04aff72921adb0f72f11d517479",
      "commit_message": "Merge pull request #496 from wneessen/bugfix/495_mail-address-parsing  Fix vulnerability in mail address passing to the smtp client",
      "files_changed": [
        {
          "filename": "b64linebreaker.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/b64linebreaker.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/b64linebreaker.go",
          "diff": "@@ -42,7 +42,7 @@ type base64LineBreaker struct {\n func (l *base64LineBreaker) Write(data []byte) (numBytes int, err error) {\n \tif l.out == nil {\n \t\terr = errors.New(\"no io.Writer set for base64LineBreaker\")\n-\t\treturn\n+\t\treturn numBytes, err\n \t}\n \tif l.used+len(data) < MaxBodyLength {\n \t\tcopy(l.line[l.used:], data)\n@@ -52,25 +52,25 @@ func (l *base64LineBreaker) Write(data []byte) (numBytes int, err error) {\n \n \t_, err = l.out.Write(l.line[0:l.used])\n \tif err != nil {\n-\t\treturn\n+\t\treturn numBytes, err\n \t}\n \texcess := MaxBodyLength - l.used\n \tl.used = 0\n \n \tnumBytes, err = l.out.Write(data[0:excess])\n \tif err != nil {\n-\t\treturn\n+\t\treturn numBytes, err\n \t}\n \n \t_, err = l.out.Write(newlineBytes)\n \tif err != nil {\n-\t\treturn\n+\t\treturn numBytes, err\n \t}\n \n \tvar n int\n \tn, err = l.Write(data[excess:]) // recurse\n \tnumBytes += n\n-\treturn\n+\treturn numBytes, err\n }\n \n // Close finalizes the base64LineBreaker, writing any remaining buffered data and appending a newline.\n@@ -85,10 +85,10 @@ func (l *base64LineBreaker) Close() (err error) {\n \tif l.used > 0 {\n \t\t_, err = l.out.Write(l.line[0:l.used])\n \t\tif err != nil {\n-\t\t\treturn\n+\t\t\treturn err\n \t\t}\n \t\t_, err = l.out.Write(newlineBytes)\n \t}\n \n-\treturn\n+\treturn err\n }"
        },
        {
          "filename": "client.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/client.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/client.go",
          "diff": "@@ -1261,7 +1261,7 @@ func (c *Client) SendWithSMTPClient(client *smtp.Client, messages ...*Msg) (retu\n \t\t\tReason: ErrConnCheck, errlist: []error{err}, isTemp: isTempError(err),\n \t\t\terrcode: errorCode(err), enhancedStatusCode: enhancedStatusCode(err, escSupport),\n \t\t}\n-\t\treturn\n+\t\treturn returnErr\n \t}\n \n \tvar errs []error\n@@ -1279,7 +1279,7 @@ func (c *Client) SendWithSMTPClient(client *smtp.Client, messages ...*Msg) (retu\n \t\t}\n \t}\n \n-\treturn\n+\treturn returnErr\n }\n \n // auth attempts to authenticate the client using SMTP AUTH mechanisms. It checks the connection,"
        },
        {
          "filename": "doc.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/doc.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/doc.go",
          "diff": "@@ -11,4 +11,4 @@ package mail\n \n // VERSION indicates the current version of the package. It is also attached to the default user\n // agent string.\n-const VERSION = \"0.7.0\"\n+const VERSION = \"0.7.1\""
        },
        {
          "filename": "eml.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/eml.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/eml.go",
          "diff": "@@ -538,7 +538,7 @@ func parseMultiPartHeader(multiPartHeader string) (header string, optional map[s\n \theaderSplit := strings.Split(multiPartHeader, \",\")\n \theader = headerSplit[0]\n \tif len(headerSplit) == 1 {\n-\t\treturn\n+\t\treturn header, optional\n \t}\n \tfor _, opt := range headerSplit[1:] {\n \t\toptString := strings.TrimLeft(opt, \" \")\n@@ -547,7 +547,7 @@ func parseMultiPartHeader(multiPartHeader string) (header string, optional map[s\n \t\t\toptional[optSplit[0]] = optSplit[1]\n \t\t}\n \t}\n-\treturn\n+\treturn header, optional\n }\n \n // parseEMLAttachmentEmbed parses a multipart that is an attachment or embed."
        },
        {
          "filename": "msg.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/msg.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/msg.go",
          "diff": "@@ -1495,10 +1495,12 @@ func (m *Msg) GetSender(useFullAddr bool) (string, error) {\n \t\t\treturn \"\", ErrNoFromAddress\n \t\t}\n \t}\n-\tif useFullAddr {\n-\t\treturn from[0].String(), nil\n+\n+\taddr := from[0]\n+\tif !useFullAddr {\n+\t\taddr.Name = \"\"\n \t}\n-\treturn from[0].Address, nil\n+\treturn addr.String(), nil\n }\n \n // GetRecipients returns a list of the currently set \"TO\", \"CC\", and \"BCC\" addresses for the Msg.\n@@ -1522,7 +1524,8 @@ func (m *Msg) GetRecipients() ([]string, error) {\n \t\t\tcontinue\n \t\t}\n \t\tfor _, r := range addresses {\n-\t\t\trcpts = append(rcpts, r.Address)\n+\t\t\tr.Name = \"\"\n+\t\t\trcpts = append(rcpts, r.String())\n \t\t}\n \t}\n \tif len(rcpts) <= 0 {"
        },
        {
          "filename": "msg_test.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/msg_test.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/msg_test.go",
          "diff": "@@ -2539,8 +2539,8 @@ func TestMsg_GetSender(t *testing.T) {\n \t\tif err != nil {\n \t\t\tt.Errorf(\"failed to get sender: %s\", err)\n \t\t}\n-\t\tif !strings.EqualFold(sender, \"toni.tester@example.com\") {\n-\t\t\tt.Errorf(\"expected sender not returned. Want: %s, got: %s\", \"toni.tester@example.com\", sender)\n+\t\tif !strings.EqualFold(sender, \"<toni.tester@example.com>\") {\n+\t\t\tt.Errorf(\"expected sender not returned. Want: %s, got: %s\", \"<toni.tester@example.com>\", sender)\n \t\t}\n \t})\n \tt.Run(\"GetSender with envelope from only (full address)\", func(t *testing.T) {\n@@ -2571,8 +2571,8 @@ func TestMsg_GetSender(t *testing.T) {\n \t\tif err != nil {\n \t\t\tt.Errorf(\"failed to get sender: %s\", err)\n \t\t}\n-\t\tif !strings.EqualFold(sender, \"toni.tester@example.com\") {\n-\t\t\tt.Errorf(\"expected sender not returned. Want: %s, got: %s\", \"toni.tester@example.com\", sender)\n+\t\tif !strings.EqualFold(sender, \"<toni.tester@example.com>\") {\n+\t\t\tt.Errorf(\"expected sender not returned. Want: %s, got: %s\", \"<toni.tester@example.com>\", sender)\n \t\t}\n \t})\n \tt.Run(\"GetSender with from only (full address)\", func(t *testing.T) {\n@@ -2606,8 +2606,8 @@ func TestMsg_GetSender(t *testing.T) {\n \t\tif err != nil {\n \t\t\tt.Errorf(\"failed to get sender: %s\", err)\n \t\t}\n-\t\tif !strings.EqualFold(sender, \"toni.tester@example.com\") {\n-\t\t\tt.Errorf(\"expected sender not returned. Want: %s, got: %s\", \"toni.tester@example.com\", sender)\n+\t\tif !strings.EqualFold(sender, \"<toni.tester@example.com>\") {\n+\t\t\tt.Errorf(\"expected sender not returned. Want: %s, got: %s\", \"<toni.tester@example.com>\", sender)\n \t\t}\n \t})\n \tt.Run(\"GetSender with envelope from and from (full address)\", func(t *testing.T) {\n@@ -2661,9 +2661,67 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 1 {\n \t\t\tt.Fatalf(\"expected 1 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n+\t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n+\t\t}\n+\t})\n+\tt.Run(\"GetRecipients with quoted local-part (issue #495)\", func(t *testing.T) {\n+\t\tmessage := NewMsg()\n+\t\tif message == nil {\n+\t\t\tt.Fatal(\"message is nil\")\n+\t\t}\n+\t\taddr := `\"toni.tester@example.com> ORCPT=admin@admin.com\"@example.com`\n+\t\tif err := message.To(addr), err != nil {\n+\t\t\tt.Fatalf(\"failed to set to address: %s\", err)\n+\t\t}\n+\t\trcpts, err := message.GetRecipients()\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"failed to get recipients: %s\", err)\n+\t\t}\n+\t\tif len(rcpts) != 1 {\n+\t\t\tt.Fatalf(\"expected 1 recipient, got: %d\", len(rcpts))\n+\t\t}\n+\t\tif !strings.EqualFold(rcpts[0], `<\"toni.tester@example.com> ORCPT=admin@admin.com\"@example.com>`) {\n+\t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n+\t\t\t\t`<\"toni.tester@example.com> ORCPT=admin@admin.com\"@example.com>`, rcpts[0])\n+\t\t}\n+\t})\n+\tt.Run(\"GetRecipients with quoted local-part in to,cc and bcc (issue #495)\", func(t *testing.T) {\n+\t\tmessage := NewMsg()\n+\t\tif message == nil {\n+\t\t\tt.Fatal(\"message is nil\")\n+\t\t}\n+\t\taddr := `\"toni.tester@example.com> ORCPT=admin@admin.com\"@example.com`\n+\t\tif err := message.To(addr), err != nil {\n+\t\t\tt.Fatalf(\"failed to set to address: %s\", err)\n+\t\t}\n+\t\taddr = `\"tina.tester@example.com> ORCPT=admin@admin.com\"@example.com`\n+\t\tif err := message.Cc(addr), err != nil {\n+\t\t\tt.Fatalf(\"failed to set to address: %s\", err)\n+\t\t}\n+\t\taddr = `\"troy.tester@example.com> ORCPT=admin@admin.com\"@example.com`\n+\t\tif err := message.Bcc(addr), err != nil {\n+\t\t\tt.Fatalf(\"failed to set to address: %s\", err)\n+\t\t}\n+\t\trcpts, err := message.GetRecipients()\n+\t\tif err != nil {\n+\t\t\tt.Errorf(\"failed to get recipients: %s\", err)\n+\t\t}\n+\t\tif len(rcpts) != 3 {\n+\t\t\tt.Fatalf(\"expected 3 recipient, got: %d\", len(rcpts))\n+\t\t}\n+\t\tif !strings.EqualFold(rcpts[0], `<\"toni.tester@example.com> ORCPT=admin@admin.com\"@example.com>`) {\n+\t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n+\t\t\t\t`<\"toni.tester@example.com> ORCPT=admin@admin.com\"@example.com>`, rcpts[0])\n+\t\t}\n+\t\tif !strings.EqualFold(rcpts[1], `<\"tina.tester@example.com> ORCPT=admin@admin.com\"@example.com>`) {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t`<\"tina.tester@example.com> ORCPT=admin@admin.com\"@example.com>`, rcpts[1])\n+\t\t}\n+\t\tif !strings.EqualFold(rcpts[2], `<\"troy.tester@example.com> ORCPT=admin@admin.com\"@example.com>`) {\n+\t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n+\t\t\t\t`<\"troy.tester@example.com> ORCPT=admin@admin.com\"@example.com>`, rcpts[2])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with only cc\", func(t *testing.T) {\n@@ -2681,9 +2739,9 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 1 {\n \t\t\tt.Fatalf(\"expected 1 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with only bcc\", func(t *testing.T) {\n@@ -2701,9 +2759,9 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 1 {\n \t\t\tt.Fatalf(\"expected 1 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with to and cc\", func(t *testing.T) {\n@@ -2724,13 +2782,13 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 2 {\n \t\t\tt.Fatalf(\"expected 2 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[1], \"tina.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[1], \"<tina.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"tina.tester@example.com\", rcpts[1])\n+\t\t\t\t\"<tina.tester@example.com>\", rcpts[1])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with to and bcc\", func(t *testing.T) {\n@@ -2751,13 +2809,13 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 2 {\n \t\t\tt.Fatalf(\"expected 2 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[1], \"tina.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[1], \"<tina.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"tina.tester@example.com\", rcpts[1])\n+\t\t\t\t\"<tina.tester@example.com>\", rcpts[1])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with cc and bcc\", func(t *testing.T) {\n@@ -2778,13 +2836,13 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 2 {\n \t\t\tt.Fatalf(\"expected 2 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[1], \"tina.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[1], \"<tina.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"tina.tester@example.com\", rcpts[1])\n+\t\t\t\t\"<tina.tester@example.com>\", rcpts[1])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with to, cc and bcc\", func(t *testing.T) {\n@@ -2808,17 +2866,17 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t\tif len(rcpts) != 3 {\n \t\t\tt.Fatalf(\"expected 3 recipient, got: %d\", len(rcpts))\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[0], \"toni.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[0], \"<toni.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"toni.tester@example.com\", rcpts[0])\n+\t\t\t\t\"<toni.tester@example.com>\", rcpts[0])\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[1], \"tina.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[1], \"<tina.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"tina.tester@example.com\", rcpts[1])\n+\t\t\t\t\"<tina.tester@example.com>\", rcpts[1])\n \t\t}\n-\t\tif !strings.EqualFold(rcpts[2], \"tom.tester@example.com\") {\n+\t\tif !strings.EqualFold(rcpts[2], \"<tom.tester@example.com>\") {\n \t\t\tt.Errorf(\"expected recipient not returned. Want: %s, got: %s\",\n-\t\t\t\t\"tina.tester@example.com\", rcpts[2])\n+\t\t\t\t\"<tina.tester@example.com>\", rcpts[2])\n \t\t}\n \t})\n \tt.Run(\"GetRecipients with no recipients\", func(t *testing.T) {\n@@ -2836,6 +2894,190 @@ func TestMsg_GetRecipients(t *testing.T) {\n \t})\n }\n \n+func TestMsg_addressCmdInjectsions(t *testing.T) {\n+\ttests := []struct {\n+\t\tname       string\n+\t\tpayload    string\n+\t\tshouldFail bool\n+\t}{\n+\t\t// Basic argument-injection (expected to fail)\n+\t\t{\"ORCPT-arg\", `\"toni.tester@example.com> ORCPT=admin@example.com\"@example.com`, false},\n+\t\t{\"SIZE-arg\", `\"toni.tester@example.com> SIZE=99999\"@example.com`, false},\n+\t\t{\"AUTH-arg\", `\"toni.tester@example.com> AUTH=PLAIN\"@example.com`, false},\n+\n+\t\t// whitespace / separator variants\n+\t\t{\"double-space\", `\"toni.tester@example.com>  ORCPT=admin@example.com\"@example.com`, false},\n+\t\t{\"tab-separator\", `\"toni.tester@example.com>\\tORCPT=admin@example.com\"@example.com`, false},\n+\n+\t\t// quoted/escape tricks\n+\t\t{\"quoted-close-space\", `\"toni.tester@example.com\\\"> ORCPT=admin@example.com\"@example.com`, false},\n+\t\t{\"escaped-backslash\", `\"toni.tester@example.com\\\\\"> ORCPT=admin@example.com\"@example.com`, true},\n+\n+\t\t// missing / mis-balanced angle brackets\n+\t\t{\"unbalanced-close\", `toni.tester@example.com> ORCPT=admin@example.com@example.com`, true},\n+\t\t{\"leading-bracket\", `<toni.tester@example.com> ORCPT=admin@example.com@example.com`, true},\n+\t\t{\"no-brackets\", `toni.tester@example.com ORCPT=admin@example.com@example.com`, true},\n+\n+\t\t// comments / RFC-style\n+\t\t{\"comment-insert\", `(comment)toni.tester@example.com> ORCPT=admin@example.com\"@example.com`, true},\n+\t\t{\"comment-inside-quote\", `\"toni.tester@example.com (orcd) > ORCPT=admin@example.com\"@example.com`, false},\n+\n+\t\t// percent-encoded attempts\n+\t\t{\"percent-encoded-sep\", `\"toni.tester@example.com%3E%20ORCPT=admin@example.com\"@example.com`, false},\n+\t\t{\"percent-encoded-crlf\", `\"toni.tester@example.com%0d%0aRCPT TO:<other@example.com>\"@example.com`, false},\n+\n+\t\t// null / control byte insertion\n+\t\t{\"null-byte\", `\"toni.tester@example.com\\000> ORCPT=admin@example.com\"@example.com`, false},\n+\n+\t\t// explicit CRLF-injection attempts\n+\t\t{\"crlf-rcpt\", `\"toni.tester@example.com\">\\r\\nRCPT TO:<attacker@example.com>\"@example.com`, true},\n+\t\t{\"crlf-mailfrom\", `\"toni.tester@example.com\">\\r\\nMAIL FROM:<attacker@example.com>\"@example.com`, true},\n+\n+\t\t// folding whitespace / long-wrapping\n+\t\t{\"folding-ws\", `\"toni.tester@example.com> \\r\\n\\tORCPT=admin@example.com\"@example.com`, false},\n+\n+\t\t// unicode / homoglyphs\n+\t\t{\"unicode-fullwidth\", `\"toni.tester@example.com> ORCPT=admin@\uff45xample.com\"@example.com`, false},\n+\t\t{\"unicode-hidden\", `\"toni.tester@example.com> ORCPT=admin@exam` + \"\\u200c\" + `ple.com\"@example.com`, false},\n+\n+\t\t// multiple @ / nested-at attempts\n+\t\t{\"nested-at\", `\"toni.tester@example.com> ORCPT=admin@sub@example.com\"@example.com`, false},\n+\t\t{\"double-at\", `\"toni.tester@example.com> ORCPT=admin@@example.com\"@example.com`, false},\n+\n+\t\t// long / overflow-ish\n+\t\t{\"long-localpart\", `\"toni.tester@example.comAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA> ORCPT=admin@example.com\"@example.com`, false},\n+\n+\t\t// safe detection-only marker\n+\t\t{\"detection-marker\", `\"toni.tester@example.com> X-INJECT-TEST=smuggle-detect@example.com\"@example.com`, false},\n+\t}\n+\n+\tt.Run(\"address command injects in recipients\", func(t *testing.T) {\n+\t\tfor _, tc := range tests {\n+\t\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\t\tmessage := NewMsg()\n+\t\t\t\tif message == nil {\n+\t\t\t\t\tt.Fatal(\"message is nil\")\n+\t\t\t\t}\n+\t\t\t\terr := message.To(tc.payload)\n+\t\t\t\tif err != nil && !tc.shouldFail {\n+\t\t\t\t\tt.Errorf(\"failed to set to address: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif err == nil && tc.shouldFail {\n+\t\t\t\t\tt.Errorf(\"setting address was supposed to fail but didn't\")\n+\t\t\t\t}\n+\t\t\t\tif tc.shouldFail {\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\n+\t\t\t\taddr, err := mail.ParseAddress(tc.payload)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to parse address payload: %s\", err)\n+\t\t\t\t}\n+\t\t\t\trcpts, err := message.GetRecipients()\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to get recipient: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif len(rcpts) != 1 {\n+\t\t\t\t\tt.Fatalf(\"expected 1 recipient, got: %d\", len(rcpts))\n+\t\t\t\t}\n+\t\t\t\tif !strings.EqualFold(rcpts[0], addr.String()) {\n+\t\t\t\t\tt.Errorf(\"recipients don't match, expected: %s, got: %s\", addr.String(), rcpts[0])\n+\t\t\t\t}\n+\t\t\t})\n+\t\t}\n+\t})\n+\tt.Run(\"address command injects in sender (from)\", func(t *testing.T) {\n+\t\tfor _, tc := range tests {\n+\t\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\t\tmessage := NewMsg()\n+\t\t\t\tif message == nil {\n+\t\t\t\t\tt.Fatal(\"message is nil\")\n+\t\t\t\t}\n+\t\t\t\terr := message.From(tc.payload)\n+\t\t\t\tif err != nil && !tc.shouldFail {\n+\t\t\t\t\tt.Errorf(\"failed to set to address: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif err == nil && tc.shouldFail {\n+\t\t\t\t\tt.Errorf(\"setting address was supposed to fail but didn't\")\n+\t\t\t\t}\n+\t\t\t\tif tc.shouldFail {\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\n+\t\t\t\taddr, err := mail.ParseAddress(tc.payload)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to parse address payload: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tfrom, err := message.GetSender(false)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to get recipient: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif from == \"\" {\n+\t\t\t\t\tt.Fatal(\"expected sender, got empty string\")\n+\t\t\t\t}\n+\t\t\t\tif !strings.EqualFold(from, addr.String()) {\n+\t\t\t\t\tt.Errorf(\"sender don't match, expected: %s, got: %s\", addr.String(), from)\n+\t\t\t\t}\n+\t\t\t\tfrom, err = message.GetSender(true)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to get recipient: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif from == \"\" {\n+\t\t\t\t\tt.Fatal(\"expected sender, got empty string\")\n+\t\t\t\t}\n+\t\t\t\tif !strings.EqualFold(from, addr.String()) {\n+\t\t\t\t\tt.Errorf(\"sender don't match, expected: %s, got: %s\", addr.String(), from)\n+\t\t\t\t}\n+\t\t\t})\n+\t\t}\n+\t})\n+\tt.Run(\"address command injects in sender (envelope-from)\", func(t *testing.T) {\n+\t\tfor _, tc := range tests {\n+\t\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\t\tmessage := NewMsg()\n+\t\t\t\tif message == nil {\n+\t\t\t\t\tt.Fatal(\"message is nil\")\n+\t\t\t\t}\n+\t\t\t\terr := message.EnvelopeFrom(tc.payload)\n+\t\t\t\tif err != nil && !tc.shouldFail {\n+\t\t\t\t\tt.Errorf(\"failed to set to address: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif err == nil && tc.shouldFail {\n+\t\t\t\t\tt.Errorf(\"setting address was supposed to fail but didn't\")\n+\t\t\t\t}\n+\t\t\t\tif tc.shouldFail {\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\n+\t\t\t\taddr, err := mail.ParseAddress(tc.payload)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to parse address payload: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tfrom, err := message.GetSender(false)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to get recipient: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif from == \"\" {\n+\t\t\t\t\tt.Fatal(\"expected sender, got empty string\")\n+\t\t\t\t}\n+\t\t\t\tif !strings.EqualFold(from, addr.String()) {\n+\t\t\t\t\tt.Errorf(\"sender don't match, expected: %s, got: %s\", addr.String(), from)\n+\t\t\t\t}\n+\t\t\t\tfrom, err = message.GetSender(true)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tt.Errorf(\"failed to get recipient: %s\", err)\n+\t\t\t\t}\n+\t\t\t\tif from == \"\" {\n+\t\t\t\t\tt.Fatal(\"expected sender, got empty string\")\n+\t\t\t\t}\n+\t\t\t\tif !strings.EqualFold(from, addr.String()) {\n+\t\t\t\t\tt.Errorf(\"sender don't match, expected: %s, got: %s\", addr.String(), from)\n+\t\t\t\t}\n+\t\t\t})\n+\t\t}\n+\t})\n+}\n+\n func TestMsg_GetAddrHeader(t *testing.T) {\n \tt.Run(\"GetAddrHeader with valid address (from)\", func(t *testing.T) {\n \t\tmessage := NewMsg()"
        },
        {
          "filename": "smtp/smtp.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/smtp/smtp.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/smtp/smtp.go",
          "diff": "@@ -266,10 +266,10 @@ func (c *Client) TLSConnectionState() (state tls.ConnectionState, ok bool) {\n \n \ttc, ok := c.conn.(*tls.Conn)\n \tif !ok {\n-\t\treturn\n+\t\treturn state, ok\n \t}\n \tstate, ok = tc.ConnectionState(), true\n-\treturn\n+\treturn state, ok\n }\n \n // Verify checks the validity of an email address on the server.\n@@ -368,7 +368,7 @@ func (c *Client) Mail(from string) error {\n \tif err := c.hello(), err != nil {\n \t\treturn err\n \t}\n-\tcmdStr := \"MAIL FROM:<%s>\"\n+\tcmdStr := \"MAIL FROM:%s\"\n \n \tc.mutex.RLock()\n \tif c.ext != nil {\n@@ -402,10 +402,10 @@ func (c *Client) Rcpt(to string) error {\n \tc.mutex.RUnlock()\n \n \tif ok && c.dsnrntype != \"\" {\n-\t\t_, _, err := c.cmd(25, \"RCPT TO:<%s> NOTIFY=%s\", to, c.dsnrntype)\n+\t\t_, _, err := c.cmd(25, \"RCPT TO:%s NOTIFY=%s\", to, c.dsnrntype)\n \t\treturn err\n \t}\n-\t_, _, err := c.cmd(25, \"RCPT TO:<%s>\", to)\n+\t_, _, err := c.cmd(25, \"RCPT TO:%s\", to)\n \treturn err\n }\n \n@@ -432,7 +432,7 @@ func (d *DataCloser) Write(p []byte) (n int, err error) {\n \td.c.mutex.Lock()\n \tn, err = d.WriteCloser.Write(p)\n \td.c.mutex.Unlock()\n-\treturn\n+\treturn n, err\n }\n \n // ServerResponse returns the response that was returned by the server after the DataCloser has"
        },
        {
          "filename": "smtp/smtp_test.go",
          "old_url": "https://raw.githubusercontent.com/wneessen/go-mail/ac1eb03d39bcbfe8a8441c3716865e18c6355c8c/smtp/smtp_test.go",
          "new_url": "https://raw.githubusercontent.com/wneessen/go-mail/42e92cfe027be04aff72921adb0f72f11d517479/smtp/smtp_test.go",
          "diff": "@@ -30,6 +30,7 @@ import (\n \t\"hash\"\n \t\"io\"\n \t\"net\"\n+\tnetmail \"net/mail\"\n \t\"os\"\n \t\"strconv\"\n \t\"strings\"\n@@ -2261,7 +2262,11 @@ func TestClient_Mail(t *testing.T) {\n \t\t\t\tt.Errorf(\"failed to close client: %s\", err)\n \t\t\t}\n \t\t})\n-\t\tif err = client.Mail(\"valid-from@domain.tld\"), err != nil {\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\tif err = client.Mail(fromAddr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set mail from address: %s\", err)\n \t\t}\n \t})\n@@ -2358,7 +2363,11 @@ func TestClient_Mail(t *testing.T) {\n \t\t\t\tt.Errorf(\"failed to close client: %s\", err)\n \t\t\t}\n \t\t})\n-\t\tif err = client.Mail(\"valid-from@domain.tld\"), err != nil {\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\tif err = client.Mail(fromAddr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set mail from address: %s\", err)\n \t\t}\n \t\texpected := \"MAIL FROM:<valid-from@domain.tld> BODY=8BITMIME\"\n@@ -2398,7 +2407,11 @@ func TestClient_Mail(t *testing.T) {\n \t\t\t\tt.Errorf(\"failed to close client: %s\", err)\n \t\t\t}\n \t\t})\n-\t\tif err = client.Mail(\"valid-from@domain.tld\"), err != nil {\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\tif err = client.Mail(fromAddr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set mail from address: %s\", err)\n \t\t}\n \t\texpected := \"MAIL FROM:<valid-from@domain.tld> SMTPUTF8\"\n@@ -2438,7 +2451,11 @@ func TestClient_Mail(t *testing.T) {\n \t\t\t\tt.Errorf(\"failed to close client: %s\", err)\n \t\t\t}\n \t\t})\n-\t\tif err = client.Mail(\"valid-from+\ud83d\udce7@domain.tld\"), err != nil {\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from+\ud83d\udce7@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\tif err = client.Mail(fromAddr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set mail from address: %s\", err)\n \t\t}\n \t\texpected := \"MAIL FROM:<valid-from+\ud83d\udce7@domain.tld> SMTPUTF8\"\n@@ -2479,7 +2496,11 @@ func TestClient_Mail(t *testing.T) {\n \t\t\t}\n \t\t})\n \t\tclient.dsnmrtype = \"FULL\"\n-\t\tif err = client.Mail(\"valid-from@domain.tld\"), err != nil {\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\tif err = client.Mail(fromAddr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set mail from address: %s\", err)\n \t\t}\n \t\texpected := \"MAIL FROM:<valid-from@domain.tld> RET=FULL\"\n@@ -2520,7 +2541,11 @@ func TestClient_Mail(t *testing.T) {\n \t\t\t}\n \t\t})\n \t\tclient.dsnmrtype = \"FULL\"\n-\t\tif err = client.Mail(\"valid-from@domain.tld\"), err != nil {\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\tif err = client.Mail(fromAddr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set mail from address: %s\", err)\n \t\t}\n \t\texpected := \"MAIL FROM:<valid-from@domain.tld> BODY=8BITMIME SMTPUTF8 RET=FULL\"\n@@ -2560,7 +2585,11 @@ func TestClient_Rcpt(t *testing.T) {\n \t\t\t\tt.Errorf(\"failed to close client: %s\", err)\n \t\t\t}\n \t\t})\n-\t\tif err = client.Rcpt(\"valid-to@domain.tld\"), err != nil {\n+\t\taddr, err := netmail.ParseAddress(\"valid-to@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse recipient address: %s\", err)\n+\t\t}\n+\t\tif err = client.Rcpt(addr.String()), err != nil {\n \t\t\tt.Errorf(\"failed to set recipient address: %s\", err)\n \t\t}\n \t})\n@@ -2626,7 +2655,11 @@ func TestClient_Rcpt(t *testing.T) {\n \t\t\tt.Fatalf(\"failed to send hello to test server: %s\", err)\n \t\t}\n \t\tclient.dsnrntype = \"SUCCESS\"\n-\t\tif err = client.Rcpt(\"valid-to@domain.tld\"), err == nil {\n+\t\taddr, err := netmail.ParseAddress(\"valid-to@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse recipient address: %s\", err)\n+\t\t}\n+\t\tif err = client.Rcpt(addr.String()), err == nil {\n \t\t\tt.Error(\"recpient address with newlines should fail\")\n \t\t}\n \t\texpected := \"RCPT TO:<valid-to@domain.tld> NOTIFY=SUCCESS\"\n@@ -3006,8 +3039,16 @@ func TestSendMail(t *testing.T) {\n \t\t\tconfig.RootCAs = testConfig.RootCAs\n \t\t\tconfig.Certificates = testConfig.Certificates\n \t\t}\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n \t\tauth := LoginAuth(\"username\", \"password\", TestServerAddr, false)\n-\t\tif err := SendMail(addr, auth, \"valid-from@domain.tld\", []string{\"valid-to@domain.tld\"},\n+\t\ttoAddr, err := netmail.ParseAddress(\"valid-to@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse recipient address: %s\", err)\n+\t\t}\n+\t\tif err := SendMail(addr, auth, fromAddr.String(), []string{toAddr.String()},\n \t\t\t[]byte(\"test message\")), err != nil {\n \t\t\tt.Fatalf(\"failed to send mail: %s\", err)\n \t\t}\n@@ -3090,8 +3131,16 @@ Subject: Hooray for Go\n Line 1\n .Leading dot line .\n Goodbye.`)\n+\t\tfromAddr, err := netmail.ParseAddress(\"valid-from@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse from address: %s\", err)\n+\t\t}\n+\t\ttoAddr, err := netmail.ParseAddress(\"valid-to@domain.tld\")\n+\t\tif err != nil {\n+\t\t\tt.Fatalf(\"failed to parse recipient address: %s\", err)\n+\t\t}\n \t\tauth := LoginAuth(\"username\", \"password\", TestServerAddr, false)\n-\t\tif err := SendMail(addr, auth, \"valid-from@domain.tld\", []string{\"valid-to@domain.tld\"}, message), err != nil {\n+\t\tif err = SendMail(addr, auth, fromAddr.String(), []string{toAddr.String()}, message), err != nil {\n \t\t\tt.Fatalf(\"failed to send mail: %s\", err)\n \t\t}\n \t\tprops.BufferMutex.RLock()"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59940",
        "https://github.com/mondeja/mkdocs-include-markdown-plugin/commit/7466d67aa0de8ffbc427204ad2475fed07678915"
      ],
      "repo": "mkdocs-include-markdown-plugin",
      "commit_hash": "7466d67aa0de8ffbc427204ad2475fed07678915",
      "commit_message": "Escape placeholders to avoid input collisions (#277)",
      "files_changed": [
        {
          "filename": "pyproject.toml",
          "old_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/1ae8fca510cb5b18f164aaefb855a07f522ec8ff/pyproject.toml",
          "new_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/7466d67aa0de8ffbc427204ad2475fed07678915/pyproject.toml",
          "diff": "@@ -1,6 +1,6 @@\n [project]\n name = \"mkdocs-include-markdown-plugin\"\n-version = \"7.1.7\"\n+version = \"7.1.8\"\n description = \"Mkdocs Markdown includer plugin.\"\n readme = \"README.md\"\n license = \"Apache-2.0\""
        },
        {
          "filename": "src/mkdocs_include_markdown_plugin/event.py",
          "old_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/1ae8fca510cb5b18f164aaefb855a07f522ec8ff/src/mkdocs_include_markdown_plugin/event.py",
          "new_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/7466d67aa0de8ffbc427204ad2475fed07678915/src/mkdocs_include_markdown_plugin/event.py",
          "diff": "@@ -28,6 +28,11 @@\n )\n from mkdocs_include_markdown_plugin.files_watcher import FilesWatcher\n from mkdocs_include_markdown_plugin.logger import logger\n+from mkdocs_include_markdown_plugin.placeholders import (\n+    escape_placeholders,\n+    save_placeholder,\n+    unescape_placeholders,\n+)\n \n \n if TYPE_CHECKING:  # pragma: no cover\n@@ -46,30 +51,6 @@\n     )\n \n \n-# Placeholders (taken from Python-Markdown)\n-STX = '\\u0002'\n-''' \"Start of Text\" marker for placeholder templates. '''\n-ETX = '\\u0003'\n-''' \"End of Text\" marker for placeholder templates. '''\n-INLINE_PLACEHOLDER_PREFIX = f'{STX}klzzwxh:'\n-\n-\n-def build_placeholder(num: int) -> str:\n-    \"\"\"Return a placeholder.\"\"\"\n-    return f'{INLINE_PLACEHOLDER_PREFIX}{num}{ETX}'\n-\n-\n-def save_placeholder(\n-        placeholders_contents: list[tuple[str, str]],\n-        text_to_include: str,\n-) -> str:\n-    \"\"\"Save the included text and return the placeholder.\"\"\"\n-    inclusion_index = len(placeholders_contents)\n-    placeholder = build_placeholder(inclusion_index)\n-    placeholders_contents.append((placeholder, text_to_include))\n-    return placeholder\n-\n-\n @dataclass\n class Settings:  # noqa: D101\n     exclude: list[str] | None\n@@ -105,6 +86,7 @@ def get_file_content(  # noqa: PLR0913, PLR0915\n     else:\n         settings_ignore_paths = []\n \n+    markdown = escape_placeholders(markdown)\n     placeholders_contents: list[tuple[str, str]] = []\n \n     def found_include_tag(  # noqa: PLR0912, PLR0915\n@@ -624,7 +606,7 @@ def found_include_markdown_tag(  # noqa: PLR0912, PLR0915\n     # Replace placeholders by contents\n     for placeholder, text in placeholders_contents:\n         markdown = markdown.replace(placeholder, text, 1)\n-    return markdown\n+    return unescape_placeholders(markdown)\n \n \n def on_page_markdown("
        },
        {
          "filename": "src/mkdocs_include_markdown_plugin/placeholders.py",
          "old_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/1ae8fca510cb5b18f164aaefb855a07f522ec8ff/src/mkdocs_include_markdown_plugin/placeholders.py",
          "new_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/7466d67aa0de8ffbc427204ad2475fed07678915/src/mkdocs_include_markdown_plugin/placeholders.py",
          "diff": "@@ -0,0 +1,37 @@\n+\"\"\"Module for placeholders processing.\"\"\"\n+\n+# Placeholders (taken from Python-Markdown)\n+from __future__ import annotations\n+\n+\n+STX = '\\u0002'\n+''' \"Start of Text\" marker for placeholder templates. '''\n+ETX = '\\u0003'\n+''' \"End of Text\" marker for placeholder templates. '''\n+INLINE_PLACEHOLDER_PREFIX = f'{STX}klzzwxh:'\n+\n+\n+def build_placeholder(num: int) -> str:\n+    \"\"\"Return a placeholder.\"\"\"\n+    return f'{INLINE_PLACEHOLDER_PREFIX}{num}{ETX}'\n+\n+\n+def escape_placeholders(text: str) -> str:\n+    \"\"\"Escape placeholders in the given text.\"\"\"\n+    return text.replace(STX, f'\\\\{STX}').replace(ETX, f'\\\\{ETX}')\n+\n+\n+def unescape_placeholders(text: str) -> str:\n+    \"\"\"Unescape placeholders in the given text.\"\"\"\n+    return text.replace(f'\\\\{STX}', STX).replace(f'\\\\{ETX}', ETX)\n+\n+\n+def save_placeholder(\n+        placeholders_contents: list[tuple[str, str]],\n+        text_to_include: str,\n+) -> str:\n+    \"\"\"Save the included text and return the placeholder.\"\"\"\n+    inclusion_index = len(placeholders_contents)\n+    placeholder = build_placeholder(inclusion_index)\n+    placeholders_contents.append((placeholder, text_to_include))\n+    return placeholder"
        },
        {
          "filename": "tests/test_unit/test_include_markdown.py",
          "old_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/1ae8fca510cb5b18f164aaefb855a07f522ec8ff/tests/test_unit/test_include_markdown.py",
          "new_url": "https://raw.githubusercontent.com/mondeja/mkdocs-include-markdown-plugin/7466d67aa0de8ffbc427204ad2475fed07678915/tests/test_unit/test_include_markdown.py",
          "diff": "@@ -3,6 +3,7 @@\n import pytest\n \n from mkdocs_include_markdown_plugin.event import on_page_markdown\n+from mkdocs_include_markdown_plugin.placeholders import build_placeholder\n \n \n @pytest.mark.parametrize(\n@@ -776,6 +777,27 @@\n             [],\n             id='internal-anchor',\n         ),\n+\n+        # Placeholder collision\n+        pytest.param(\n+            '''# Header\n+\n+''' + build_placeholder(0) + '''\n+\n+{%\n+  include-markdown \"{filepath}\"\n+%}\n+''',\n+            'Content to include',\n+            '''# Header\n+\n+''' + build_placeholder(0) + '''\n+\n+Content to include\n+''',\n+            [],\n+            id='placeholder-collision',\n+        ),\n     ),\n )\n def test_include_markdown("
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59941",
        "https://github.com/filecoin-project/go-f3/commit/76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625"
      ],
      "repo": "go-f3",
      "commit_hash": "76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625",
      "commit_message": "tests: fix assertions in emulator (#1043)  This PR fixes assertions checks in emulator and re-organises the validation logic a bit to facilitate testing.  Signed-off-by: Jakub Sztandera <oss@kubuxu.com>",
      "files_changed": [
        {
          "filename": "emulator/driver_assertions.go",
          "old_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/a055c66291ce9c46a992f0f22bc8094c2cb58919/emulator/driver_assertions.go",
          "new_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625/emulator/driver_assertions.go",
          "diff": "@@ -60,11 +60,11 @@ func (d *Driver) RequirePrepareAtRound(round uint64, value *gpbft.ECChain, justi\n \td.require.NotNil(msg)\n \tinstance := d.host.getInstance(msg.Vote.Instance)\n \td.require.NotNil(instance)\n-\td.require.Equal(gpbft.PREPARE_PHASE, msg.Vote.Phase)\n-\td.require.Equal(round, msg.Vote.Round)\n-\td.require.True(value.Eq(msg.Vote.Value))\n-\td.require.Equal(instance.id, msg.Vote.Instance)\n-\td.require.Equal(instance.supplementalData, msg.Vote.SupplementalData)\n+\td.require.Equal(gpbft.PREPARE_PHASE, msg.Vote.Phase, \"phase different: expected %s, got %s\", gpbft.PREPARE_PHASE, msg.Vote.Phase)\n+\td.require.Equal(round, msg.Vote.Round, \"round different\")\n+\td.require.True(value.Eq(msg.Vote.Value), \"value different\")\n+\td.require.Equal(instance.id, msg.Vote.Instance, \"instance different\")\n+\td.require.Equal(instance.supplementalData, msg.Vote.SupplementalData, \"supplemental data different\")\n \td.requireEqualJustification(justification, msg.Justification)\n \td.require.Empty(msg.Ticket)\n \n@@ -85,7 +85,7 @@ func (d *Driver) RequireCommit(round uint64, vote *gpbft.ECChain, justification\n \td.require.Equal(instance.supplementalData, msg.Vote.SupplementalData)\n \td.require.Equal(instance.id, msg.Vote.Instance)\n \td.require.True(vote.Eq(msg.Vote.Value))\n-\td.requireEqualJustification(justification, justification)\n+\td.requireEqualJustification(justification, msg.Justification)\n \td.require.Empty(msg.Ticket)\n \n \td.require.NoError(d.deliverMessage(msg))\n@@ -107,13 +107,22 @@ func (d *Driver) RequireConverge(round uint64, vote *gpbft.ECChain, justificatio\n \td.require.NoError(d.deliverMessage(msg))\n }\n \n+// Must panics if err is non-nil, otherwise returns v.\n+func Must[V any](v V, err error) V {\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\treturn v\n+}\n+\n func (d *Driver) requireEqualJustification(one *gpbft.Justification, other *gpbft.Justification) {\n \tif one == nil || other == nil {\n \t\td.require.Equal(one, other)\n \t} else {\n-\t\td.require.Equal(one.Signature, other.Signature)\n-\t\td.require.Equal(one.Signers, other.Signers)\n+\t\td.require.Equal(Must(one.Signers.All(100000)), Must(other.Signers.All(100000)), \"signers different\")\n+\t\td.require.EqualExportedValues(one.Vote, other.Vote)\n \t\td.require.True(one.Vote.Eq(&other.Vote))\n+\t\td.require.Equal(one.Signature, other.Signature, \"signature different\")\n \t}\n }\n "
        },
        {
          "filename": "gpbft/gpbft_test.go",
          "old_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/a055c66291ce9c46a992f0f22bc8094c2cb58919/gpbft/gpbft_test.go",
          "new_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625/gpbft/gpbft_test.go",
          "diff": "@@ -225,7 +225,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\t\tVote:   instance.NewCommit(0, &gpbft.ECChain{}),\n \t\t})\n \n-\t\tevidenceOfCommitForBottom := instance.NewJustification(0, gpbft.COMMIT_PHASE, &gpbft.ECChain{}, 0, 1)\n+\t\tevidenceOfCommitForBottom := instance.NewJustification(0, gpbft.COMMIT_PHASE, nil, 0, 1)\n \n \t\tdriver.RequireConverge(1, baseChain, evidenceOfCommitForBottom)\n \t\tdriver.RequireDeliverMessage(&gpbft.GMessage{\n@@ -342,7 +342,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\tdriver.RequireStartInstance(futureInstance.ID())\n \t\tdriver.RequireQuality()\n \t\tdriver.RequirePrepare(futureInstance.Proposal())\n-\t\tdriver.RequireCommit(0, futureInstance.Proposal(), instance.NewJustification(0, gpbft.PREPARE_PHASE, futureInstance.Proposal(), 0, 1))\n+\t\tdriver.RequireCommit(0, futureInstance.Proposal(), futureInstance.NewJustification(0, gpbft.PREPARE_PHASE, futureInstance.Proposal(), 0, 1))\n \t})\n \n \tt.Run(\"Rebroadcasts selected messages on timeout\", func(t *testing.T) {\n@@ -379,7 +379,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\t})\n \n \t\t// Expect progress to COMMIT with strong evidence of PREPARE.\n-\t\tevidenceOfPrepare := instance.NewJustification(0, gpbft.PREPARE_PHASE, instance.Proposal(), 0, 1)\n+\t\tevidenceOfPrepare := instance.NewJustification(0, gpbft.PREPARE_PHASE, baseChain, 0, 1)\n \t\tdriver.RequireCommit(0, baseChain, evidenceOfPrepare)\n \n \t\t// Expect no messages until the rebroadcast timeout has expired.\n@@ -463,6 +463,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \n \t\tfutureRoundProposal := instance.Proposal().Extend(tipSet4.Key)\n \t\tevidenceOfPrepareAtRound76 := instance.NewJustification(76, gpbft.PREPARE_PHASE, futureRoundProposal, 0, 1)\n+\t\tevidenceOfPrepareAtRound77 := instance.NewJustification(77, gpbft.PREPARE_PHASE, futureRoundProposal, 0, 1)\n \n \t\t// Send Prepare messages to facilitate weak quorum of prepare at future round.\n \t\tdriver.RequireDeliverMessage(&gpbft.GMessage{\n@@ -480,7 +481,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\t// Expect skip to round.\n \t\tdriver.RequireConverge(77, futureRoundProposal, evidenceOfPrepareAtRound76)\n \t\tdriver.RequirePrepareAtRound(77, futureRoundProposal, evidenceOfPrepareAtRound76)\n-\t\tdriver.RequireCommit(77, futureRoundProposal, evidenceOfPrepareAtRound76)\n+\t\tdriver.RequireCommit(77, futureRoundProposal, evidenceOfPrepareAtRound77)\n \t\t// Expect no messages until the rebroadcast timeout has expired.\n \t\tdriver.RequireNoBroadcast()\n \t\t// Trigger rebroadcast alarm.\n@@ -492,7 +493,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\t//\n \t\t// See: https://github.com/filecoin-project/go-f3/issues/595\n \t\tdriver.RequireQuality()\n-\t\tdriver.RequireCommit(77, futureRoundProposal, evidenceOfPrepareAtRound76)\n+\t\tdriver.RequireCommit(77, futureRoundProposal, evidenceOfPrepareAtRound77)\n \t\tdriver.RequirePrepareAtRound(77, futureRoundProposal, evidenceOfPrepareAtRound76)\n \t\tdriver.RequireConverge(77, futureRoundProposal, evidenceOfPrepareAtRound76)\n \t\tdriver.RequireNoBroadcast()\n@@ -501,7 +502,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\tdriver.RequireDeliverMessage(&gpbft.GMessage{\n \t\t\tSender:        1,\n \t\t\tVote:          instance.NewCommit(77, futureRoundProposal),\n-\t\t\tJustification: evidenceOfPrepareAtRound76,\n+\t\t\tJustification: evidenceOfPrepareAtRound77,\n \t\t})\n \n \t\t// Expect DECIDE with strong evidence of COMMIT.\n@@ -651,7 +652,7 @@ func TestGPBFT_WithEvenPowerDistribution(t *testing.T) {\n \t\t\t\tVote:   instance.NewPrepare(0, instance.Proposal().BaseChain()),\n \t\t\t})\n \t\t\t// Assert COMMIT phase for base decision.\n-\t\t\tdriver.RequireCommit(0, instance.Proposal().BaseChain(), instance.NewJustification(0, gpbft.PREPARE_PHASE, instance.Proposal(), 0, 1))\n+\t\t\tdriver.RequireCommit(0, instance.Proposal().BaseChain(), instance.NewJustification(0, gpbft.PREPARE_PHASE, instance.Proposal().BaseChain(), 0, 1))\n \t\t}\n \t\tt.Run(\"Justification of CONVERGE to bottom from next round completes phase\", func(t *testing.T) {\n \t\t\tinstance, driver := newInstanceAndDriver(t)\n@@ -783,7 +784,7 @@ func TestGPBFT_WithExactOneThirdToTwoThirdPowerDistribution(t *testing.T) {\n \t\t\t\tVote:   instance.NewPrepare(0, baseChain),\n \t\t\t},\n \t\t)\n-\t\tdriver.RequireCommit(0, baseChain, instance.NewJustification(0, gpbft.PREPARE_PHASE, baseChain, 1, 0))\n+\t\tdriver.RequireCommit(0, baseChain, instance.NewJustification(0, gpbft.PREPARE_PHASE, baseChain, 1))\n \n \t\t// Trigger timeout of COMMIT phase to force a scheduled re-broadcast.\n \t\tdriver.RequireDeliverAlarm()"
        },
        {
          "filename": "gpbft/participant_test.go",
          "old_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/a055c66291ce9c46a992f0f22bc8094c2cb58919/gpbft/participant_test.go",
          "new_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625/gpbft/participant_test.go",
          "diff": "@@ -992,7 +992,7 @@ func TestParticipant_ValidateMessage(t *testing.T) {\n \t\t\twantErr: \"has justification from wrong round\",\n \t\t},\n \t\t{\n-\t\t\tname: \"justification with invalid value is error\",\n+\t\t\tname: \"justification with different value is error\",\n \t\t\tmsg: func(subject *participantTestSubject) *gpbft.GMessage {\n \t\t\t\tsubject.mockValidSignature(somePowerEntry.PubKey, signature)\n \t\t\t\treturn &gpbft.GMessage{\n@@ -1007,13 +1007,14 @@ func TestParticipant_ValidateMessage(t *testing.T) {\n \t\t\t\t\tJustification: &gpbft.Justification{\n \t\t\t\t\t\tVote: gpbft.Payload{\n \t\t\t\t\t\t\tInstance:         initialInstanceNumber,\n+\t\t\t\t\t\t\tPhase:            gpbft.PREPARE_PHASE,\n \t\t\t\t\t\t\tValue:            &gpbft.ECChain{TipSets: []*gpbft.TipSet{subject.canonicalChain.Base(), {PowerTable: subject.supplementalData.PowerTable}}},\n \t\t\t\t\t\t\tSupplementalData: *subject.supplementalData,\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t}\n \t\t\t},\n-\t\t\twantErr: \"invalid justification vote value chain\",\n+\t\t\twantErr: \"has invalid justification vote value chain\",\n \t\t},\n \t}\n \tfor _, test := range tests {"
        },
        {
          "filename": "gpbft/validator.go",
          "old_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/a055c66291ce9c46a992f0f22bc8094c2cb58919/gpbft/validator.go",
          "new_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625/gpbft/validator.go",
          "diff": "@@ -338,39 +338,24 @@ func (v *cachingValidator) validateJustification(ctx context.Context, valueKey *\n \tpartial := valueKey != nil\n \tcacheNamespace := validationNamespaces.justification(partial)\n \n-\t// It doesn't matter whether the justification is partial or not. Because, namespace\n-\t// separates the two.\n-\tcacheKey, err := v.getCacheKey(msg.Justification)\n-\tvar alreadyValidated bool\n-\tif err != nil {\n-\t\tlog.Warnw(\"failed to get cache key for justification\", \"partial\", partial, \"err\", err)\n-\t\t// If we can't compute the cache key, we can't cache the justification. But we\n-\t\t// can still validate it.\n-\t\tcacheKey = nil\n-\t} else {\n-\t\t// Only cache the justification if:\n-\t\t//  * marshalling it was successful, and\n-\t\t//  * it is not yet present in the cache.\n-\t\tif alreadyValidated, err = v.isAlreadyValidated(msg.Vote.Instance, cacheNamespace, cacheKey), err != nil {\n-\t\t\tlog.Warnw(\"failed to check if justification is already cached\", \"partial\", partial, \"err\", err)\n-\t\t} else if alreadyValidated {\n-\t\t\tmetrics.validationCache.Add(ctx, 1, metric.WithAttributes(attrCacheHit, attrCacheKindJustification, attrPartial(partial)))\n-\t\t\treturn nil\n-\t\t} else {\n-\t\t\tmetrics.validationCache.Add(ctx, 1, metric.WithAttributes(attrCacheMiss, attrCacheKindJustification, attrPartial(partial)))\n-\t\t}\n-\t}\n-\n \t// Check that the justification is for the same instance.\n \tif msg.Vote.Instance != msg.Justification.Vote.Instance {\n \t\treturn fmt.Errorf(\"message with instanceID %v has evidence from instanceID: %v\", msg.Vote.Instance, msg.Justification.Vote.Instance)\n \t}\n \tif !msg.Vote.SupplementalData.Eq(&msg.Justification.Vote.SupplementalData) {\n \t\treturn fmt.Errorf(\"message and justification have inconsistent supplemental data: %v != %v\", msg.Vote.SupplementalData, msg.Justification.Vote.SupplementalData)\n \t}\n+\n \t// Check that justification vote value is a valid chain.\n \tif err := msg.Justification.Vote.Value.Validate(), err != nil {\n-\t\treturn fmt.Errorf(\"invalid justification vote value chain: %w\", err)\n+\t\treturn fmt.Errorf(\"has invalid justification vote value chain: %w\", err)\n+\t}\n+\n+\tzeroKey := (&ECChain{}).Key()\n+\tmsgKey := valueKey\n+\tif !partial {\n+\t\tkey := msg.Vote.Value.Key()\n+\t\tmsgKey = &key\n \t}\n \n \t// Check every remaining field of the justification, according to the phase requirements.\n@@ -379,27 +364,27 @@ func (v *cachingValidator) validateJustification(ctx context.Context, valueKey *\n \t// Anything else is disallowed.\n \texpectations := map[Phase]map[Phase]struct {\n \t\tRound uint64\n-\t\tValue *ECChain\n+\t\tKey   *ECChainKey\n \t}{\n \t\t// CONVERGE is justified by a strong quorum of COMMIT for bottom,\n \t\t// or a strong quorum of PREPARE for the same value, from the previous round.\n \t\tCONVERGE_PHASE: {\n-\t\t\tCOMMIT_PHASE:  {msg.Vote.Round - 1, &ECChain{}},\n-\t\t\tPREPARE_PHASE: {msg.Vote.Round - 1, msg.Vote.Value},\n+\t\t\tCOMMIT_PHASE:  {msg.Vote.Round - 1, &zeroKey},\n+\t\t\tPREPARE_PHASE: {msg.Vote.Round - 1, msgKey},\n \t\t},\n \t\t// PREPARE is justified by the same rules as CONVERGE (in rounds > 0).\n \t\tPREPARE_PHASE: {\n-\t\t\tCOMMIT_PHASE:  {msg.Vote.Round - 1, &ECChain{}},\n-\t\t\tPREPARE_PHASE: {msg.Vote.Round - 1, msg.Vote.Value},\n+\t\t\tCOMMIT_PHASE:  {msg.Vote.Round - 1, &zeroKey},\n+\t\t\tPREPARE_PHASE: {msg.Vote.Round - 1, msgKey},\n \t\t},\n \t\t// COMMIT is justified by a strong quorum of PREPARE from the same round with the same value.\n \t\tCOMMIT_PHASE: {\n-\t\t\tPREPARE_PHASE: {msg.Vote.Round, msg.Vote.Value},\n+\t\t\tPREPARE_PHASE: {msg.Vote.Round, msgKey},\n \t\t},\n \t\t// DECIDE is justified by a strong quorum of COMMIT with the same value.\n \t\t// The DECIDE message doesn't specify a round.\n \t\tDECIDE_PHASE: {\n-\t\t\tCOMMIT_PHASE: {math.MaxUint64, msg.Vote.Value},\n+\t\t\tCOMMIT_PHASE: {math.MaxUint64, msgKey},\n \t\t},\n \t}\n \n@@ -410,25 +395,15 @@ func (v *cachingValidator) validateJustification(ctx context.Context, valueKey *\n \t\t\t\treturn fmt.Errorf(\"message %v has justification from wrong round %d\", msg, msg.Justification.Vote.Round)\n \t\t\t}\n \n-\t\t\t// There are 4 possible cases:\n-\t\t\t// 1. The justification is from a complete message with a non-zero value\n-\t\t\t// 2. The justification is from a complete message with a zero value\n-\t\t\t// 3. The justification is from a partial message with non-zero value key\n-\t\t\t// 4. The justification is from a partial message with zero value key\n-\t\t\t//\n-\t\t\t// In cases 1 and 2, the justification vote value must match the expected value\n-\t\t\t// exactly.\n-\t\t\t//\n-\t\t\t// Whereas in cases 3 and 4, the justification vote can't directly be checked and\n-\t\t\t// instead we rely on asserting the value via signature verification. Because the\n-\t\t\t// signing payload uses the value key only.\n-\t\t\tif partial {\n-\t\t\t\texpectedVoteValueKey = *valueKey\n-\t\t\t} else {\n-\t\t\t\tif !msg.Justification.Vote.Value.Eq(expected.Value) {\n+\t\t\t// The key can be either the value key or the zero key.\n+\t\t\t// Depending on which type of justification we are dealing with,\n+\t\t\t// if message is not partial, then check the justification Value is same as the expected Value\n+\t\t\texpectedVoteValueKey = *expected.Key\n+\t\t\tif !partial {\n+\t\t\t\tjustificationVoteValueKey := msg.Justification.Vote.Value.Key()\n+\t\t\t\tif !bytes.Equal(justificationVoteValueKey[:], expected.Key[:]) {\n \t\t\t\t\treturn fmt.Errorf(\"message %v has justification for a different value: %v\", msg, msg.Justification.Vote.Value)\n \t\t\t\t}\n-\t\t\t\texpectedVoteValueKey = expected.Value.Key()\n \t\t\t}\n \t\t} else {\n \t\t\treturn fmt.Errorf(\"message %v has justification with unexpected phase: %v\", msg, msg.Justification.Vote.Phase)\n@@ -437,18 +412,30 @@ func (v *cachingValidator) validateJustification(ctx context.Context, valueKey *\n \t\treturn fmt.Errorf(\"message %v has unexpected phase for justification\", msg)\n \t}\n \n-\t// Check justification power and signature.\n-\tjustificationPower, signers, err := msg.Justification.GetSigners(comt.PowerTable)\n+\tcacheKey, err := v.getCacheKey(msg.Justification, expectedVoteValueKey[:])\n+\tvar alreadyValidated bool\n \tif err != nil {\n-\t\treturn fmt.Errorf(\"failed to get justification signers: %w\", err)\n-\t}\n-\tif !IsStrongQuorum(justificationPower, comt.PowerTable.ScaledTotal) {\n-\t\treturn fmt.Errorf(\"message %v has justification with insufficient power: %v :%w\", msg, justificationPower, ErrValidationInvalid)\n+\t\tlog.Warnw(\"failed to get cache key for justification\", \"partial\", partial, \"err\", err)\n+\t\t// If we can't compute the cache key, we can't cache the justification. But we\n+\t\t// can still validate it.\n+\t\tcacheKey = nil\n+\t} else {\n+\t\t// Only cache the justification if:\n+\t\t//  * marshalling it was successful, and\n+\t\t//  * it is not yet present in the cache.\n+\t\tif alreadyValidated, err = v.isAlreadyValidated(msg.Vote.Instance, cacheNamespace, cacheKey), err != nil {\n+\t\t\tlog.Warnw(\"failed to check if justification is already cached\", \"partial\", partial, \"err\", err)\n+\t\t} else if alreadyValidated {\n+\t\t\tmetrics.validationCache.Add(ctx, 1, metric.WithAttributes(attrCacheHit, attrCacheKindJustification, attrPartial(partial)))\n+\t\t\treturn nil\n+\t\t} else {\n+\t\t\tmetrics.validationCache.Add(ctx, 1, metric.WithAttributes(attrCacheMiss, attrCacheKindJustification, attrPartial(partial)))\n+\t\t}\n \t}\n \n-\tpayload := msg.Justification.Vote.MarshalForSigningWithValueKey(v.networkName, expectedVoteValueKey)\n-\tif err := comt.AggregateVerifier.VerifyAggregate(signers, payload, msg.Justification.Signature), err != nil {\n-\t\treturn fmt.Errorf(\"verification of the aggregate failed: %+v: %w\", msg.Justification, err)\n+\terr = v.validateJustificationSignature(comt, msg.Justification, expectedVoteValueKey)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"internal justification validation failed: %w\", err)\n \t}\n \n \tif len(cacheKey) > 0 {\n@@ -461,6 +448,27 @@ func (v *cachingValidator) validateJustification(ctx context.Context, valueKey *\n \treturn nil\n }\n \n+func (v *cachingValidator) validateJustificationSignature(comt *Committee, justif *Justification, expectedVoteValueKey ECChainKey) error {\n+\t// It doesn't matter whether the justification is partial or not. Because, namespace\n+\t// separates the two.\n+\n+\t// Check justification power and signature.\n+\tjustificationPower, signers, err := justif.GetSigners(comt.PowerTable)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"failed to get justification signers: %w\", err)\n+\t}\n+\tif !IsStrongQuorum(justificationPower, comt.PowerTable.ScaledTotal) {\n+\t\treturn fmt.Errorf(\"has justification with insufficient power: %v :%w\", justificationPower, ErrValidationInvalid)\n+\t}\n+\n+\tpayload := justif.Vote.MarshalForSigningWithValueKey(v.networkName, expectedVoteValueKey)\n+\tif err := comt.AggregateVerifier.VerifyAggregate(signers, payload, justif.Signature), err != nil {\n+\t\treturn fmt.Errorf(\"verification of the aggregate failed: %+v: %w\", justif, err)\n+\t}\n+\n+\treturn nil\n+}\n+\n func (v *cachingValidator) isAlreadyValidated(group uint64, namespace validatorNamespace, cacheKey []byte) (bool, error) {\n \talreadyValidated, err := v.cache.Contains(group, namespace, cacheKey)\n \tif err != nil {\n@@ -469,10 +477,13 @@ func (v *cachingValidator) isAlreadyValidated(group uint64, namespace validatorN\n \treturn alreadyValidated, nil\n }\n \n-func (v *cachingValidator) getCacheKey(msg cbor.Marshaler) ([]byte, error) {\n+func (v *cachingValidator) getCacheKey(msg cbor.Marshaler, additionalFields ...[]byte) ([]byte, error) {\n \tvar buf bytes.Buffer\n \tif err := msg.MarshalCBOR(&buf), err != nil {\n \t\treturn nil, fmt.Errorf(\"failed to get cache key: %w\", err)\n \t}\n+\tfor _, field := range additionalFields {\n+\t\t_, _ = buf.Write(field)\n+\t}\n \treturn buf.Bytes(), nil\n }"
        },
        {
          "filename": "merkle/merkle_test.go",
          "old_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/a055c66291ce9c46a992f0f22bc8094c2cb58919/merkle/merkle_test.go",
          "new_url": "https://raw.githubusercontent.com/filecoin-project/go-f3/76fff18cf07b21baccf537024bdb2fb41f75f6e2#diff-e1f646cea41790e1642e4e649c9e3c526344736d67222201703e1c29c23e9625/merkle/merkle_test.go",
          "diff": "@@ -13,8 +13,6 @@ import (\n func TestHashTree(t *testing.T) {\n \tfor i := 1, i < 256, i++ {\n \t\tt.Run(fmt.Sprintf(\"Length/%d\", i), func(t *testing.T) {\n-\t\t\tt.Parallel()\n-\n \t\t\ttest := make([][]byte, i)\n \t\t\tfor j := range test {\n \t\t\t\ttest[j] = []byte{byte(j)}"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59948",
        "https://github.com/FreshRSS/FreshRSS/commit/7df6c201f2e6a6521d20718dfd8d9794c7437d1f"
      ],
      "repo": "FreshRSS",
      "commit_hash": "7df6c201f2e6a6521d20718dfd8d9794c7437d1f",
      "commit_message": "Put CSP everywhere (#7810)  * Puts CSP everywhere in `p/api`    * including the HTML query page \u2757    * Also in `p/ext.php` * Puts `X-Content-Type-Options: nosniff` everywhere * Fixes custom icon configuration not showing `blob:` icon in statsController (idle feeds)    * Also removes `style-src 'unsafe-inline'` since it doesn't seem to be needed * Improves CSP of `p/f.php`  * Add `sandbox` directive",
      "files_changed": [
        {
          "filename": "app/Controllers/statsController.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/app/Controllers/statsController.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/app/Controllers/statsController.php",
          "diff": "@@ -30,8 +30,7 @@ public function firstAction(): void {\n \t\t$this->_csp([\n \t\t\t'default-src' => \"'self'\",\n \t\t\t'frame-ancestors' => \"'none'\",\n-\t\t\t'img-src' => '* data:',\n-\t\t\t'style-src' => \"'self' 'unsafe-inline'\",\n+\t\t\t'img-src' => '* data: blob:',\n \t\t]),\n \n \t\t$catDAO = FreshRSS_Factory::createCategoryDao(),"
        },
        {
          "filename": "app/FreshRSS.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/app/FreshRSS.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/app/FreshRSS.php",
          "diff": "@@ -149,7 +149,7 @@ public static function loadStylesAndScripts(): void {\n \t}\n \n \tpublic static function preLayout(): void {\n-\t\theader(\"X-Content-Type-Options: nosniff\"),\n+\t\theader('X-Content-Type-Options: nosniff'),\n \n \t\tFreshRSS_Share::load(join_path(APP_PATH, 'shares.php')),\n \t\tself::loadStylesAndScripts(),"
        },
        {
          "filename": "p/api/fever.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/api/fever.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/api/fever.php",
          "diff": "@@ -1,5 +1,7 @@\n <?php\n declare(strict_types=1),\n+header(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n+header('X-Content-Type-Options: nosniff'),\n \n /**\n  * Fever API for FreshRSS"
        },
        {
          "filename": "p/api/greader.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/api/greader.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/api/greader.php",
          "diff": "@@ -28,6 +28,9 @@\n require(__DIR__ . '/../../constants.php'),\n require(LIB_PATH . '/lib_rss.php'),\t//Includes class autoloader\n \n+header(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n+header('X-Content-Type-Options: nosniff'),\n+\n if (PHP_INT_SIZE < 8) {\t//32-bit\n \t/** @return numeric-string */\n \tfunction hex2dec(string $hex): string {"
        },
        {
          "filename": "p/api/index.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/api/index.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/api/index.php",
          "diff": "@@ -1,5 +1,7 @@\n <?php\n \tdeclare(strict_types=1),\n+\theader(\"Content-Security-Policy: default-src 'self', frame-ancestors 'none'\"),\n+\theader('X-Content-Type-Options: nosniff'),\n ?>\n <!DOCTYPE html>\n <html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en-GB\" lang=\"en-GB\">"
        },
        {
          "filename": "p/api/pshb.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/api/pshb.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/api/pshb.php",
          "diff": "@@ -6,6 +6,7 @@\n const MAX_PAYLOAD = 3_145_728,\n \n header('Content-Type: text/plain, charset=UTF-8'),\n+header(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n header('X-Content-Type-Options: nosniff'),\n \n $ORIGINAL_INPUT = file_get_contents('php://input', false, null, 0, MAX_PAYLOAD) ?: '',"
        },
        {
          "filename": "p/api/query.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/api/query.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/api/query.php",
          "diff": "@@ -1,5 +1,8 @@\n <?php\n declare(strict_types=1),\n+\n+header('X-Content-Type-Options: nosniff'),\n+\n require(__DIR__ . '/../../constants.php'),\n require(LIB_PATH . '/lib_rss.php'),\t//Includes class autoloader\n \n@@ -175,10 +178,12 @@\n \n if (in_array($format, ['rss', 'atom'], true)) {\n \theader('Content-Type: application/rss+xml, charset=utf-8'),\n+\theader(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n \t$view->_layout(null),\n \t$view->_path('index/rss.phtml'),\n } elseif (in_array($format, ['greader', 'json'], true)) {\n \theader('Content-Type: application/json, charset=utf-8'),\n+\theader(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n \t$view->_layout(null),\n \t$view->type = 'query/' . $token,\n \t$view->list_title = $query->getName(),\n@@ -190,9 +195,11 @@\n \t\tdie(),\n \t}\n \theader('Content-Type: application/xml, charset=utf-8'),\n+\theader(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n \t$view->_layout(null),\n \t$view->_path('index/opml.phtml'),\n } else {\n+\theader(\"Content-Security-Policy: default-src 'self', frame-src *, img-src * data:, frame-ancestors 'none', media-src *\"),\n \t$view->_layout('layout'),\n \t$view->_path('index/html.phtml'),\n }"
        },
        {
          "filename": "p/ext.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/ext.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/ext.php",
          "diff": "@@ -94,6 +94,8 @@ function sendNotFoundResponse(): never {\n $content_type = FreshRSS_extension_Controller::MIME_TYPES[$file_type],\n header(\"Content-Type: {$content_type}\"),\n header(\"Content-Disposition: inline, filename='{$file_name}'\"),\n+header(\"Content-Security-Policy: default-src 'self', frame-ancestors 'none'\"),\n+header('X-Content-Type-Options: nosniff'),\n header('Referrer-Policy: same-origin'),\n \n $mtime = @filemtime($absolute_filename),"
        },
        {
          "filename": "p/f.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/2b1b268fc27268197b8c86ed839bf22daab79438/p/f.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/7df6c201f2e6a6521d20718dfd8d9794c7437d1f/p/f.php",
          "diff": "@@ -5,6 +5,9 @@\n require(LIB_PATH . '/favicons.php'),\n require(LIB_PATH . '/http-conditional.php'),\n \n+header(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', sandbox\"),\n+header('X-Content-Type-Options: nosniff'),\n+\n function show_default_favicon(int $cacheSeconds = 3600): void {\n \t$default_mtime = @filemtime(DEFAULT_FAVICON) ?: 0,\n \tif (!httpConditional($default_mtime, $cacheSeconds, 2)) {\n@@ -56,7 +59,6 @@ function show_default_favicon(int $cacheSeconds = 3600): void {\n \t}\n }\n \n-header(\"Content-Security-Policy: default-src 'none', frame-ancestors 'none', img-src 'self', style-src 'self',\"),\n if (!httpConditional($ico_mtime, mt_rand(14, 21) * 86400, 2)) {\n \t$ico_content_type = contentType($ico),\n \theader('Content-Type: ' . $ico_content_type),"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-61586",
        "https://github.com/FreshRSS/FreshRSS/commit/6549932d59aef3b72a9da29294af0f30ffb77af5"
      ],
      "repo": "FreshRSS",
      "commit_hash": "6549932d59aef3b72a9da29294af0f30ffb77af5",
      "commit_message": "Disallow setting non-existent theme (#7722)  Related: https://github.com/FreshRSS/xExtension-Demo/pull/2, https://github.com/FreshRSS/FreshRSS/pull/7559#issuecomment-2858083635  Mostly to make sure that no one is able to break the demo instance But the issues below could possibly be exploited in other scenarios too: * Setting a theme like `../../lib/core-extensions/UserJS`: this directory contains `metadata.json` like themes do, so FreshRSS treats it as a theme after setting it and doesn't load any CSS * Setting a theme like `x dropdown-menu`: the `dropdown-menu` class was able to get injected into the `<body>` element since https://github.com/FreshRSS/FreshRSS/pull/7559 and turn every page blank",
      "files_changed": [
        {
          "filename": "app/Controllers/configureController.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/ce22997dfbe4a8f2a6efa6f77d5b0bfc7b2dabd1/app/Controllers/configureController.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/6549932d59aef3b72a9da29294af0f30ffb77af5/app/Controllers/configureController.php",
          "diff": "@@ -47,7 +47,10 @@ public function displayAction(): void {\n \t\tif (Minz_Request::isPost()) {\n \t\t\tFreshRSS_Context::userConf()->language = Minz_Request::paramString('language') ?: 'en',\n \t\t\tFreshRSS_Context::userConf()->timezone = Minz_Request::paramString('timezone'),\n-\t\t\tFreshRSS_Context::userConf()->theme = Minz_Request::paramString('theme') ?: FreshRSS_Themes::$defaultTheme,\n+\t\t\t$theme = Minz_Request::paramString('theme') ?: FreshRSS_Themes::$defaultTheme,\n+\t\t\tif (FreshRSS_Themes::exists($theme)) {\n+\t\t\t\tFreshRSS_Context::userConf()->theme = $theme,\n+\t\t\t}\n \t\t\tFreshRSS_Context::userConf()->darkMode = Minz_Request::paramString('darkMode') ?: 'auto',\n \t\t\tFreshRSS_Context::userConf()->content_width = Minz_Request::paramString('content_width') ?: 'thin',\n \t\t\tFreshRSS_Context::userConf()->topline_read = Minz_Request::paramBoolean('topline_read'),"
        },
        {
          "filename": "app/Models/Themes.php",
          "old_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/ce22997dfbe4a8f2a6efa6f77d5b0bfc7b2dabd1/app/Models/Themes.php",
          "new_url": "https://raw.githubusercontent.com/FreshRSS/FreshRSS/6549932d59aef3b72a9da29294af0f30ffb77af5/app/Models/Themes.php",
          "diff": "@@ -15,6 +15,12 @@ public static function getList(): array {\n \t\t)),\n \t}\n \n+\tpublic static function exists(string $theme_id): bool {\n+\t\t$theme_dir = PUBLIC_PATH . self::$themesUrl . $theme_id,\n+\t\treturn str_replace(['..', '/', DIRECTORY_SEPARATOR], '', $theme_id) === $theme_id\n+\t\t\t&& file_exists($theme_dir . '/metadata.json'),\n+\t}\n+\n \t/** @return array<string,array{id:string,name:string,author:string,description:string,version:float|string,files:array<string>,theme-color?:string|array{dark?:string,light?:string,default?:string}}> */\n \tpublic static function get(): array {\n \t\t$themes_list = self::getList(),"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59954",
        "https://github.com/KnowageLabs/Knowage-Server/commit/1bb60d42557724f7ed24c19df6c5017e169527ca"
      ],
      "repo": "Knowage-Server",
      "commit_hash": "1bb60d42557724f7ed24c19df6c5017e169527ca",
      "commit_message": "[Closes KNOWAGE-8569] Improve handling of XPath expressions",
      "files_changed": [
        {
          "filename": "knowagemeta/src/main/java/it/eng/knowage/meta/model/util/JXPathContextBuilder.java",
          "old_url": "https://raw.githubusercontent.com/KnowageLabs/Knowage-Server/0010109b3a45c4265a0843f1320f6e15d775f892/knowagemeta/src/main/java/it/eng/knowage/meta/model/util/JXPathContextBuilder.java",
          "new_url": "https://raw.githubusercontent.com/KnowageLabs/Knowage-Server/1bb60d42557724f7ed24c19df6c5017e169527ca/knowagemeta/src/main/java/it/eng/knowage/meta/model/util/JXPathContextBuilder.java",
          "diff": "@@ -0,0 +1,59 @@\n+/*\n+ * Knowage, Open Source Business Intelligence suite\n+ * Copyright (C) 2016 Engineering Ingegneria Informatica S.p.A.\n+ *\n+ * Knowage is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Knowage is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY, without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package it.eng.knowage.meta.model.util,\n+\n+import org.apache.commons.jxpath.AbstractFactory,\n+import org.apache.commons.jxpath.FunctionLibrary,\n+import org.apache.commons.jxpath.JXPathContext,\n+\n+/** Contains utility methods to create safe {@code JXPathContext} objects. */\n+public class JXPathContextBuilder {\n+\n+\tprivate JXPathContext context,\n+\n+\tprivate JXPathContextBuilder(Object contextBean) {\n+\t\tcontext = newSafeContext(contextBean),\n+\t}\n+\n+\tpublic static JXPathContextBuilder newInstance(Object contextBean) {\n+\t\treturn new JXPathContextBuilder(contextBean),\n+\t}\n+\n+\tpublic JXPathContextBuilder withFactory(AbstractFactory factory) {\n+\t\tcontext.setFactory(factory),\n+\t\treturn this,\n+\t}\n+\n+\t/**\n+\t * Creates a {@code JXPathContext} that disables calling Java methods from XPath expressions.\n+\t *\n+\t * @param contextBean the root node object\n+\t * @return the context\n+\t */\n+\tpublic JXPathContext newSafeContext(Object contextBean) {\n+\t\tJXPathContext safeContext = JXPathContext.newContext(contextBean),\n+\t\t// Set empty function library to prevent calling functions\n+\t\tsafeContext.setFunctions(new FunctionLibrary()),\n+\t\treturn safeContext,\n+\t}\n+\n+\tpublic JXPathContext build() {\n+\t\treturn context,\n+\t}\n+\n+}\n\\ No newline at end of file"
        },
        {
          "filename": "knowagemeta/src/main/java/it/eng/knowage/meta/service/MetaService.java",
          "old_url": "https://raw.githubusercontent.com/KnowageLabs/Knowage-Server/0010109b3a45c4265a0843f1320f6e15d775f892/knowagemeta/src/main/java/it/eng/knowage/meta/service/MetaService.java",
          "new_url": "https://raw.githubusercontent.com/KnowageLabs/Knowage-Server/1bb60d42557724f7ed24c19df6c5017e169527ca/knowagemeta/src/main/java/it/eng/knowage/meta/service/MetaService.java",
          "diff": "@@ -110,6 +110,7 @@\n import it.eng.knowage.meta.model.physical.PhysicalTable,\n import it.eng.knowage.meta.model.serializer.EmfXmiSerializer,\n import it.eng.knowage.meta.model.serializer.ModelPropertyFactory,\n+import it.eng.knowage.meta.model.util.JXPathContextBuilder,\n import it.eng.qbe.utility.CustomFunctionsSingleton,\n import it.eng.qbe.utility.CustomizedFunctionsReader,\n import it.eng.qbe.utility.DbTypeThreadLocal,\n@@ -214,7 +215,8 @@ public Response loadSbiModel(@PathParam(\"bmId\") Integer bmId, @Context HttpServl\n \n \t\t\treturn Response.ok(translatedModel.toString()).build(),\n \n-\t\t} catch (Throwable t) {\r\t\t\tlogger.error(\"Impossibile to load the model\", t),\n+\t\t} catch (Throwable t) {\n+\t\t\tlogger.error(\"Impossibile to load the model\", t),\n \t\t\tthrow new SpagoBIServiceException(req.getPathInfo(), t),\n \t\t}\n \t}\n@@ -1491,8 +1493,7 @@ private void applyDiff(JSONObject jsonRoot, Model model) throws SpagoBIException\n \tprivate void applyPatch(JsonNode patch, Model model) throws SpagoBIException {\n \t\tlogger.debug(\"applyPatch:\" + patch != null ? patch.toString() : \"null\"),\n \t\tIterator<JsonNode> elements = patch.elements(),\n-\t\tJXPathContext context = JXPathContext.newContext(model),\n-\t\tcontext.setFactory(new ModelPropertyFactory()),\n+\t\tJXPathContext context = JXPathContextBuilder.newInstance(model).withFactory(new ModelPropertyFactory()).build(),\n \t\twhile (elements.hasNext()) {\n \t\t\tJsonNode jsonNode = elements.next(),\n \t\t\tString operation = jsonNode.get(\"op\").textValue(),"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-59956",
        "https://github.com/coder/agentapi/commit/5c425c62447b8a9eac19e9fc5a2eae7f0803f149"
      ],
      "repo": "agentapi",
      "commit_hash": "5c425c62447b8a9eac19e9fc5a2eae7f0803f149",
      "commit_message": "feat: implement HTTP allowed hosts/origins checking (#49)",
      "files_changed": [
        {
          "filename": "README.md",
          "old_url": "https://raw.githubusercontent.com/coder/agentapi/e783ff109645cad7a35b3b536feaa0c7a65dfab1/README.md",
          "new_url": "https://raw.githubusercontent.com/coder/agentapi/5c425c62447b8a9eac19e9fc5a2eae7f0803f149/README.md",
          "diff": "@@ -4,7 +4,6 @@ Control [Claude Code](https://github.com/anthropics/claude-code), [Goose](https:\n \n ![agentapi-chat](https://github.com/user-attachments/assets/57032c9f-4146-4b66-b219-09e38ab7690d)\n \n-\n You can use AgentAPI:\n \n - to build a unified chat interface for coding agents\n@@ -54,9 +53,6 @@ You can use AgentAPI:\n \n Run an HTTP server that lets you control an agent. If you'd like to start an agent with additional arguments, pass the full agent command after the `--` flag.\n \n-> [!NOTE]\n-> When using Codex, always specify the agent type explicitly (`agentapi server --type=codex -- codex`), or message formatting may break.\n-\n ```bash\n agentapi server -- claude --allowedTools \"Bash(git*) Edit Replace\"\n ```\n@@ -68,6 +64,9 @@ agentapi server -- aider --model sonnet --api-key anthropic=sk-ant-apio3-XXX\n agentapi server -- goose\n ```\n \n+> [!NOTE]\n+> When using Codex, always specify the agent type explicitly (`agentapi server --type=codex -- codex`), or message formatting may break.\n+\n An OpenAPI schema is available in [openapi.json](openapi.json).\n \n By default, the server runs on port 3284. Additionally, the server exposes the same OpenAPI schema at http://localhost:3284/openapi.json and the available endpoints in a documentation UI at http://localhost:3284/docs.\n@@ -79,6 +78,54 @@ There are 4 endpoints:\n - GET `/status` - returns the current status of the agent, either \"stable\" or \"running\"\n - GET `/events` - an SSE stream of events from the agent: message and status updates\n \n+#### Allowed hosts\n+\n+By default, the server only allows requests with the host header set to `localhost`. If you'd like to host AgentAPI elsewhere, you can change this by using the `AGENTAPI_ALLOWED_HOSTS` environment variable or the `--allowed-hosts` flag. Hosts must be hostnames only (no ports), the server ignores the port portion of incoming requests when authorizing.\n+\n+To allow requests from any host, use `*` as the allowed host.\n+\n+```bash\n+agentapi server --allowed-hosts '*' -- claude\n+```\n+\n+To allow a specific host, use:\n+\n+```bash\n+agentapi server --allowed-hosts 'example.com' -- claude\n+```\n+\n+To specify multiple hosts, use a comma-separated list when using the `--allowed-hosts` flag, or a space-separated list when using the `AGENTAPI_ALLOWED_HOSTS` environment variable.\n+\n+```bash\n+agentapi server --allowed-hosts 'example.com,example.org' -- claude\n+# or\n+AGENTAPI_ALLOWED_HOSTS='example.com example.org' agentapi server -- claude\n+```\n+\n+#### Allowed origins\n+\n+By default, the server allows CORS requests from `http://localhost:3284`, `http://localhost:3000`, and `http://localhost:3001`. If you'd like to change which origins can make cross-origin requests to AgentAPI, you can change this by using the `AGENTAPI_ALLOWED_ORIGINS` environment variable or the `--allowed-origins` flag.\n+\n+To allow requests from any origin, use `*` as the allowed origin:\n+\n+```bash\n+agentapi server --allowed-origins '*' -- claude\n+```\n+\n+To allow a specific origin, use:\n+\n+```bash\n+agentapi server --allowed-origins 'https://example.com' -- claude\n+```\n+\n+To specify multiple origins, use a comma-separated list when using the `--allowed-origins` flag, or a space-separated list when using the `AGENTAPI_ALLOWED_ORIGINS` environment variable. Origins must include the protocol (`http://` or `https://`) and support wildcards (e.g., `https://*.example.com`):\n+\n+```bash\n+agentapi server --allowed-origins 'https://example.com,http://localhost:3000' -- claude\n+# or\n+AGENTAPI_ALLOWED_ORIGINS='https://example.com http://localhost:3000' agentapi server -- claude\n+```\n+\n ### `agentapi attach`\n \n Attach to a running agent's terminal session."
        },
        {
          "filename": "cmd/server/server.go",
          "old_url": "https://raw.githubusercontent.com/coder/agentapi/e783ff109645cad7a35b3b536feaa0c7a65dfab1/cmd/server/server.go",
          "new_url": "https://raw.githubusercontent.com/coder/agentapi/5c425c62447b8a9eac19e9fc5a2eae7f0803f149/cmd/server/server.go",
          "diff": "@@ -95,12 +95,17 @@ func runServer(ctx context.Context, logger *slog.Logger, argsToPass []string) er\n \t\t}\n \t}\n \tport := viper.GetInt(FlagPort)\n-\tsrv := httpapi.NewServer(ctx, httpapi.ServerConfig{\n-\t\tAgentType:    agentType,\n-\t\tProcess:      process,\n-\t\tPort:         port,\n-\t\tChatBasePath: viper.GetString(FlagChatBasePath),\n+\tsrv, err := httpapi.NewServer(ctx, httpapi.ServerConfig{\n+\t\tAgentType:      agentType,\n+\t\tProcess:        process,\n+\t\tPort:           port,\n+\t\tChatBasePath:   viper.GetString(FlagChatBasePath),\n+\t\tAllowedHosts:   viper.GetStringSlice(FlagAllowedHosts),\n+\t\tAllowedOrigins: viper.GetStringSlice(FlagAllowedOrigins),\n \t})\n+\tif err != nil {\n+\t\treturn xerrors.Errorf(\"failed to create server: %w\", err)\n+\t}\n \tif printOpenAPI {\n \t\tfmt.Println(srv.GetOpenAPI())\n \t\treturn nil\n@@ -150,12 +155,15 @@ type flagSpec struct {\n }\n \n const (\n-\tFlagType         = \"type\"\n-\tFlagPort         = \"port\"\n-\tFlagPrintOpenAPI = \"print-openapi\"\n-\tFlagChatBasePath = \"chat-base-path\"\n-\tFlagTermWidth    = \"term-width\"\n-\tFlagTermHeight   = \"term-height\"\n+\tFlagType           = \"type\"\n+\tFlagPort           = \"port\"\n+\tFlagPrintOpenAPI   = \"print-openapi\"\n+\tFlagChatBasePath   = \"chat-base-path\"\n+\tFlagTermWidth      = \"term-width\"\n+\tFlagTermHeight     = \"term-height\"\n+\tFlagAllowedHosts   = \"allowed-hosts\"\n+\tFlagAllowedOrigins = \"allowed-origins\"\n+\tFlagExit           = \"exit\"\n )\n \n func CreateServerCmd() *cobra.Command {\n@@ -165,6 +173,10 @@ func CreateServerCmd() *cobra.Command {\n \t\tLong:  fmt.Sprintf(\"Run the server with the specified agent (one of: %s)\", strings.Join(agentNames, \", \")),\n \t\tArgs:  cobra.MinimumNArgs(1),\n \t\tRun: func(cmd *cobra.Command, args []string) {\n+\t\t\t// The --exit flag is used for testing validation of flags in the test suite\n+\t\t\tif viper.GetBool(FlagExit) {\n+\t\t\t\treturn\n+\t\t\t}\n \t\t\tlogger := slog.New(slog.NewTextHandler(os.Stdout, nil))\n \t\t\tctx := logctx.WithLogger(context.Background(), logger)\n \t\t\tif err := runServer(ctx, logger, cmd.Flags().Args()), err != nil {\n@@ -181,6 +193,10 @@ func CreateServerCmd() *cobra.Command {\n \t\t{FlagChatBasePath, \"c\", \"/chat\", \"Base path for assets and routes used in the static files of the chat interface\", \"string\"},\n \t\t{FlagTermWidth, \"W\", uint16(80), \"Width of the emulated terminal\", \"uint16\"},\n \t\t{FlagTermHeight, \"H\", uint16(1000), \"Height of the emulated terminal\", \"uint16\"},\n+\t\t// localhost is the default host for the server. Port is ignored during matching.\n+\t\t{FlagAllowedHosts, \"a\", []string{\"localhost\", \"127.0.0.1\", \"[::1]\"}, \"HTTP allowed hosts (hostnames only, no ports). Use '*' for all, comma-separated list via flag, space-separated list via AGENTAPI_ALLOWED_HOSTS env var\", \"stringSlice\"},\n+\t\t// localhost:3284 is the default origin when you open the chat interface in your browser. localhost:3000 and 3001 are used during development.\n+\t\t{FlagAllowedOrigins, \"o\", []string{\"http://localhost:3284\", \"http://localhost:3000\", \"http://localhost:3001\"}, \"HTTP allowed origins. Use '*' for all, comma-separated list via flag, space-separated list via AGENTAPI_ALLOWED_ORIGINS env var\", \"stringSlice\"},\n \t}\n \n \tfor _, spec := range flagSpecs {\n@@ -193,6 +209,8 @@ func CreateServerCmd() *cobra.Command {\n \t\t\tserverCmd.Flags().BoolP(spec.name, spec.shorthand, spec.defaultValue.(bool), spec.usage)\n \t\tcase \"uint16\":\n \t\t\tserverCmd.Flags().Uint16P(spec.name, spec.shorthand, spec.defaultValue.(uint16), spec.usage)\n+\t\tcase \"stringSlice\":\n+\t\t\tserverCmd.Flags().StringSliceP(spec.name, spec.shorthand, spec.defaultValue.([]string), spec.usage)\n \t\tdefault:\n \t\t\tpanic(fmt.Sprintf(\"unknown flag type: %s\", spec.flagType))\n \t\t}\n@@ -201,6 +219,14 @@ func CreateServerCmd() *cobra.Command {\n \t\t}\n \t}\n \n+\tserverCmd.Flags().Bool(FlagExit, false, \"Exit immediately after parsing arguments\")\n+\tif err := serverCmd.Flags().MarkHidden(FlagExit), err != nil {\n+\t\tpanic(fmt.Sprintf(\"failed to mark flag %s as hidden: %v\", FlagExit, err))\n+\t}\n+\tif err := viper.BindPFlag(FlagExit, serverCmd.Flags().Lookup(FlagExit)), err != nil {\n+\t\tpanic(fmt.Sprintf(\"failed to bind flag %s: %v\", FlagExit, err))\n+\t}\n+\n \tviper.SetEnvPrefix(\"AGENTAPI\")\n \tviper.AutomaticEnv()\n \tviper.SetEnvKeyReplacer(strings.NewReplacer(\"-\", \"_\"))"
        },
        {
          "filename": "cmd/server/server_test.go",
          "old_url": "https://raw.githubusercontent.com/coder/agentapi/e783ff109645cad7a35b3b536feaa0c7a65dfab1/cmd/server/server_test.go",
          "new_url": "https://raw.githubusercontent.com/coder/agentapi/5c425c62447b8a9eac19e9fc5a2eae7f0803f149/cmd/server/server_test.go",
          "diff": "@@ -12,6 +12,20 @@ import (\n \t\"github.com/stretchr/testify/require\"\n )\n \n+type nullWriter struct{}\n+\n+func (w *nullWriter) Write(p []byte) (int, error) {\n+\treturn len(p), nil\n+}\n+\n+// setupCommandOutput configures a cobra command to use a null writer for output capture.\n+func setupCommandOutput(t *testing.T, cmd *cobra.Command) {\n+\tt.Helper()\n+\n+\tcmd.SetOut(&nullWriter{})\n+\tcmd.SetErr(&nullWriter{})\n+}\n+\n func TestParseAgentType(t *testing.T) {\n \ttests := []struct {\n \t\tfirstArg     string\n@@ -141,17 +155,17 @@ func TestServerCmd_AllArgs_Defaults(t *testing.T) {\n \t\t{\"chat-base-path default\", FlagChatBasePath, \"/chat\", func() any { return viper.GetString(FlagChatBasePath) }},\n \t\t{\"term-width default\", FlagTermWidth, uint16(80), func() any { return viper.GetUint16(FlagTermWidth) }},\n \t\t{\"term-height default\", FlagTermHeight, uint16(1000), func() any { return viper.GetUint16(FlagTermHeight) }},\n+\t\t{\"allowed-hosts default\", FlagAllowedHosts, []string{\"localhost\", \"127.0.0.1\", \"[::1]\"}, func() any { return viper.GetStringSlice(FlagAllowedHosts) }},\n+\t\t{\"allowed-origins default\", FlagAllowedOrigins, []string{\"http://localhost:3284\", \"http://localhost:3000\", \"http://localhost:3001\"}, func() any { return viper.GetStringSlice(FlagAllowedOrigins) }},\n \t}\n \n \tfor _, tt := range tests {\n \t\tt.Run(tt.name, func(t *testing.T) {\n \t\t\tisolateViper(t)\n \t\t\tserverCmd := CreateServerCmd()\n-\t\t\tcmd := &cobra.Command{}\n-\t\t\tcmd.AddCommand(serverCmd)\n-\n-\t\t\t// Execute with no args to get defaults\n-\t\t\tserverCmd.SetArgs([]string{\"--help\"}) // Use help to avoid actual execution\n+\t\t\tsetupCommandOutput(t, serverCmd)\n+\t\t\t// Execute with --exit to get defaults\n+\t\t\tserverCmd.SetArgs([]string{\"--exit\", \"dummy-command\"})\n \t\t\tif err := serverCmd.Execute(), err != nil {\n \t\t\t\tt.Fatalf(\"Failed to execute server command: %v\", err)\n \t\t\t}\n@@ -175,6 +189,8 @@ func TestServerCmd_AllEnvVars(t *testing.T) {\n \t\t{\"AGENTAPI_CHAT_BASE_PATH\", \"AGENTAPI_CHAT_BASE_PATH\", \"/api\", \"/api\", func() any { return viper.GetString(FlagChatBasePath) }},\n \t\t{\"AGENTAPI_TERM_WIDTH\", \"AGENTAPI_TERM_WIDTH\", \"120\", uint16(120), func() any { return viper.GetUint16(FlagTermWidth) }},\n \t\t{\"AGENTAPI_TERM_HEIGHT\", \"AGENTAPI_TERM_HEIGHT\", \"500\", uint16(500), func() any { return viper.GetUint16(FlagTermHeight) }},\n+\t\t{\"AGENTAPI_ALLOWED_HOSTS\", \"AGENTAPI_ALLOWED_HOSTS\", \"localhost example.com\", []string{\"localhost\", \"example.com\"}, func() any { return viper.GetStringSlice(FlagAllowedHosts) }},\n+\t\t{\"AGENTAPI_ALLOWED_ORIGINS\", \"AGENTAPI_ALLOWED_ORIGINS\", \"https://example.com http://localhost:3000\", []string{\"https://example.com\", \"http://localhost:3000\"}, func() any { return viper.GetStringSlice(FlagAllowedOrigins) }},\n \t}\n \n \tfor _, tt := range tests {\n@@ -183,10 +199,8 @@ func TestServerCmd_AllEnvVars(t *testing.T) {\n \t\t\tt.Setenv(tt.envVar, tt.envValue)\n \n \t\t\tserverCmd := CreateServerCmd()\n-\t\t\tcmd := &cobra.Command{}\n-\t\t\tcmd.AddCommand(serverCmd)\n-\n-\t\t\tserverCmd.SetArgs([]string{\"--help\"})\n+\t\t\tsetupCommandOutput(t, serverCmd)\n+\t\t\tserverCmd.SetArgs([]string{\"--exit\", \"dummy-command\"})\n \t\t\tif err := serverCmd.Execute(), err != nil {\n \t\t\t\tt.Fatalf(\"Failed to execute server command: %v\", err)\n \t\t\t}\n@@ -247,16 +261,23 @@ func TestServerCmd_ArgsPrecedenceOverEnv(t *testing.T) {\n \t\t\tuint16(600),\n \t\t\tfunc() any { return viper.GetUint16(FlagTermHeight) },\n \t\t},\n+\t\t{\n+\t\t\t\"allowed-origins: CLI overrides env\",\n+\t\t\t\"AGENTAPI_ALLOWED_ORIGINS\", \"https://env-example.com http://localhost:3000\",\n+\t\t\t[]string{\"--allowed-origins\", \"https://cli-example.com\"},\n+\t\t\t[]string{\"https://cli-example.com\"},\n+\t\t\tfunc() any { return viper.GetStringSlice(FlagAllowedOrigins) },\n+\t\t},\n \t}\n \n \tfor _, tt := range tests {\n \t\tt.Run(tt.name, func(t *testing.T) {\n \t\t\tisolateViper(t)\n \t\t\tt.Setenv(tt.envVar, tt.envValue)\n \n-\t\t\t// Mock execution to test arg parsing without running server\n-\t\t\targs := append(tt.args, \"--help\")\n+\t\t\targs := append(tt.args, \"--exit\", \"dummy-command\")\n \t\t\tserverCmd := CreateServerCmd()\n+\t\t\tsetupCommandOutput(t, serverCmd)\n \t\t\tserverCmd.SetArgs(args)\n \t\t\tif err := serverCmd.Execute(), err != nil {\n \t\t\t\tt.Fatalf(\"Failed to execute server command: %v\", err)\n@@ -277,7 +298,8 @@ func TestMixed_ConfigurationScenarios(t *testing.T) {\n \n \t\t// Set some CLI args\n \t\tserverCmd := CreateServerCmd()\n-\t\tserverCmd.SetArgs([]string{\"--port\", \"9999\", \"--print-openapi\", \"--help\"})\n+\t\tsetupCommandOutput(t, serverCmd)\n+\t\tserverCmd.SetArgs([]string{\"--port\", \"9999\", \"--print-openapi\", \"--exit\", \"dummy-command\"})\n \t\tif err := serverCmd.Execute(), err != nil {\n \t\t\tt.Fatalf(\"Failed to execute server command: %v\", err)\n \t\t}\n@@ -291,3 +313,186 @@ func TestMixed_ConfigurationScenarios(t *testing.T) {\n \t\tassert.Equal(t, uint16(1000), viper.GetUint16(FlagTermHeight)) // default\n \t})\n }\n+\n+func TestServerCmd_AllowedHosts(t *testing.T) {\n+\ttests := []struct {\n+\t\tname        string\n+\t\tenv         map[string]string\n+\t\targs        []string\n+\t\texpectedErr string\n+\t\texpected    []string // only checked if expectedErr is empty\n+\t}{\n+\t\t// Environment variable scenarios (space-separated format)\n+\t\t{\n+\t\t\tname:     \"env: single valid host\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_HOSTS\": \"localhost\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"localhost\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"env: multiple valid hosts space-separated\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_HOSTS\": \"localhost example.com 192.168.1.1\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"localhost\", \"example.com\", \"192.168.1.1\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"env: host with tab\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_HOSTS\": \"localhost\\texample.com\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"localhost\", \"example.com\"},\n+\t\t},\n+\t\t// CLI flag scenarios (comma-separated format)\n+\t\t{\n+\t\t\tname:     \"flag: single valid host\",\n+\t\t\targs:     []string{\"--allowed-hosts\", \"localhost\"},\n+\t\t\texpected: []string{\"localhost\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: multiple valid hosts comma-separated\",\n+\t\t\targs:     []string{\"--allowed-hosts\", \"localhost,example.com,192.168.1.1\"},\n+\t\t\texpected: []string{\"localhost\", \"example.com\", \"192.168.1.1\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: multiple valid hosts with multiple flags\",\n+\t\t\targs:     []string{\"--allowed-hosts\", \"localhost\", \"--allowed-hosts\", \"example.com\"},\n+\t\t\texpected: []string{\"localhost\", \"example.com\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: host with newline\",\n+\t\t\targs:     []string{\"--allowed-hosts\", \"localhost\\n\"},\n+\t\t\texpected: []string{\"localhost\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: ipv6 bracketed literal\",\n+\t\t\targs:     []string{\"--allowed-hosts\", \"[2001:db8::1]\"},\n+\t\t\texpected: []string{\"[2001:db8::1]\"},\n+\t\t},\n+\n+\t\t// Mixed scenarios (env + flag precedence)\n+\t\t{\n+\t\t\tname:     \"mixed: flag overrides env\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_HOSTS\": \"localhost\"},\n+\t\t\targs:     []string{\"--allowed-hosts\", \"override.com\"},\n+\t\t\texpected: []string{\"override.com\"},\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(tt.name, func(t *testing.T) {\n+\t\t\tisolateViper(t)\n+\n+\t\t\t// Set environment variables if provided\n+\t\t\tfor key, value := range tt.env {\n+\t\t\t\tt.Setenv(key, value)\n+\t\t\t}\n+\n+\t\t\tserverCmd := CreateServerCmd()\n+\t\t\tsetupCommandOutput(t, serverCmd)\n+\t\t\tserverCmd.SetArgs(append(tt.args, \"--exit\", \"dummy-command\"))\n+\t\t\terr := serverCmd.Execute()\n+\n+\t\t\tif tt.expectedErr != \"\" {\n+\t\t\t\trequire.Error(t, err)\n+\t\t\t\tassert.Contains(t, err.Error(), tt.expectedErr)\n+\t\t\t} else {\n+\t\t\t\trequire.NoError(t, err)\n+\t\t\t\tassert.Equal(t, tt.expected, viper.GetStringSlice(FlagAllowedHosts))\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func TestServerCmd_AllowedOrigins(t *testing.T) {\n+\ttests := []struct {\n+\t\tname        string\n+\t\tenv         map[string]string\n+\t\targs        []string\n+\t\texpectedErr string\n+\t\texpected    []string // only checked if expectedErr is empty\n+\t}{\n+\t\t// Environment variable scenarios (space-separated format)\n+\t\t{\n+\t\t\tname:     \"env: single valid origin\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_ORIGINS\": \"https://example.com\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"https://example.com\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"env: multiple valid origins space-separated\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_ORIGINS\": \"https://example.com http://localhost:3000 https://app.example.com\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"https://example.com\", \"http://localhost:3000\", \"https://app.example.com\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"env: wildcard origin\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_ORIGINS\": \"*\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"*\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"env: origin with tab\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_ORIGINS\": \"https://example.com\\thttp://localhost:3000\"},\n+\t\t\targs:     []string{},\n+\t\t\texpected: []string{\"https://example.com\", \"http://localhost:3000\"},\n+\t\t},\n+\n+\t\t// CLI flag scenarios (comma-separated format)\n+\t\t{\n+\t\t\tname:     \"flag: single valid origin\",\n+\t\t\targs:     []string{\"--allowed-origins\", \"https://example.com\"},\n+\t\t\texpected: []string{\"https://example.com\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: multiple valid origins comma-separated\",\n+\t\t\targs:     []string{\"--allowed-origins\", \"https://example.com,http://localhost:3000,https://app.example.com\"},\n+\t\t\texpected: []string{\"https://example.com\", \"http://localhost:3000\", \"https://app.example.com\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: multiple valid origins with multiple flags\",\n+\t\t\targs:     []string{\"--allowed-origins\", \"https://example.com\", \"--allowed-origins\", \"http://localhost:3000\"},\n+\t\t\texpected: []string{\"https://example.com\", \"http://localhost:3000\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: wildcard origin\",\n+\t\t\targs:     []string{\"--allowed-origins\", \"*\"},\n+\t\t\texpected: []string{\"*\"},\n+\t\t},\n+\t\t{\n+\t\t\tname:     \"flag: origin with newline\",\n+\t\t\targs:     []string{\"--allowed-origins\", \"https://example.com\\n\"},\n+\t\t\texpected: []string{\"https://example.com\"},\n+\t\t},\n+\n+\t\t// Mixed scenarios (env + flag precedence)\n+\t\t{\n+\t\t\tname:     \"mixed: flag overrides env\",\n+\t\t\tenv:      map[string]string{\"AGENTAPI_ALLOWED_ORIGINS\": \"https://env-example.com\"},\n+\t\t\targs:     []string{\"--allowed-origins\", \"https://override.com\"},\n+\t\t\texpected: []string{\"https://override.com\"},\n+\t\t},\n+\t}\n+\n+\tfor _, tt := range tests {\n+\t\tt.Run(tt.name, func(t *testing.T) {\n+\t\t\tisolateViper(t)\n+\n+\t\t\t// Set environment variables if provided\n+\t\t\tfor key, value := range tt.env {\n+\t\t\t\tt.Setenv(key, value)\n+\t\t\t}\n+\n+\t\t\tserverCmd := CreateServerCmd()\n+\t\t\tsetupCommandOutput(t, serverCmd)\n+\t\t\tserverCmd.SetArgs(append(tt.args, \"--exit\", \"dummy-command\"))\n+\t\t\terr := serverCmd.Execute()\n+\n+\t\t\tif tt.expectedErr != \"\" {\n+\t\t\t\trequire.Error(t, err)\n+\t\t\t\tassert.Contains(t, err.Error(), tt.expectedErr)\n+\t\t\t} else {\n+\t\t\t\trequire.NoError(t, err)\n+\t\t\t\tassert.Equal(t, tt.expected, viper.GetStringSlice(FlagAllowedOrigins))\n+\t\t\t}\n+\t\t})\n+\t}\n+}"
        },
        {
          "filename": "lib/httpapi/server.go",
          "old_url": "https://raw.githubusercontent.com/coder/agentapi/e783ff109645cad7a35b3b536feaa0c7a65dfab1/lib/httpapi/server.go",
          "new_url": "https://raw.githubusercontent.com/coder/agentapi/5c425c62447b8a9eac19e9fc5a2eae7f0803f149/lib/httpapi/server.go",
          "diff": "@@ -7,9 +7,11 @@ import (\n \t\"log/slog\"\n \t\"net/http\"\n \t\"net/url\"\n+\t\"slices\"\n \t\"strings\"\n \t\"sync\"\n \t\"time\"\n+\t\"unicode\"\n \n \t\"github.com/coder/agentapi/lib/logctx\"\n \tmf \"github.com/coder/agentapi/lib/msgfmt\"\n@@ -60,18 +62,124 @@ func (s *Server) GetOpenAPI() string {\n const snapshotInterval = 25 * time.Millisecond\n \n type ServerConfig struct {\n-\tAgentType    mf.AgentType\n-\tProcess      *termexec.Process\n-\tPort         int\n-\tChatBasePath string\n+\tAgentType      mf.AgentType\n+\tProcess        *termexec.Process\n+\tPort           int\n+\tChatBasePath   string\n+\tAllowedHosts   []string\n+\tAllowedOrigins []string\n+}\n+\n+// Validate allowed hosts don't contain whitespace, commas, schemes, or ports.\n+// Viper/Cobra use different separators (space for env vars, comma for flags),\n+// so these characters likely indicate user error.\n+func parseAllowedHosts(input []string) ([]string, error) {\n+\tif len(input) == 0 {\n+\t\treturn nil, fmt.Errorf(\"the list must not be empty\")\n+\t}\n+\tif slices.Contains(input, \"*\") {\n+\t\treturn []string{\"*\"}, nil\n+\t}\n+\t// First pass: whitespace & comma checks (surface these errors first)\n+\t// Viper/Cobra use different separators (space for env vars, comma for flags),\n+\t// so these characters likely indicate user error.\n+\tfor _, item := range input {\n+\t\tfor _, r := range item {\n+\t\t\tif unicode.IsSpace(r) {\n+\t\t\t\treturn nil, fmt.Errorf(\"'%s' contains whitespace characters, which are not allowed\", item)\n+\t\t\t}\n+\t\t}\n+\t\tif strings.Contains(item, \",\") {\n+\t\t\treturn nil, fmt.Errorf(\"'%s' contains comma characters, which are not allowed\", item)\n+\t\t}\n+\t}\n+\t// Second pass: scheme check\n+\tfor _, item := range input {\n+\t\tif strings.Contains(item, \"http://\") || strings.Contains(item, \"https://\") {\n+\t\t\treturn nil, fmt.Errorf(\"'%s' must not include http:// or https://\", item)\n+\t\t}\n+\t}\n+\thosts := make([]*url.URL, 0, len(input))\n+\t// Third pass: url parse\n+\tfor _, item := range input {\n+\t\ttrimmed := strings.TrimSpace(item)\n+\t\tu, err := url.Parse(\"http://\" + trimmed)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"'%s' is not a valid host: %w\", item, err)\n+\t\t}\n+\t\thosts = append(hosts, u)\n+\t}\n+\t// Fourth pass: port check\n+\tfor _, u := range hosts {\n+\t\tif u.Port() != \"\" {\n+\t\t\treturn nil, fmt.Errorf(\"'%s' must not include a port\", u.Host)\n+\t\t}\n+\t}\n+\thostStrings := make([]string, 0, len(hosts))\n+\tfor _, u := range hosts {\n+\t\thostStrings = append(hostStrings, u.Hostname())\n+\t}\n+\treturn hostStrings, nil\n+}\n+\n+// Validate allowed origins\n+func parseAllowedOrigins(input []string) ([]string, error) {\n+\tif len(input) == 0 {\n+\t\treturn nil, fmt.Errorf(\"the list must not be empty\")\n+\t}\n+\tif slices.Contains(input, \"*\") {\n+\t\treturn []string{\"*\"}, nil\n+\t}\n+\t// Viper/Cobra use different separators (space for env vars, comma for flags),\n+\t// so these characters likely indicate user error.\n+\tfor _, item := range input {\n+\t\tfor _, r := range item {\n+\t\t\tif unicode.IsSpace(r) {\n+\t\t\t\treturn nil, fmt.Errorf(\"'%s' contains whitespace characters, which are not allowed\", item)\n+\t\t\t}\n+\t\t}\n+\t\tif strings.Contains(item, \",\") {\n+\t\t\treturn nil, fmt.Errorf(\"'%s' contains comma characters, which are not allowed\", item)\n+\t\t}\n+\t}\n+\torigins := make([]string, 0, len(input))\n+\tfor _, item := range input {\n+\t\ttrimmed := strings.TrimSpace(item)\n+\t\tu, err := url.Parse(trimmed)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"'%s' is not a valid origin: %w\", item, err)\n+\t\t}\n+\t\torigins = append(origins, fmt.Sprintf(\"%s://%s\", u.Scheme, u.Host))\n+\t}\n+\treturn origins, nil\n }\n \n // NewServer creates a new server instance\n-func NewServer(ctx context.Context, config ServerConfig) *Server {\n+func NewServer(ctx context.Context, config ServerConfig) (*Server, error) {\n \trouter := chi.NewMux()\n \n+\tlogger := logctx.From(ctx)\n+\n+\tallowedHosts, err := parseAllowedHosts(config.AllowedHosts)\n+\tif err != nil {\n+\t\treturn nil, xerrors.Errorf(\"failed to parse allowed hosts: %w\", err)\n+\t}\n+\tallowedOrigins, err := parseAllowedOrigins(config.AllowedOrigins)\n+\tif err != nil {\n+\t\treturn nil, xerrors.Errorf(\"failed to parse allowed origins: %w\", err)\n+\t}\n+\n+\tlogger.Info(fmt.Sprintf(\"Allowed hosts: %s\", strings.Join(allowedHosts, \", \")))\n+\tlogger.Info(fmt.Sprintf(\"Allowed origins: %s\", strings.Join(allowedOrigins, \", \")))\n+\n+\t// Enforce allowed hosts in a custom middleware that ignores the port during matching.\n+\tbadHostHandler := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n+\t\thttp.Error(w, \"Invalid host header. Allowed hosts: \"+strings.Join(allowedHosts, \", \"), http.StatusBadRequest)\n+\t})\n+\trouter.Use(hostAuthorizationMiddleware(allowedHosts, badHostHandler))\n+\n \tcorsMiddleware := cors.New(cors.Options{\n-\t\tAllowedOrigins:   []string{\"*\"},\n+\t\tAllowedOrigins:   allowedOrigins,\n \t\tAllowedMethods:   []string{\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"},\n \t\tAllowedHeaders:   []string{\"Accept\", \"Authorization\", \"Content-Type\", \"X-CSRF-Token\"},\n \t\tExposedHeaders:   []string{\"Link\"},\n@@ -101,7 +209,7 @@ func NewServer(ctx context.Context, config ServerConfig) *Server {\n \t\tapi:          api,\n \t\tport:         config.Port,\n \t\tconversation: conversation,\n-\t\tlogger:       logctx.From(ctx),\n+\t\tlogger:       logger,\n \t\tagentio:      config.Process,\n \t\tagentType:    config.AgentType,\n \t\temitter:      emitter,\n@@ -111,14 +219,48 @@ func NewServer(ctx context.Context, config ServerConfig) *Server {\n \t// Register API routes\n \ts.registerRoutes()\n \n-\treturn s\n+\treturn s, nil\n }\n \n // Handler returns the underlying chi.Router for testing purposes.\n func (s *Server) Handler() http.Handler {\n \treturn s.router\n }\n \n+// hostAuthorizationMiddleware enforces that the request Host header matches one of the allowed\n+// hosts, ignoring any port in the comparison. If allowedHosts is empty, all hosts are allowed.\n+// Always uses url.Parse(\"http://\" + r.Host) to robustly extract the hostname (handles IPv6).\n+func hostAuthorizationMiddleware(allowedHosts []string, badHostHandler http.Handler) func(next http.Handler) http.Handler {\n+\t// Copy for safety, also build a map for O(1) lookups with case-insensitive keys.\n+\tallowed := make(map[string]struct{}, len(allowedHosts))\n+\tfor _, h := range allowedHosts {\n+\t\tallowed[strings.ToLower(h)] = struct{}{}\n+\t}\n+\twildcard := slices.Contains(allowedHosts, \"*\")\n+\treturn func(next http.Handler) http.Handler {\n+\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n+\t\t\tif wildcard { // wildcard semantics: allow all\n+\t\t\t\tnext.ServeHTTP(w, r)\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\t// Extract hostname from the Host header using url.Parse, ignore any port.\n+\t\t\thostHeader := r.Host\n+\t\t\tif hostHeader == \"\" {\n+\t\t\t\tbadHostHandler.ServeHTTP(w, r)\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tif u, err := url.Parse(\"http://\" + hostHeader), err == nil {\n+\t\t\t\thostname := u.Hostname()\n+\t\t\t\tif _, ok := allowed[strings.ToLower(hostname)], ok {\n+\t\t\t\t\tnext.ServeHTTP(w, r)\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tbadHostHandler.ServeHTTP(w, r)\n+\t\t})\n+\t}\n+}\n+\n func (s *Server) StartSnapshotLoop(ctx context.Context) {\n \ts.conversation.StartSnapshotLoop(ctx)\n \tgo func() {"
        },
        {
          "filename": "lib/httpapi/server_test.go",
          "old_url": "https://raw.githubusercontent.com/coder/agentapi/e783ff109645cad7a35b3b536feaa0c7a65dfab1/lib/httpapi/server_test.go",
          "new_url": "https://raw.githubusercontent.com/coder/agentapi/5c425c62447b8a9eac19e9fc5a2eae7f0803f149/lib/httpapi/server_test.go",
          "diff": "@@ -46,12 +46,15 @@ func TestOpenAPISchema(t *testing.T) {\n \tt.Parallel()\n \n \tctx := logctx.WithLogger(context.Background(), slog.New(slog.NewTextHandler(os.Stdout, nil)))\n-\tsrv := httpapi.NewServer(ctx, httpapi.ServerConfig{\n-\t\tAgentType:    msgfmt.AgentTypeClaude,\n-\t\tProcess:      nil,\n-\t\tPort:         0,\n-\t\tChatBasePath: \"/chat\",\n+\tsrv, err := httpapi.NewServer(ctx, httpapi.ServerConfig{\n+\t\tAgentType:      msgfmt.AgentTypeClaude,\n+\t\tProcess:        nil,\n+\t\tPort:           0,\n+\t\tChatBasePath:   \"/chat\",\n+\t\tAllowedHosts:   []string{\"*\"},\n+\t\tAllowedOrigins: []string{\"*\"},\n \t})\n+\trequire.NoError(t, err)\n \tcurrentSchemaStr := srv.GetOpenAPI()\n \tvar currentSchema any\n \tif err := json.Unmarshal([]byte(currentSchemaStr), &currentSchema), err != nil {\n@@ -95,12 +98,15 @@ func TestServer_redirectToChat(t *testing.T) {\n \t\tt.Run(tc.name, func(t *testing.T) {\n \t\t\tt.Parallel()\n \t\t\ttCtx := logctx.WithLogger(context.Background(), slog.New(slog.NewTextHandler(os.Stdout, nil)))\n-\t\t\ts := httpapi.NewServer(tCtx, httpapi.ServerConfig{\n-\t\t\t\tAgentType:    msgfmt.AgentTypeClaude,\n-\t\t\t\tProcess:      nil,\n-\t\t\t\tPort:         0,\n-\t\t\t\tChatBasePath: tc.chatBasePath,\n+\t\t\ts, err := httpapi.NewServer(tCtx, httpapi.ServerConfig{\n+\t\t\t\tAgentType:      msgfmt.AgentTypeClaude,\n+\t\t\t\tProcess:        nil,\n+\t\t\t\tPort:           0,\n+\t\t\t\tChatBasePath:   tc.chatBasePath,\n+\t\t\t\tAllowedHosts:   []string{\"*\"},\n+\t\t\t\tAllowedOrigins: []string{\"*\"},\n \t\t\t})\n+\t\t\trequire.NoError(t, err)\n \t\t\ttsServer := httptest.NewServer(s.Handler())\n \t\t\tt.Cleanup(tsServer.Close)\n \n@@ -120,3 +126,508 @@ func TestServer_redirectToChat(t *testing.T) {\n \t\t})\n \t}\n }\n+\n+func TestServer_AllowedHosts(t *testing.T) {\n+\tcases := []struct {\n+\t\tname               string\n+\t\tallowedHosts       []string\n+\t\thostHeader         string\n+\t\texpectedStatusCode int\n+\t\texpectedErrorMsg   string\n+\t\tvalidationErrorMsg string\n+\t}{\n+\t\t{\n+\t\t\tname:               \"wildcard hosts - any host allowed\",\n+\t\t\tallowedHosts:       []string{\"*\"},\n+\t\t\thostHeader:         \"example.com\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"wildcard hosts - another host allowed\",\n+\t\t\tallowedHosts:       []string{\"*\"},\n+\t\t\thostHeader:         \"malicious.com\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"specific hosts - valid host allowed\",\n+\t\t\tallowedHosts:       []string{\"localhost\", \"app.example.com\"},\n+\t\t\thostHeader:         \"localhost:3000\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"specific hosts - another valid host allowed\",\n+\t\t\tallowedHosts:       []string{\"localhost\", \"app.example.com\"},\n+\t\t\thostHeader:         \"app.example.com\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"specific hosts - invalid host rejected\",\n+\t\t\tallowedHosts:       []string{\"localhost\", \"app.example.com\"},\n+\t\t\thostHeader:         \"malicious.com\",\n+\t\t\texpectedStatusCode: http.StatusBadRequest,\n+\t\t\texpectedErrorMsg:   \"Invalid host header. Allowed hosts: localhost, app.example.com\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"ipv6 bracketed configured allowed - with port\",\n+\t\t\tallowedHosts:       []string{\"[2001:db8::1]\"},\n+\t\t\thostHeader:         \"[2001:db8::1]:80\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"ipv6 literal invalid host rejected\",\n+\t\t\tallowedHosts:       []string{\"[2001:db8::1]\"},\n+\t\t\thostHeader:         \"[2001:db8::2]\",\n+\t\t\texpectedStatusCode: http.StatusBadRequest,\n+\t\t\texpectedErrorMsg:   \"Invalid host header. Allowed hosts: 2001:db8::1\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"allowed hosts must not be empty\",\n+\t\t\tallowedHosts:       []string{},\n+\t\t\tvalidationErrorMsg: \"the list must not be empty\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"ipv6 literal without square brackets is invalid\",\n+\t\t\tallowedHosts:       []string{\"2001:db8::1\"},\n+\t\t\tvalidationErrorMsg: \"must not include a port\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"host with port in config is invalid\",\n+\t\t\tallowedHosts:       []string{\"example.com:8080\"},\n+\t\t\tvalidationErrorMsg: \"must not include a port\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"bracketed ipv6 with port in config is invalid\",\n+\t\t\tallowedHosts:       []string{\"[2001:db8::1]:443\"},\n+\t\t\tvalidationErrorMsg: \"must not include a port\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"hostname with http scheme is invalid\",\n+\t\t\tallowedHosts:       []string{\"http://example.com\"},\n+\t\t\tvalidationErrorMsg: \"must not include http:// or https://\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"hostname with https scheme is invalid\",\n+\t\t\tallowedHosts:       []string{\"https://example.com\"},\n+\t\t\tvalidationErrorMsg: \"must not include http:// or https://\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"hostname containing comma is invalid\",\n+\t\t\tallowedHosts:       []string{\"example.com,malicious.com\"},\n+\t\t\tvalidationErrorMsg: \"contains comma characters, which are not allowed\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"hostname with leading whitespace is invalid\",\n+\t\t\tallowedHosts:       []string{\" example.com\"},\n+\t\t\tvalidationErrorMsg: \"contains whitespace characters, which are not allowed\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"hostname with internal whitespace is invalid\",\n+\t\t\tallowedHosts:       []string{\"exa mple.com\"},\n+\t\t\tvalidationErrorMsg: \"contains whitespace characters, which are not allowed\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"uppercase allowed host matches lowercase request\",\n+\t\t\tallowedHosts:       []string{\"EXAMPLE.COM\"},\n+\t\t\thostHeader:         \"example.com:80\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"wildcard with extra invalid entries still allows all\",\n+\t\t\tallowedHosts:       []string{\"*\", \"https://bad.com\", \"example.com:8080\", \" space.com\"},\n+\t\t\thostHeader:         \"malicious.com\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"trailing dot in allowed host requires trailing dot in request (no match)\",\n+\t\t\tallowedHosts:       []string{\"example.com.\"},\n+\t\t\thostHeader:         \"example.com\",\n+\t\t\texpectedStatusCode: http.StatusBadRequest,\n+\t\t\texpectedErrorMsg:   \"Invalid host header. Allowed hosts: example.com.\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"trailing dot in allowed host matches trailing dot in request\",\n+\t\t\tallowedHosts:       []string{\"example.com.\"},\n+\t\t\thostHeader:         \"example.com.:80\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"ipv6 bracketed configured allowed - without port header\",\n+\t\t\tallowedHosts:       []string{\"[2001:db8::1]\"},\n+\t\t\thostHeader:         \"[2001:db8::1]\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t}\n+\n+\tfor _, tc := range cases {\n+\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tctx := logctx.WithLogger(context.Background(), slog.New(slog.NewTextHandler(os.Stdout, nil)))\n+\t\t\ts, err := httpapi.NewServer(ctx, httpapi.ServerConfig{\n+\t\t\t\tAgentType:      msgfmt.AgentTypeClaude,\n+\t\t\t\tProcess:        nil,\n+\t\t\t\tPort:           0,\n+\t\t\t\tChatBasePath:   \"/chat\",\n+\t\t\t\tAllowedHosts:   tc.allowedHosts,\n+\t\t\t\tAllowedOrigins: []string{\"https://example.com\"}, // Set a default to isolate host testing\n+\t\t\t})\n+\t\t\tif tc.validationErrorMsg != \"\" {\n+\t\t\t\trequire.Error(t, err)\n+\t\t\t\trequire.Contains(t, err.Error(), tc.validationErrorMsg)\n+\t\t\t\treturn\n+\t\t\t} else {\n+\t\t\t\trequire.NoError(t, err)\n+\t\t\t}\n+\t\t\ttsServer := httptest.NewServer(s.Handler())\n+\t\t\tt.Cleanup(tsServer.Close)\n+\n+\t\t\treq, err := http.NewRequest(\"GET\", tsServer.URL+\"/status\", nil)\n+\t\t\trequire.NoError(t, err)\n+\n+\t\t\tif tc.hostHeader != \"\" {\n+\t\t\t\treq.Host = tc.hostHeader\n+\t\t\t}\n+\n+\t\t\tclient := &http.Client{}\n+\t\t\tresp, err := client.Do(req)\n+\t\t\trequire.NoError(t, err)\n+\t\t\tt.Cleanup(func() {\n+\t\t\t\t_ = resp.Body.Close()\n+\t\t\t})\n+\n+\t\t\trequire.Equal(t, tc.expectedStatusCode, resp.StatusCode,\n+\t\t\t\t\"expected status code %d, got %d\", tc.expectedStatusCode, resp.StatusCode)\n+\n+\t\t\tif tc.expectedErrorMsg != \"\" {\n+\t\t\t\tbody, err := io.ReadAll(resp.Body)\n+\t\t\t\trequire.NoError(t, err)\n+\t\t\t\trequire.Contains(t, string(body), tc.expectedErrorMsg)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func TestServer_CORSPreflightWithHosts(t *testing.T) {\n+\tcases := []struct {\n+\t\tname               string\n+\t\tallowedHosts       []string\n+\t\thostHeader         string\n+\t\toriginHeader       string\n+\t\texpectedStatusCode int\n+\t\texpectCORSHeaders  bool\n+\t}{\n+\t\t{\n+\t\t\tname:               \"preflight with wildcard hosts\",\n+\t\t\tallowedHosts:       []string{\"*\"},\n+\t\t\thostHeader:         \"example.com\",\n+\t\t\toriginHeader:       \"https://example.com\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t\texpectCORSHeaders:  true,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"preflight with specific valid host\",\n+\t\t\tallowedHosts:       []string{\"localhost\"},\n+\t\t\thostHeader:         \"localhost:3000\",\n+\t\t\toriginHeader:       \"https://localhost:3000\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t\texpectCORSHeaders:  true,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"preflight with invalid host\",\n+\t\t\tallowedHosts:       []string{\"localhost\"},\n+\t\t\thostHeader:         \"malicious.com\",\n+\t\t\toriginHeader:       \"https://malicious.com\",\n+\t\t\texpectedStatusCode: http.StatusBadRequest,\n+\t\t\texpectCORSHeaders:  false,\n+\t\t},\n+\t}\n+\n+\tfor _, tc := range cases {\n+\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tctx := logctx.WithLogger(context.Background(), slog.New(slog.NewTextHandler(os.Stdout, nil)))\n+\t\t\ts, err := httpapi.NewServer(ctx, httpapi.ServerConfig{\n+\t\t\t\tAgentType:      msgfmt.AgentTypeClaude,\n+\t\t\t\tProcess:        nil,\n+\t\t\t\tPort:           0,\n+\t\t\t\tChatBasePath:   \"/chat\",\n+\t\t\t\tAllowedHosts:   tc.allowedHosts,\n+\t\t\t\tAllowedOrigins: []string{\"*\"}, // Set wildcard origins to isolate host testing\n+\t\t\t})\n+\t\t\trequire.NoError(t, err)\n+\t\t\ttsServer := httptest.NewServer(s.Handler())\n+\t\t\tt.Cleanup(tsServer.Close)\n+\n+\t\t\t// Test CORS preflight request\n+\t\t\treq, err := http.NewRequest(\"OPTIONS\", tsServer.URL+\"/status\", nil)\n+\t\t\trequire.NoError(t, err)\n+\n+\t\t\tif tc.hostHeader != \"\" {\n+\t\t\t\treq.Host = tc.hostHeader\n+\t\t\t}\n+\t\t\tif tc.originHeader != \"\" {\n+\t\t\t\treq.Header.Set(\"Origin\", tc.originHeader)\n+\t\t\t}\n+\t\t\treq.Header.Set(\"Access-Control-Request-Method\", \"GET\")\n+\t\t\treq.Header.Set(\"Access-Control-Request-Headers\", \"Content-Type\")\n+\n+\t\t\tclient := &http.Client{}\n+\t\t\tresp, err := client.Do(req)\n+\t\t\trequire.NoError(t, err)\n+\t\t\tt.Cleanup(func() {\n+\t\t\t\t_ = resp.Body.Close()\n+\t\t\t})\n+\n+\t\t\trequire.Equal(t, tc.expectedStatusCode, resp.StatusCode,\n+\t\t\t\t\"expected status code %d, got %d\", tc.expectedStatusCode, resp.StatusCode)\n+\n+\t\t\tif tc.expectCORSHeaders {\n+\t\t\t\tallowMethods := resp.Header.Get(\"Access-Control-Allow-Methods\")\n+\t\t\t\trequire.Contains(t, allowMethods, \"GET\", \"expected GET in allowed methods\")\n+\n+\t\t\t\tallowHeaders := resp.Header.Get(\"Access-Control-Allow-Headers\")\n+\t\t\t\trequire.Contains(t, allowHeaders, \"Content-Type\", \"expected Content-Type in allowed headers\")\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func TestServer_CORSOrigins(t *testing.T) {\n+\tcases := []struct {\n+\t\tname                   string\n+\t\tallowedOrigins         []string\n+\t\toriginHeader           string\n+\t\texpectedStatusCode     int\n+\t\texpectedCORSOrigin     string\n+\t\texpectCORSOriginHeader bool\n+\t\tvalidationErrorMsg     string\n+\t}{\n+\t\t{\n+\t\t\tname:                   \"wildcard origins - any origin allowed\",\n+\t\t\tallowedOrigins:         []string{\"*\"},\n+\t\t\toriginHeader:           \"https://example.com\",\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t\texpectedCORSOrigin:     \"*\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"wildcard origins - malicious origin allowed\",\n+\t\t\tallowedOrigins:         []string{\"*\"},\n+\t\t\toriginHeader:           \"http://malicious.com\",\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t\texpectedCORSOrigin:     \"*\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"specific origins - valid origin allowed https\",\n+\t\t\tallowedOrigins:         []string{\"https://localhost:3000\", \"http://app.example.com\"},\n+\t\t\toriginHeader:           \"https://localhost:3000\",\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t\texpectedCORSOrigin:     \"https://localhost:3000\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"specific origins - valid origin allowed http\",\n+\t\t\tallowedOrigins:         []string{\"https://localhost:3000\", \"http://app.example.com\"},\n+\t\t\toriginHeader:           \"http://app.example.com\",\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t\texpectedCORSOrigin:     \"http://app.example.com\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"specific origins - invalid origin rejected\",\n+\t\t\tallowedOrigins:         []string{\"https://localhost:3000\", \"http://app.example.com\"},\n+\t\t\toriginHeader:           \"https://malicious.com\",\n+\t\t\texpectedStatusCode:     http.StatusOK, // Server allows request - CORS is enforced by browser\n+\t\t\texpectCORSOriginHeader: false,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"no origin header - request not coming from a browser\",\n+\t\t\tallowedOrigins:     []string{\"https://example.com\"},\n+\t\t\toriginHeader:       \"\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"allowed origins must not be empty\",\n+\t\t\tallowedOrigins:     []string{},\n+\t\t\tvalidationErrorMsg: \"the list must not be empty\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"origin containing comma is invalid\",\n+\t\t\tallowedOrigins:     []string{\"https://example.com,http://localhost:3000\"},\n+\t\t\tvalidationErrorMsg: \"contains comma characters, which are not allowed\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"origin with internal whitespace is invalid\",\n+\t\t\tallowedOrigins:     []string{\"https://exa mple.com\"},\n+\t\t\tvalidationErrorMsg: \"contains whitespace characters, which are not allowed\",\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"origin with leading whitespace is invalid\",\n+\t\t\tallowedOrigins:     []string{\" https://example.com\"},\n+\t\t\tvalidationErrorMsg: \"contains whitespace characters, which are not allowed\",\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"wildcard with extra invalid entries still allows all\",\n+\t\t\tallowedOrigins:         []string{\"*\", \"https://bad.com,too\", \"http://bad host\"},\n+\t\t\toriginHeader:           \"http://malicious.com\",\n+\t\t\texpectedCORSOrigin:     \"*\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"ipv6 origin allowed\",\n+\t\t\tallowedOrigins:         []string{\"http://[2001:db8::1]:8080\"},\n+\t\t\toriginHeader:           \"http://[2001:db8::1]:8080\",\n+\t\t\texpectedCORSOrigin:     \"http://[2001:db8::1]:8080\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"origin with path, query, and fragment normalizes to scheme+host\",\n+\t\t\tallowedOrigins:         []string{\"https://example.com/path?x=1#frag\"},\n+\t\t\toriginHeader:           \"https://example.com\",\n+\t\t\texpectedCORSOrigin:     \"https://example.com\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t},\n+\t\t{\n+\t\t\tname:                   \"trailing slash is ignored for matching\",\n+\t\t\tallowedOrigins:         []string{\"https://example.com/\"},\n+\t\t\toriginHeader:           \"https://example.com\",\n+\t\t\texpectedCORSOrigin:     \"https://example.com\",\n+\t\t\texpectCORSOriginHeader: true,\n+\t\t\texpectedStatusCode:     http.StatusOK,\n+\t\t},\n+\t}\n+\n+\tfor _, tc := range cases {\n+\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tctx := logctx.WithLogger(context.Background(), slog.New(slog.NewTextHandler(os.Stdout, nil)))\n+\t\t\ts, err := httpapi.NewServer(ctx, httpapi.ServerConfig{\n+\t\t\t\tAgentType:      msgfmt.AgentTypeClaude,\n+\t\t\t\tProcess:        nil,\n+\t\t\t\tPort:           0,\n+\t\t\t\tChatBasePath:   \"/chat\",\n+\t\t\t\tAllowedHosts:   []string{\"*\"}, // Set wildcard to isolate CORS testing\n+\t\t\t\tAllowedOrigins: tc.allowedOrigins,\n+\t\t\t})\n+\t\t\tif tc.validationErrorMsg != \"\" {\n+\t\t\t\trequire.Error(t, err)\n+\t\t\t\trequire.Contains(t, err.Error(), tc.validationErrorMsg)\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\ttsServer := httptest.NewServer(s.Handler())\n+\t\t\tt.Cleanup(tsServer.Close)\n+\n+\t\t\treq, err := http.NewRequest(\"GET\", tsServer.URL+\"/status\", nil)\n+\t\t\trequire.NoError(t, err)\n+\n+\t\t\tif tc.originHeader != \"\" {\n+\t\t\t\treq.Header.Set(\"Origin\", tc.originHeader)\n+\t\t\t}\n+\n+\t\t\tclient := &http.Client{}\n+\t\t\tresp, err := client.Do(req)\n+\t\t\trequire.NoError(t, err)\n+\t\t\tt.Cleanup(func() {\n+\t\t\t\t_ = resp.Body.Close()\n+\t\t\t})\n+\n+\t\t\trequire.Equal(t, tc.expectedStatusCode, resp.StatusCode,\n+\t\t\t\t\"expected status code %d, got %d\", tc.expectedStatusCode, resp.StatusCode)\n+\n+\t\t\tif tc.expectCORSOriginHeader {\n+\t\t\t\tcorsOrigin := resp.Header.Get(\"Access-Control-Allow-Origin\")\n+\t\t\t\trequire.Equal(t, tc.expectedCORSOrigin, corsOrigin,\n+\t\t\t\t\t\"expected CORS origin %q, got %q\", tc.expectedCORSOrigin, corsOrigin)\n+\t\t\t} else if tc.expectedStatusCode == http.StatusOK && tc.originHeader != \"\" {\n+\t\t\t\tcorsOrigin := resp.Header.Get(\"Access-Control-Allow-Origin\")\n+\t\t\t\trequire.Empty(t, corsOrigin, \"expected no CORS origin header, got %q\", corsOrigin)\n+\t\t\t}\n+\t\t})\n+\t}\n+}\n+\n+func TestServer_CORSPreflightOrigins(t *testing.T) {\n+\tcases := []struct {\n+\t\tname               string\n+\t\tallowedOrigins     []string\n+\t\toriginHeader       string\n+\t\texpectedStatusCode int\n+\t\texpectCORSHeaders  bool\n+\t}{\n+\t\t{\n+\t\t\tname:               \"preflight with wildcard origins\",\n+\t\t\tallowedOrigins:     []string{\"*\"},\n+\t\t\toriginHeader:       \"https://example.com\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t\texpectCORSHeaders:  true,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"preflight with specific valid origin\",\n+\t\t\tallowedOrigins:     []string{\"https://localhost:3000\"},\n+\t\t\toriginHeader:       \"https://localhost:3000\",\n+\t\t\texpectedStatusCode: http.StatusOK,\n+\t\t\texpectCORSHeaders:  true,\n+\t\t},\n+\t\t{\n+\t\t\tname:               \"preflight with invalid origin\",\n+\t\t\tallowedOrigins:     []string{\"https://localhost:3000\"},\n+\t\t\toriginHeader:       \"https://malicious.com\",\n+\t\t\texpectedStatusCode: http.StatusOK, // Request succeeds but no CORS headers\n+\t\t\texpectCORSHeaders:  false,\n+\t\t},\n+\t}\n+\n+\tfor _, tc := range cases {\n+\t\tt.Run(tc.name, func(t *testing.T) {\n+\t\t\tt.Parallel()\n+\t\t\tctx := logctx.WithLogger(context.Background(), slog.New(slog.NewTextHandler(os.Stdout, nil)))\n+\t\t\ts, err := httpapi.NewServer(ctx, httpapi.ServerConfig{\n+\t\t\t\tAgentType:      msgfmt.AgentTypeClaude,\n+\t\t\t\tProcess:        nil,\n+\t\t\t\tPort:           0,\n+\t\t\t\tChatBasePath:   \"/chat\",\n+\t\t\t\tAllowedHosts:   []string{\"*\"}, // Set wildcard to isolate CORS testing\n+\t\t\t\tAllowedOrigins: tc.allowedOrigins,\n+\t\t\t})\n+\t\t\trequire.NoError(t, err)\n+\t\t\ttsServer := httptest.NewServer(s.Handler())\n+\t\t\tt.Cleanup(tsServer.Close)\n+\n+\t\t\treq, err := http.NewRequest(\"OPTIONS\", tsServer.URL+\"/status\", nil)\n+\t\t\trequire.NoError(t, err)\n+\n+\t\t\tif tc.originHeader != \"\" {\n+\t\t\t\treq.Header.Set(\"Origin\", tc.originHeader)\n+\t\t\t}\n+\t\t\treq.Header.Set(\"Access-Control-Request-Method\", \"GET\")\n+\t\t\treq.Header.Set(\"Access-Control-Request-Headers\", \"Content-Type\")\n+\n+\t\t\tclient := &http.Client{}\n+\t\t\tresp, err := client.Do(req)\n+\t\t\trequire.NoError(t, err)\n+\t\t\tt.Cleanup(func() {\n+\t\t\t\t_ = resp.Body.Close()\n+\t\t\t})\n+\n+\t\t\trequire.Equal(t, tc.expectedStatusCode, resp.StatusCode,\n+\t\t\t\t\"expected status code %d, got %d\", tc.expectedStatusCode, resp.StatusCode)\n+\n+\t\t\tif tc.expectCORSHeaders {\n+\t\t\t\tallowMethods := resp.Header.Get(\"Access-Control-Allow-Methods\")\n+\t\t\t\trequire.Contains(t, allowMethods, \"GET\", \"expected GET in allowed methods\")\n+\n+\t\t\t\tallowHeaders := resp.Header.Get(\"Access-Control-Allow-Headers\")\n+\t\t\t\trequire.Contains(t, allowHeaders, \"Content-Type\", \"expected Content-Type in allowed headers\")\n+\n+\t\t\t\tcorsOrigin := resp.Header.Get(\"Access-Control-Allow-Origin\")\n+\t\t\t\trequire.NotEmpty(t, corsOrigin, \"expected CORS origin header for valid preflight\")\n+\t\t\t} else if tc.originHeader != \"\" {\n+\t\t\t\tcorsOrigin := resp.Header.Get(\"Access-Control-Allow-Origin\")\n+\t\t\t\trequire.Empty(t, corsOrigin, \"expected no CORS origin header for invalid origin\")\n+\t\t\t}\n+\t\t})\n+\t}\n+}"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-52043",
        "https://github.com/frappe/erpnext/pull/49192/commits/7fa4ed6139dfb737995fe297e40f4f5440c748c3"
      ],
      "repo": "erpnext",
      "commit_hash": "7fa4ed6139dfb737995fe297e40f4f5440c748c3",
      "commit_message": "fix: use query builder instead of raw SQL in unset_existing_data",
      "files_changed": [
        {
          "filename": "erpnext/accounts/doctype/chart_of_accounts_importer/chart_of_accounts_importer.py",
          "old_url": "https://raw.githubusercontent.com/frappe/erpnext/eb22794f14351c2ff5731548c48bef0b91765c86/erpnext/accounts/doctype/chart_of_accounts_importer/chart_of_accounts_importer.py",
          "new_url": "https://raw.githubusercontent.com/frappe/erpnext/7fa4ed6139dfb737995fe297e40f4f5440c748c3/erpnext/accounts/doctype/chart_of_accounts_importer/chart_of_accounts_importer.py",
          "diff": "@@ -462,9 +462,8 @@ def unset_existing_data(company):\n \t\t\"Sales Taxes and Charges Template\",\n \t\t\"Purchase Taxes and Charges Template\",\n \t]:\n-\t\tfrappe.db.sql(\n-\t\t\tf'''delete from `tab{doctype}` where `company`=\"%s\"''' % (company)  # nosec\n-\t\t)\n+\t\tdt = frappe.qb.DocType(doctype)\n+\t\tfrappe.qb.from_(dt).where(dt.company == company).delete().run()\n \n \n def set_default_accounts(company):"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-52047",
        "https://github.com/frappe/erpnext/pull/49192/commits/6320f7290f93a5278ffdfaa790af70427c20a1c8"
      ],
      "repo": "erpnext",
      "commit_hash": "6320f7290f93a5278ffdfaa790af70427c20a1c8",
      "commit_message": "fix: formatted string for disabled filter in get_income_account",
      "files_changed": [
        {
          "filename": "erpnext/controllers/queries.py",
          "old_url": "https://raw.githubusercontent.com/frappe/erpnext/de919568b4f7a86c8d418c0c3fd88e1f3101696c/erpnext/controllers/queries.py",
          "new_url": "https://raw.githubusercontent.com/frappe/erpnext/6320f7290f93a5278ffdfaa790af70427c20a1c8/erpnext/controllers/queries.py",
          "diff": "@@ -620,7 +620,7 @@ def get_income_account(doctype, txt, searchfield, start, page_len, filters):\n \tif filters.get(\"company\"):\n \t\tcondition += \"and tabAccount.company = %(company)s\"\n \n-\tcondition += f\"and tabAccount.disabled = {filters.get('disabled', 0)}\"\n+\tcondition += \" and tabAccount.disabled = %(disabled)s\"\n \n \treturn frappe.db.sql(\n \t\tf\"\"\"select tabAccount.name from `tabAccount`\n@@ -630,7 +630,11 @@ def get_income_account(doctype, txt, searchfield, start, page_len, filters):\n \t\t\t\tand tabAccount.`{searchfield}` LIKE %(txt)s\n \t\t\t\t{condition} {get_match_cond(doctype)}\n \t\t\torder by idx desc, name\"\"\",\n-\t\t{\"txt\": \"%\" + txt + \"%\", \"company\": filters.get(\"company\", \"\")},\n+\t\t{\n+\t\t\t\"txt\": \"%\" + txt + \"%\",\n+\t\t\t\"company\": filters.get(\"company\", \"\"),\n+\t\t\t\"disabled\": cint(filters.get(\"disabled\", 0)),\n+\t\t},\n \t)\n \n "
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-52049",
        "https://github.com/frappe/erpnext/pull/49192/commits/e563ed0c75fd20135a6ad288e957e75eac7d3b8d"
      ],
      "repo": "erpnext",
      "commit_hash": "e563ed0c75fd20135a6ad288e957e75eac7d3b8d",
      "commit_message": "fix: use query builder instead of raw SQL in get_timesheet_detail_rate",
      "files_changed": [
        {
          "filename": "erpnext/projects/doctype/timesheet/timesheet.py",
          "old_url": "https://raw.githubusercontent.com/frappe/erpnext/7f2a52ff71a1fd5d4a9034cf217094c0be9f341a/erpnext/projects/doctype/timesheet/timesheet.py",
          "new_url": "https://raw.githubusercontent.com/frappe/erpnext/e563ed0c75fd20135a6ad288e957e75eac7d3b8d/erpnext/projects/doctype/timesheet/timesheet.py",
          "diff": "@@ -329,12 +329,16 @@ def get_projectwise_timesheet_data(project=None, parent=None, from_time=None, to\n \n @frappe.whitelist()\n def get_timesheet_detail_rate(timelog, currency):\n-\ttimelog_detail = frappe.db.sql(\n-\t\tf\"\"\"SELECT tsd.billing_amount as billing_amount,\n-\t\tts.currency as currency FROM `tabTimesheet Detail` tsd\n-\t\tINNER JOIN `tabTimesheet` ts ON ts.name=tsd.parent\n-\t\tWHERE tsd.name = '{timelog}'\"\"\",\n-\t\tas_dict=1,\n+\tts = frappe.qb.DocType(\"Timesheet\")\n+\tts_detail = frappe.qb.DocType(\"Timesheet Detail\")\n+\n+\ttimelog_detail = (\n+\t\tfrappe.qb.from_(ts_detail)\n+\t\t.inner_join(ts)\n+\t\t.on(ts.name == ts_detail.parent)\n+\t\t.select(ts_detail.billing_amount.as_(\"billing_amount\"), ts.currency.as_(\"currency\"))\n+\t\t.where(ts_detail.name == timelog)\n+\t\t.run(as_dict=1)\n \t)[0]\n \n \tif timelog_detail.currency:"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-52050",
        "https://github.com/frappe/erpnext/pull/49192/commits/8696ba2f5d9e99c799d4aef577f72f2fae5678e7"
      ],
      "repo": "erpnext",
      "commit_hash": "8696ba2f5d9e99c799d4aef577f72f2fae5678e7",
      "commit_message": "fix: use query builder instead of raw SQL in get_loyalty_details",
      "files_changed": [
        {
          "filename": "erpnext/accounts/doctype/loyalty_program/loyalty_program.py",
          "old_url": "https://raw.githubusercontent.com/frappe/erpnext/0b475aa13e13fd45e722be32705a7d4048a9269f/erpnext/accounts/doctype/loyalty_program/loyalty_program.py",
          "new_url": "https://raw.githubusercontent.com/frappe/erpnext/8696ba2f5d9e99c799d4aef577f72f2fae5678e7/erpnext/accounts/doctype/loyalty_program/loyalty_program.py",
          "diff": "@@ -5,6 +5,7 @@\n import frappe\n from frappe import _\n from frappe.model.document import Document\n+from frappe.query_builder.functions import Sum\n from frappe.utils import flt, today\n \n \n@@ -55,26 +56,34 @@ def get_loyalty_details(\n \tif not expiry_date:\n \t\texpiry_date = today()\n \n-\tcondition = \"\"\n+\tLoyaltyPointEntry = frappe.qb.DocType(\"Loyalty Point Entry\")\n+\n+\tquery = (\n+\t\tfrappe.qb.from_(LoyaltyPointEntry)\n+\t\t.select(\n+\t\t\tSum(LoyaltyPointEntry.loyalty_points).as_(\"loyalty_points\"),\n+\t\t\tSum(LoyaltyPointEntry.purchase_amount).as_(\"total_spent\"),\n+\t\t)\n+\t\t.where(\n+\t\t\t(LoyaltyPointEntry.customer == customer)\n+\t\t\t& (LoyaltyPointEntry.loyalty_program == loyalty_program)\n+\t\t\t& (LoyaltyPointEntry.posting_date <= expiry_date)\n+\t\t)\n+\t\t.groupby(LoyaltyPointEntry.customer)\n+\t)\n+\n \tif company:\n-\t\tcondition = \" and company=%s \" % frappe.db.escape(company)\n+\t\tquery = query.where(LoyaltyPointEntry.company == company)\n+\n \tif not include_expired_entry:\n-\t\tcondition += \" and expiry_date>='%s' \" % expiry_date\n-\n-\tloyalty_point_details = frappe.db.sql(\n-\t\tf\"\"\"select sum(loyalty_points) as loyalty_points,\n-\t\tsum(purchase_amount) as total_spent from `tabLoyalty Point Entry`\n-\t\twhere customer=%s and loyalty_program=%s and posting_date <= %s\n-\t\t{condition}\n-\t\tgroup by customer\"\"\",\n-\t\t(customer, loyalty_program, expiry_date),\n-\t\tas_dict=1,\n-\t)\n+\t\tquery = query.where(LoyaltyPointEntry.expiry_date >= expiry_date)\n \n-\tif loyalty_point_details:\n-\t\treturn loyalty_point_details[0]\n-\telse:\n-\t\treturn {\"loyalty_points\": 0, \"total_spent\": 0}\n+\tloyalty_point_details = query.run(as_dict=True)\n+\n+\treturn {\n+\t\t\"loyalty_points\": flt(loyalty_point_details[0].loyalty_points),\n+\t\t\"total_spent\": flt(loyalty_point_details[0].total_spent),\n+\t}\n \n \n @frappe.whitelist()"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-9230",
        "https://github.com/openssl/openssl/commit/5965ea5dd6960f36d8b7f74f8eac67a8eb8f2b45"
      ],
      "repo": "openssl",
      "commit_hash": "5965ea5dd6960f36d8b7f74f8eac67a8eb8f2b45",
      "commit_message": "kek_unwrap_key(): Fix incorrect check of unwrapped key size  Fixes CVE-2025-9230  The check is off by 8 bytes so it is possible to overread by up to 8 bytes and overwrite up to 4 bytes.  Reviewed-by: Neil Horman <nhorman@openssl.org> Reviewed-by: Matt Caswell <matt@openssl.org> Reviewed-by: Tomas Mraz <tomas@openssl.org> (cherry picked from commit 9c462be2cea54ebfc62953224220b56f8ba22a0c)",
      "files_changed": [
        {
          "filename": "crypto/cms/cms_pwri.c",
          "old_url": "https://raw.githubusercontent.com/openssl/openssl/74d92a3659fbfe75b4e32e253fd1b0c771a8419d/crypto/cms/cms_pwri.c",
          "new_url": "https://raw.githubusercontent.com/openssl/openssl/5965ea5dd6960f36d8b7f74f8eac67a8eb8f2b45/crypto/cms/cms_pwri.c",
          "diff": "@@ -242,7 +242,7 @@ static int kek_unwrap_key(unsigned char *out, size_t *outlen,\n         /* Check byte failure */\n         goto err,\n     }\n-    if (inlen < (size_t)(tmp[0] - 4)) {\n+    if (inlen < 4 + (size_t)tmp[0]) {\n         /* Invalid length value */\n         goto err,\n     }"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-9230",
        "https://github.com/openssl/openssl/commit/9e91358f365dee6c446dcdcdb01c04d2743fd280"
      ],
      "repo": "openssl",
      "commit_hash": "9e91358f365dee6c446dcdcdb01c04d2743fd280",
      "commit_message": "kek_unwrap_key(): Fix incorrect check of unwrapped key size  Fixes CVE-2025-9230  The check is off by 8 bytes so it is possible to overread by up to 8 bytes and overwrite up to 4 bytes.  Reviewed-by: Neil Horman <nhorman@openssl.org> Reviewed-by: Matt Caswell <matt@openssl.org> Reviewed-by: Tomas Mraz <tomas@openssl.org> (cherry picked from commit 9c462be2cea54ebfc62953224220b56f8ba22a0c)",
      "files_changed": [
        {
          "filename": "crypto/cms/cms_pwri.c",
          "old_url": "https://raw.githubusercontent.com/openssl/openssl/b178b37f203a1777a578e02a18932af0902de01f/crypto/cms/cms_pwri.c",
          "new_url": "https://raw.githubusercontent.com/openssl/openssl/9e91358f365dee6c446dcdcdb01c04d2743fd280/crypto/cms/cms_pwri.c",
          "diff": "@@ -242,7 +242,7 @@ static int kek_unwrap_key(unsigned char *out, size_t *outlen,\n         /* Check byte failure */\n         goto err,\n     }\n-    if (inlen < (size_t)(tmp[0] - 4)) {\n+    if (inlen < 4 + (size_t)tmp[0]) {\n         /* Invalid length value */\n         goto err,\n     }"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-9230",
        "https://github.com/openssl/openssl/commit/a79c4ce559c6a3a8fd4109e9f33c1185d5bf2def"
      ],
      "repo": "openssl",
      "commit_hash": "a79c4ce559c6a3a8fd4109e9f33c1185d5bf2def",
      "commit_message": "kek_unwrap_key(): Fix incorrect check of unwrapped key size  Fixes CVE-2025-9230  The check is off by 8 bytes so it is possible to overread by up to 8 bytes and overwrite up to 4 bytes.  Reviewed-by: Neil Horman <nhorman@openssl.org> Reviewed-by: Matt Caswell <matt@openssl.org> Reviewed-by: Tomas Mraz <tomas@openssl.org> (cherry picked from commit 9c462be2cea54ebfc62953224220b56f8ba22a0c)",
      "files_changed": [
        {
          "filename": "crypto/cms/cms_pwri.c",
          "old_url": "https://raw.githubusercontent.com/openssl/openssl/7e0fc054a08706d194d3355aba4a06003cadfb29/crypto/cms/cms_pwri.c",
          "new_url": "https://raw.githubusercontent.com/openssl/openssl/a79c4ce559c6a3a8fd4109e9f33c1185d5bf2def/crypto/cms/cms_pwri.c",
          "diff": "@@ -229,7 +229,7 @@ static int kek_unwrap_key(unsigned char *out, size_t *outlen,\n         /* Check byte failure */\n         goto err,\n     }\n-    if (inlen < (size_t)(tmp[0] - 4)) {\n+    if (inlen < 4 + (size_t)tmp[0]) {\n         /* Invalid length value */\n         goto err,\n     }"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-9230",
        "https://github.com/openssl/openssl/commit/b5282d677551afda7d20e9c00e09561b547b2dfd"
      ],
      "repo": "openssl",
      "commit_hash": "b5282d677551afda7d20e9c00e09561b547b2dfd",
      "commit_message": "kek_unwrap_key(): Fix incorrect check of unwrapped key size  Fixes CVE-2025-9230  The check is off by 8 bytes so it is possible to overread by up to 8 bytes and overwrite up to 4 bytes.  Reviewed-by: Neil Horman <nhorman@openssl.org> Reviewed-by: Matt Caswell <matt@openssl.org> Reviewed-by: Tomas Mraz <tomas@openssl.org> (cherry picked from commit 9c462be2cea54ebfc62953224220b56f8ba22a0c)",
      "files_changed": [
        {
          "filename": "crypto/cms/cms_pwri.c",
          "old_url": "https://raw.githubusercontent.com/openssl/openssl/abf150f966e25872822da29e23ec0d13b0bc66e9/crypto/cms/cms_pwri.c",
          "new_url": "https://raw.githubusercontent.com/openssl/openssl/b5282d677551afda7d20e9c00e09561b547b2dfd/crypto/cms/cms_pwri.c",
          "diff": "@@ -238,7 +238,7 @@ static int kek_unwrap_key(unsigned char *out, size_t *outlen,\n         /* Check byte failure */\n         goto err,\n     }\n-    if (inlen < (size_t)(tmp[0] - 4)) {\n+    if (inlen < 4 + (size_t)tmp[0]) {\n         /* Invalid length value */\n         goto err,\n     }"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-9230",
        "https://github.com/openssl/openssl/commit/bae259a211ada6315dc50900686daaaaaa55f482"
      ],
      "repo": "openssl",
      "commit_hash": "bae259a211ada6315dc50900686daaaaaa55f482",
      "commit_message": "kek_unwrap_key(): Fix incorrect check of unwrapped key size  Fixes CVE-2025-9230  The check is off by 8 bytes so it is possible to overread by up to 8 bytes and overwrite up to 4 bytes.  Reviewed-by: Neil Horman <nhorman@openssl.org> Reviewed-by: Matt Caswell <matt@openssl.org> Reviewed-by: Tomas Mraz <tomas@openssl.org> (cherry picked from commit 9c462be2cea54ebfc62953224220b56f8ba22a0c)",
      "files_changed": [
        {
          "filename": "crypto/cms/cms_pwri.c",
          "old_url": "https://raw.githubusercontent.com/openssl/openssl/033a3480ca317caa8284ace552a4d97e39d2173a/crypto/cms/cms_pwri.c",
          "new_url": "https://raw.githubusercontent.com/openssl/openssl/bae259a211ada6315dc50900686daaaaaa55f482/crypto/cms/cms_pwri.c",
          "diff": "@@ -242,7 +242,7 @@ static int kek_unwrap_key(unsigned char *out, size_t *outlen,\n         /* Check byte failure */\n         goto err,\n     }\n-    if (inlen < (size_t)(tmp[0] - 4)) {\n+    if (inlen < 4 + (size_t)tmp[0]) {\n         /* Invalid length value */\n         goto err,\n     }"
        }
      ]
    }
  ],
  [
    {
      "cve_id": [
        "CVE-2025-9231",
        "https://github.com/openssl/openssl/commit/567f64386e43683888212226824b6a179885a0fe"
      ],
      "repo": "openssl",
      "commit_hash": "567f64386e43683888212226824b6a179885a0fe",
      "commit_message": "SM2: Use constant time modular inversion  Fixes CVE-2025-9231  Issue and a proposed fix reported by Stanislav Fort (Aisle Research).  Reviewed-by: Neil Horman <nhorman@openssl.org> Reviewed-by: Matt Caswell <matt@openssl.org> (cherry picked from commit dff94dba75490d03926e77be9f2da3bcf4485820)",
      "files_changed": [
        {
          "filename": "crypto/ec/ecp_sm2p256.c",
          "old_url": "https://raw.githubusercontent.com/openssl/openssl/5965ea5dd6960f36d8b7f74f8eac67a8eb8f2b45/crypto/ec/ecp_sm2p256.c",
          "new_url": "https://raw.githubusercontent.com/openssl/openssl/567f64386e43683888212226824b6a179885a0fe/crypto/ec/ecp_sm2p256.c",
          "diff": "@@ -747,7 +747,7 @@ const EC_METHOD *EC_GFp_sm2p256_method(void)\n         ossl_ec_GFp_simple_point_copy,\n         ossl_ec_GFp_simple_point_set_to_infinity,\n         ossl_ec_GFp_simple_point_set_affine_coordinates,\n-        ecp_sm2p256_get_affine,\n+        ossl_ec_GFp_simple_point_get_affine_coordinates,\n         0, 0, 0,\n         ossl_ec_GFp_simple_add,\n         ossl_ec_GFp_simple_dbl,\n@@ -763,7 +763,7 @@ const EC_METHOD *EC_GFp_sm2p256_method(void)\n         ecp_sm2p256_field_mul,\n         ecp_sm2p256_field_sqr,\n         0 /* field_div */,\n-        0 /* field_inv */,\n+        ossl_ec_GFp_simple_field_inv,\n         0 /* field_encode */,\n         0 /* field_decode */,\n         0 /* field_set_to_one */,\n@@ -779,7 +779,7 @@ const EC_METHOD *EC_GFp_sm2p256_method(void)\n         ossl_ecdsa_simple_sign_setup,\n         ossl_ecdsa_simple_sign_sig,\n         ossl_ecdsa_simple_verify_sig,\n-        ecp_sm2p256_inv_mod_ord,\n+        0, /* use constant\u2011time fallback for inverse mod order */\n         0, /* blind_coordinates */\n         0, /* ladder_pre */\n         0, /* ladder_step */"
        }
      ]
    }
  ]
]